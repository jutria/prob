[["index.html", "Probabilidade Capítulo 1 Introdução", " Probabilidade Prof. Dr. Jaime Utria 2022-05-03 Capítulo 1 Introdução Este material contém os conceitos básicos para um primeiro curso em Teoria das Probabilidades no nível universitário. O Gitbook visa server de apoio para a disciplina de Probabilidade I do curso de Estatística da Universidade Federal Fluminense. "],["esp-prob.html", "Capítulo 2 Espaços de Probabilidade 2.1 Espaço amostral 2.2 Eventos 2.3 Probabilidade 2.4 Probabilidade Condicional", " Capítulo 2 Espaços de Probabilidade Neste capítulo formulamos um modelo matemático (ou modelo probabilístico) para um experimento aleatório. Começamos definindo o que é um experimento aleatório. Definição 2.1 Um experimento é aleatório se, quando repetido sob as mesmas condições nem sempre gera os mesmos resultados, isto é, não conseguimos prever o resultado do experimento até que ele seja realizado. Exemplos de experimentos aleatorios Lançar um dado e registrar a face superior. Contar o número de pessoas que chegam numa agência bancária durante um período de tempo dado. Medir o tempo de vida útil, em horas, de uma lâmpada. A seguir descreveremos o modelo probabilistíco para um experimento aleatório. 2.1 Espaço amostral Definição 2.2 (Espaço amostral) O conjunto de todos os resultados possíveis de um experimento aleatório é chamado de espaço amostral, e o denotamos por \\(\\Omega\\). A continuação apresentamos um espaço amostral adequado para cada um dos experientos descritos nos exemplos acima: \\(\\Omega = \\{1,2,3,4,5,6\\}\\). \\(\\Omega = \\{0,1,2,3,\\ldots\\}\\) \\(\\Omega = \\{x \\in \\mathbb R : 0\\leq x &lt; \\infty \\}.\\) Note que nos exemplos (i) e (ii), \\(\\Omega\\) é um conjunto no máximo enumerável, quando isso acontece dizemos que \\(\\Omega\\) é um espaço amostral discreto. No entanto, no exemplo (iii) temos um conjunto infinito não-enumerável, nesse caso dizemos que \\(\\Omega\\) é um espaço amostral contínuo. 2.2 Eventos Definição 2.3 (Evento) Informalmente, um evento é qualquer subconjunto \\(A\\subset \\Omega\\). 2.2.1 Relaçoes e operações entre eventos Seja \\(A\\) um evento. Se \\(\\omega\\) é um elemento em \\(\\Omega\\), tal que \\(\\omega \\in A\\), dizemos que \\(A\\) ocorre. Se \\(A=\\{\\omega\\}\\) para algum \\(\\omega \\in \\Omega\\), dizemos que \\(A\\) é um evento elementar. Dados dois eventos \\(A\\) e \\(B\\), dizemos que \\(A\\subset B\\), se \\(\\omega \\in A\\Rightarrow \\omega \\in B\\). Em palavras a ocorrência de \\(A\\) implica a ocorrência de \\(B\\). A união de dois eventos \\(A\\) e \\(B\\) é \\(A \\cup B =\\{\\omega: \\omega \\in A \\text{ ou } \\omega \\in B \\}\\) e representa o evento A intersecção de dois eventos \\(A\\) e \\(B\\) é \\(A\\cap B =\\{\\omega: \\omega \\in A \\text{ e } \\omega \\in B\\}\\) e representa o evento de que ambos \\(A\\) e \\(B\\) ocorrem. A diferença de dois eventos \\(A\\) e \\(B\\) é \\(A\\setminus B = \\{\\omega: \\omega \\in A \\text{ e } \\omega \\notin B\\}\\) e representa o evento de que \\(A\\) ocorre e \\(B\\) não ocorre. Dois eventos \\(A\\) e \\(B\\) são disjuntos ou mutuamente exclusivos se \\(A\\cap B =\\emptyset\\). Isso significa que \\(A\\) e \\(B\\) não ocorrem simultaneamente. Para qualquer evento \\(A\\), o complementar de \\(A\\) é \\(A^c =\\{\\omega: \\omega \\notin A\\}\\) e representa o evento de que \\(A\\) não ocorre. Leis de Morgan: Sejam \\(A_1,A_2,\\ldots,A_n\\) eventos, temos que \\[\\begin{align} \\left( \\bigcup_{i=1}^n A_i\\right)^c = \\bigcap_{i=1}^n A_i^c, \\tag{LM1} \\label{LM1} \\\\ \\left( \\bigcap_{i=1}^n A_i\\right)^c = \\bigcup_{i=1}^n A_i^c. \\label{LM2} \\tag{LM2} \\end{align}\\] Observação. Note que \\(\\eqref{LM1}\\) diz que o complementar de que pelo menos um dos \\(A_i\\)’s ocorre é igual ao evento de que nenhum dos \\(A_i\\)’s ocorra. Enquanto \\(\\eqref{LM2}\\) diz que o complementar de que todos os \\(A_i\\)’s ocorrem é igual ao evento de que pelo menos um dos \\(A_i\\)’s não ocorre. 2.3 Probabilidade Definição 2.4 (Definição clássica) Seja \\(\\Omega =\\{\\omega_1,\\ldots,\\omega_N\\}\\) finito, e suponhamos que cada evento elementar é igualmente provável, isto é, \\[ P(\\omega) = \\frac{1}{N}, \\, \\omega \\in \\Omega. \\] Definimos a probabilidade do evento \\(A\\subset \\Omega\\) como \\[ P(A) = \\frac{|A|}{|\\Omega|}. \\] Definição 2.5 (Definição axiomática) Uma probabilidade é uma função \\(P: \\mathcal F \\rightarrow \\mathbb R\\), em que \\(\\mathcal F\\) é uma classe de eventos de um espaço amostral \\(\\Omega\\), que satisfaz as seguintes condições: \\(P(A) \\geq 0\\), para todo \\(A \\in \\mathcal F\\), \\(P(\\Omega) = 1\\), (Aditividade enumerável). Para qualquer sequência \\(A_1,A_2,\\ldots \\in \\mathcal F\\), tais que \\(A_i \\cap A_j =\\emptyset\\), \\(i\\neq j\\), \\[\\begin{align*} P\\left(\\bigcup_{i=1}^\\infty A_i\\right)= \\sum_{i=1}^\\infty P(A_i). \\end{align*}\\] Observação. Quando \\(\\Omega\\) é infinito não-enumerável, geralmente é impossível associar uma probabilidade bem definida a todos os subconjuntos de \\(\\Omega\\). Para isso, definimos uma probabilidade em uma classe mais restrita de subconjuntos de \\(\\Omega\\) (chamada de \\(\\sigma\\)-álgebra e definida abaixo); e apenas esses subconjuntos são chamados de eventos. Definição 2.6 (sigma-álgebra) Uma classe \\(\\mathcal F \\subset 2^\\Omega\\) é uma \\(\\sigma\\)-álgebra (em \\(\\Omega \\neq \\emptyset\\)) se satisfaz as seguintes condições \\(\\Omega \\in \\mathcal F\\), Se \\(A \\in \\mathcal F\\), então \\(A^c \\in \\mathcal F\\), Se \\(A_1,A_2,\\ldots \\in \\mathcal F\\), então \\(\\displaystyle\\bigcup_{i=1}^\\infty A_i \\in \\mathcal F\\). O trio \\((\\Omega,\\mathcal F, P)\\) é chamado de um espaço de probabilidade. 2.3.1 Propriedades de uma probabilidade \\(P(\\emptyset) = 0\\). Se \\(A_1,A_2,\\ldots,A_n\\) são eventos dois a dois disjuntos, então \\[\\begin{align*} P\\left(\\bigcup_{i=1}^n A_i \\right) = \\sum_{i=1}^n P(A_i) \\end{align*}\\] \\(P(A) = 1- P(A^c)\\) para todo evento \\(A\\). Para quaisquer eventos \\(A\\) e \\(B\\), \\[\\begin{align*} P(B) = P(A \\cap B) + P(A^c \\cap B) \\end{align*}\\] Se \\(A \\subset B\\), então \\(P(A) \\leq P(B)\\). \\(P(A)\\leq 1\\) para todo evento \\(A\\). Para quaisquer eventos \\(A\\) e \\(B\\), \\[\\begin{align*} P(A\\cup B) =P(A) + P(B) - P(A\\cap B). \\end{align*}\\] Princípio da Inclusão-Exclusão \\[\\begin{align*} P\\left(\\bigcup_{i=1}^n A_i \\right) &amp;= \\sum_{i=1}^n P(A_i) - \\sum_{i&lt;j} P(A_i \\cap A_j)\\\\ &amp;+ \\sum_{i&lt;j&lt;k} P(A_i \\cap A_j \\cap A_k) - \\cdots +(-1)^{n+1} P(A_1\\cap \\cdots \\cap A_n) \\end{align*}\\] Subaditividade finita: Para qualquer sequência finita \\(A_1,A_2,\\ldots, A_n\\) de eventos, \\[ P\\left(\\bigcup_{i=1}^n A_i \\right) \\leq \\sum_{i=1}^n P(A_i). \\] Subaditividade enumerável: Para qualquer sequência \\(A_1,A_2,\\ldots\\) de eventos, \\[ P\\left(\\bigcup_{i=1}^\\infty A_i \\right) \\leq \\sum_{i=1}^\\infty P(A_i). \\] As propriedades (ix) e (x), são conhecidas como Desigualdades de Boole. Prova. Para provar i. Defina \\(A_1 = \\Omega\\), \\(A_i = \\emptyset\\), \\(i&gt;1\\), logo \\(\\Omega = \\bigcup _{i=1}^\\infty A_i\\). Além disso, \\[\\begin{align*} 1=P(\\Omega) = P(\\Omega) + \\sum_{i=2}^\\infty P(\\emptyset) \\Rightarrow \\sum_{i=2}^\\infty P(\\emptyset) = 0 \\Rightarrow P(\\emptyset) = 0. \\end{align*}\\] Defina \\(A_i = \\emptyset\\), \\(i&gt;n\\), logo \\(\\bigcup_{i=1}^\\infty A_i = \\bigcup_{i=1}^n A_i\\), pelo axioma (iii) em e a propriedade 1, segue que \\[\\begin{align*} P\\left(\\bigcup_{i=1}^n A_i\\right)=P\\left(\\bigcup_{i=1}^\\infty A_i\\right) = \\sum_{i=1}^n P(A_i) + \\sum_{i=n+1}^\\infty P(\\emptyset) = \\sum_{i=1}^n P(A_i) \\end{align*}\\] Note que para qualquer \\(A\\subset \\Omega\\), temos que \\(\\Omega= A \\cup A^c\\) e \\(A\\cap A^c = \\emptyset\\), logo \\[\\begin{align*} 1=P(\\Omega)=P(A) + P(A^c) \\Rightarrow P(A^c) = 1-P(A) \\end{align*}\\] Note que \\(B = (A\\cap B) \\cup (A^c \\cap B)\\) tal que \\((A\\cap B) \\cap (A^c \\cap B) = \\emptyset\\), logo \\[\\begin{align*} P(B) = P(A\\cap B) + P(A^c \\cap B) \\end{align*}\\] Como \\(A\\subset B\\), temos que \\(B=(B\\setminus A) \\cup A\\), com \\((B\\setminus A) \\cap A = \\emptyset\\), logo \\[\\begin{align*} P(B) = P(A) + P(A\\setminus B) \\geq P(A). \\end{align*}\\] Como \\(A\\subset \\Omega\\), logo \\(P(A) \\leq P(\\Omega) = 1\\). Note que \\(A\\cup B = (A\\setminus B) \\cup (A \\cap B) \\cup (B \\setminus A)\\), logo \\[\\begin{align*} P(A\\cup B) &amp;= P(A\\setminus B) + P(A \\cap B) + P(B\\setminus A) \\\\ &amp;= [P(A\\setminus B) + P(A \\cap B)] + [P(B\\setminus A) + P(A\\cap B)] - P(A\\cap B)\\\\ &amp;= P(A) + P(B) - P(A\\cap B). \\end{align*}\\] Use indução em \\(n\\). Note que para o caso \\(n=3\\), temos \\[\\begin{align*} P(A\\cup B\\cup C) &amp;= P(A) + P(B) + P(C) - P(A\\cap B) - P(A\\cap C) - P(B \\cap C) \\\\ &amp;+ P(A\\cap B \\cap C). \\end{align*}\\] 2.3.2 Calculando probabilidades Exemplo 2.1 Um comitê de 5 pessoas deve ser selecionado de um grupo de 6 homens e 9 mulheres. Se a seleção for feita aleatoriamente, qual a probabilidade de que o comitê seja formado por 3 homens e 2 mulheres? Solução. Como o experimento consiste em escolher 5 pessoas do total de 15, temos que \\(|\\Omega|= \\binom{15}{5}\\). Supondo que todas as \\(\\binom{15}{5}\\) tem a mesma probabilidade e se \\(A\\) representa o evento de que a seleção feita seja formada por 3 homens e 2 mulheres, temos que \\(|A| = \\binom{6}{3} \\binom{9}{2}\\). Portanto, \\[\\begin{align*} P(A) &amp;= \\frac{|A|}{|\\Omega|} \\\\ &amp;= \\frac{\\binom{6}{3}\\binom{9}{2}}{\\binom{15}{5}}=\\frac{240}{1001} \\end{align*}\\] Exemplo 2.2 Numa mão de pôquer de cinco cartas, o full house ocorre quando alguém sai com três cartas de mesmo valor e duas outras cartas do mesmo valor (diferente do primeiro). Assim um full house é formado por uma trinca e um par. Qual a probabilidade de alguém sair com um full house? Solução. Vamos supor que todas \\(\\binom{52}{5}\\) possíveis seleções são equiprováveis. Note que o número de maneiras de escolher um par é \\(13 \\cdot \\binom{4}{2}\\) e uma vez escolhido o par, o número de maneiras de escolher uma trinca é \\(12 \\cdot \\binom{4}{3}\\), logo se \\(A\\) é o evento de sair um full house, temos que \\[\\begin{align*} P(A) = \\frac{13\\cdot 12 \\cdot \\binom{4}{2} \\cdot \\binom{4}{3}}{\\binom{52}{5}} \\approx 0,0014. \\end{align*}\\] Exemplo 2.3 Um estudante possui 5 livros diferentes de Probabilidade, 2 livros diferentes de Estatística e 3 livros diferentes de Computação, que serão dispostos aleatoriamente em uma prateleira. Qual a probabilidade de que os livros de cada assunto fiquem juntos? Solução. Primeiro observe que temos 10! maneiras de dispor os 10 livros na prateleira, logo para garantir que os livros de cada assunto fiquem juntos vamos formar três blocos (um por cada assunto): o primeiro bloco é formado pelos 5 livros de Probabilidade, o segundo pelos 2 livros de Estatística e o terceiro pelos 3 livros de Computação. Assim, para o primeiro bloco temos 5! maneiras de ordenar eles, para o segundo temos 2! e para o terceiro temos 3!, finalmente temos 3! maneiras de ordenar os blocos. Portanto, a probabilidade pedida é \\[\\begin{align*} P(\\text{os livros de cada assunto fiquem juntos}) &amp;= \\frac{5!2!3!3!}{10!}\\\\ &amp;=\\frac{1}{420} \\end{align*}\\] 2.3.3 Espaço de probabilidade no caso \\(\\Omega\\) enumerável Suponha que \\(\\Omega = \\{\\omega_1, \\omega_2,\\ldots\\}\\) seja um conjunto enumerável e assuma que a cada \\(\\omega_i \\in \\Omega\\), atribuimos um peso \\(p(\\omega_i)\\) tal que \\(\\sum_{i=1}^\\infty p(\\omega_i) = 1\\), além disso considere como família de eventos \\(\\mathcal F = 2^\\Omega\\) e para qualquer \\(A \\in \\mathcal F\\), definimos a probabilidade de \\(A\\) como \\[ P(A) = \\sum_{i: \\omega_i \\in A} p(\\omega_i). \\] Exemplo 2.4 Suponha um jogo no qual você ganha \\(k-2\\) reais com probabilidade \\(\\left(\\frac{1}{2}\\right)^k\\) para qualquer \\(k\\geq 1\\) inteiro. Qual a probabilidade de você ganhar mais de dos reais ? Solução. Neste caso o espaço amostral é dado pela quantidade de reais que você pode ganhar no jogo, ou seja, \\[ \\Omega = \\{-1,0,1,2,\\ldots\\}, \\] e \\[ P(\\{\\omega\\})=P(\\omega) = \\left(\\frac{1}{2}\\right)^{\\omega+2}, \\; \\omega \\in \\Omega.\\] Por exemplo, \\(P(\\{-1\\}) = 1/2\\) e \\(P(\\{0\\}) = 1/4\\). O evento de interesse é \\(A=\\{3,4,5,6,\\ldots\\}\\). Portanto, \\[\\begin{align*} P(A) = \\sum_{\\omega = 3}^\\infty P(\\omega) &amp;= \\sum_{\\omega=3}^\\infty \\left(\\frac{1}{2}\\right)^{\\omega + 2}\\\\ &amp;=\\frac{1}{4} \\sum_{\\omega=3}^\\infty \\left(\\frac{1}{2}\\right)^{\\omega} \\\\ &amp;= \\frac{1}{16}. \\end{align*}\\] 2.4 Probabilidade Condicional Considere o experimento que consiste em lançar um dado honesto e defina os eventos \\(A=\\{1,2,3\\}\\) e \\(B=\\{2,4,6\\}\\), temos que \\(P(A) = \\frac{1}{2}\\), essa é a probabilidade a priori de \\(A\\), isto é, antes que o experimento se realize. Suponha que uma vez realizado o experimento alguém nos infrome que o resultado do mesmo é um número par, ou seja que \\(B\\) ocorreu. Com essa nova informação, a probabilidade de \\(A\\) é atualizada, pois para que \\(A\\) aconteça o único resultado possível do experimento deve ter sido 2. O que nos leva a \\[ P(A \\text{ dado } B) = \\frac{|A\\cap B|}{|\\Omega|} = \\frac{1}{3}. \\] Essa probabilidade é chamada de probabilidade a posteriori de \\(A\\) dado \\(B\\). Daqui em diante, vamos chama-la de probabilidade de \\(A\\) dada a ocorrência de \\(B\\) ou simplesmente de probabilidade de \\(A\\) dado \\(B\\). Do exemplo, podemos generalizar com a seguinte definição: Definição 2.7 (Probabilidade condicional) Sejam \\(A,B\\) dois eventos em um espaço de probabilidade \\((\\Omega, \\mathcal F, P)\\), tal que \\(P(B)&gt;0\\), definimos a probabilidade condicional de \\(A\\) dado \\(B\\) como \\[\\begin{align*} P(A|B) = \\frac{P(A\\cap B)}{P(B)}. \\end{align*}\\] Proposição 2.1 Seja \\(B\\) um evento em um espaço de probabilidade \\((\\Omega,\\mathcal F, P)\\), tal que \\(P(B)&gt;0\\), temos que \\(P(\\cdot|B)\\) é uma probabilidade. Prova. Devemos verificar os três axiomas da definição axiomática de probabilidade. Com efeito \\(P(A|B) \\geq 0\\), para qualquer evento \\(A\\) (trivial). \\(P(\\Omega|B) = \\frac{P(\\Omega\\cap B)}{P(B)} = \\frac{P(B)}{P(B)} = 1\\). Aditividade enumerável: Sejam \\(A_1, A_2,\\ldots\\) eventos disjuntos dois a dois, então \\[\\begin{align*} P\\left(\\bigcup_{i=1}^\\infty A_i|B\\right) &amp;= \\frac{P\\left(\\left(\\bigcup_{i=1}^\\infty A_i\\right) \\cap B\\right)}{P(B)}\\\\ &amp;= \\frac{P\\left(\\bigcup_{i=1}^\\infty (A_i \\cap B)\\right)}{P(B)} \\\\ &amp;= \\frac{\\sum_{i=1}^\\infty P(A_i\\cap B)}{P(B)} \\\\ &amp;= \\sum_{i=1}^\\infty P(A_i|B) \\end{align*}\\] Proposição 2.2 (Regra da multiplicação) Se \\(A_1,\\ldots,A_n\\) são eventos em um espaço de probabilidade \\((\\Omega,\\mathcal F, P)\\) com \\(P(A_1\\cap \\ldots \\cap A_{n-1})&gt;0\\), então \\[ P(A_1 \\cap A_2 \\cap \\ldots \\cap A_n) = P(A_1)P(A_2|A_1) \\cdots P(A_n|A_1 \\cap \\ldots \\cap A_{n-1}) \\] 2.4.1 Fórmula da probabilidade total Definição 2.8 (Partição) Seja \\(\\Omega\\neq \\emptyset\\), uma partição de \\(\\Omega\\) é uma sequencia finita de conjuntos (ou eventos) \\(A_1,\\ldots,A_n\\) tais que \\(A_i \\cap A_j = \\emptyset\\) para qualquer \\(i\\neq j\\), \\(i,j=1,\\ldots,n\\), \\(\\displaystyle \\bigcup_{i=1}^n A_i = \\Omega\\). Teorema 2.1 (Fórmula da probabilidade total) Seja \\(\\{A_i\\}_{i=1}^n\\) uma partição do espaço amostral \\(\\Omega\\), tal que \\(P(A_i)&gt;0\\) para qualquer \\(i=1,\\ldots, n\\) e \\(B\\) um evento qualquer, temos que \\[ P(B) = \\sum_{i=1}^n P(B|A_i)P(A_i). \\] Prova. Note que \\(\\displaystyle B = \\bigcup_{i=1}^n (B\\cap A_i)\\) e \\((B\\cap A_i) \\cap (B\\cap A_j)\\) para qualquer \\(i\\neq j\\). Logo \\[ P(B) = \\sum_{i=1}^n P(B\\cap A_i) = \\sum_{i=1}^n P(B|A_i) P(A_i), \\] onde a ultima passagem decorre da regra da multiplicação para dois eventos. Exemplo 2.5 Durante o mês de outubro a probabilidade de chuva em um dia determinado é de 4/10. Um time de futebol ganha um jogo em um dia com chuva com probabilidade 6/10 e em um dia sem chuva com probabilidade de 4/10. Qual a probabilidade de que esse time ganhe um jogo naquele dia de outubro? Solução. Seja \\(A\\): Fluminense ganhe um jogo naquele dia de outubro e \\(B\\): teve chuva naquele dia de outubro, logo \\[ P(A) = P(A|B)P(B) + P(A|B^c)P(B^c) = (6/10)(4/10) + (4/10)(6/10) = 24/50 \\] Exemplo 2.6 Ao responder uma questão em uma prova de múltipla escolha, um estudante sabe a resposta ou a chuta. Seja \\(p\\) a probabilidade de que o estudante saiba a resposta e \\(1-p\\) a probabilidade de que ele chute. Suponha que um estudante que chuta a resposta tem uma probabilidade de acerto de \\(1/m\\), onde \\(m\\) é o número de alternativas em cada questão de múltipla escolha. Qual a probabilidade que ele a tenha respondido corretamente? Solução. Denote por \\(A\\): o estudante tenha respondido corretamente [acerta a resposta] e por \\(B\\): o estudante sabe a resposta, logo \\[ P(A) = P(A|B)P(B) + P(A|B^c)P(B^c) = p\\cdot 1 + (1-p) \\cdot 1/m = p+(1-p)/m. \\] Por exemplo, se \\(p=1/2\\) e \\(m=10\\), temos que \\(P(A) = \\frac{11}{20}\\). Exemplo 2.7 Em uma cidade, os motoristas são parados pela polícia para fazer um teste sobre o teor de álcool no sangue. Suponha que a probabilidade de que um motorista detido esteja embriagado é 5% e que o teste realizado acerta o estado de embriaguez em 80% das ocasiões. Qual a probabilidade de que o teste de um motorista detido resulte positivo? 2.4.2 Fórmula de Bayes Teorema 2.2 (Fórmula de Bayes) Seja \\(\\{A_i\\}_{i=1}^n\\) uma partição do espaço amostral \\(\\Omega\\), tal que \\(P(A_i)&gt;0\\) para qualquer \\(i=1,\\ldots, n\\) e \\(B\\) um evento, temos que \\[ P(A_i|B) = \\frac{P(B|A_i)P(A_i)}{\\sum_{i=1}^n P(B|A_i)P(A_i)} \\] Prova. Para cada \\(i=1,2,\\ldots,n\\), temos que \\[\\begin{align*} P(A_i|B)&amp;=\\frac{P(A_i\\cap B)}{P(B)} \\\\ &amp;=\\frac{P(B|A_i)P(A_i)}{\\sum_{i=1}^n P(B|A_i)P(A_i)} \\end{align*}\\] Na primeira passagem aplicamos a definição de probabilidade condicional, na segunda passagem aplicamos, no numerador, a regra da multiplicação e no denominador o teorema da probabilidade total. Solução. Denote por \\(A\\): teste resulte positivo e por \\(B\\): o motorista está embriagado. \\[P(A) = P(A|B)P(B) + P(A|B^c)P(B^c) = (0,80)(0,05) + (0,20)(0,95) = 23/100.\\] Exemplo 2.8 Nas mesmas condições do exemplo 3, dado que o teste de um motorista resulto negativo, qual a probabilidade de que estava dirigindo com um índice alcoólico acima do permitido? Solução. Defina \\(B\\): embriagado, \\(B^c\\): sóbrio, \\(A^c\\): teste negativo, \\(A\\): teste positivo Pelo Teorema de Bayes, temos que \\[\\begin{align*} P(B|A^c) &amp;=\\frac{P(A^c|B)P(B)}{P(A^c|B)P(B) + P(A^c|B^c)P(B^c)}\\\\ &amp;=\\frac{(0,20)(0,05)}{(0,20)(0,05)+(0,80)(0,95)} \\\\ &amp;\\approx 0.01 \\end{align*}\\] Ou seja, a probabilidade de ocorrer um falso negativo é aproximadamente de 1% . "],["conjuntos-limites-e-continuidade-da-probabilidade.html", "Capítulo 3 Conjuntos limites e continuidade da probabilidade 3.1 Limite superior e inferior de uma sequência de números reais.", " Capítulo 3 Conjuntos limites e continuidade da probabilidade Definição 3.1 (Sequências monótonas de eventos) Sejam \\(A_1,A_2,\\ldots\\) eventos em um espaço de probabilidade \\((\\Omega, \\mathcal F, P)\\). Dizemos que \\((A_n)_{n\\geq 1}\\) é uma sequência de eventos crescente se \\[ A_1 \\subset A_2 \\subset A_3 \\subset \\cdots \\] Dizemos que \\((A_n)_{n\\geq 1}\\) é uma sequência de eventos decrescente se \\[ A_1 \\supset A_2 \\supset A_3 \\supset \\cdots \\] Observação. Se \\((A_n)_{n\\geq 1}\\) é uma sequência crescente ou decrescente, dizemos que é monótona. Definição 3.2 (Limite de sequências monótonas de eventos) Seja \\((A_n)_{n\\geq 1}\\) uma sequência de eventos em um espaço de probabilidade \\((\\Omega,\\mathcal F, P)\\). Denotamos por \\(A_n\\uparrow A\\), se \\((A_n)_{n\\geq 1}\\) é uma sequência crescente de eventos e \\[ A = \\bigcup_{n=1}^\\infty A_n. \\] Denotamos por \\(A_n\\downarrow A\\), se \\((A_n)_{n\\geq 1}\\) é uma sequência crescente de eventos e \\[ A = \\bigcap_{n=1}^\\infty A_n. \\] Teorema 3.1 (Continuidade monótona da probabilidade) Seja \\((A_n)_{n\\geq 1}\\) uma sequência de eventos em um espaço de probabilidade \\((\\Omega,\\mathcal F, P)\\). Se \\(A_n \\uparrow A\\), então \\(P(A_n) \\uparrow P(A)\\) (continuidade por baixo). Se \\(A_n \\downarrow A\\), então \\(P(A_n) \\downarrow P(A)\\) (continuidade por cima). Prova. Para provar i. Defina \\(B_1 = A_1\\), \\(B_k = A_k\\setminus A_{k-1}\\), \\(k\\geq 2\\) e note que os eventos \\(B_1,B_2,\\ldots\\) são disjuntos dois a dois. Além disso, \\[ A_n=\\bigcup_{k=1}^n B_k \\; \\; \\; \\text{e} \\; \\; \\; A = \\bigcup_{n=1}^\\infty A_n = \\bigcup_{n=1}^\\infty B_n \\] Logo, \\[\\begin{align} P(A_n) = \\sum_{k=1}^n P(B_k), \\\\ P(A) =\\sum_{n=1}^\\infty P(B_k). \\end{align}\\] Além disso, como \\(A_n\\subset A_{n+1},\\) \\(\\forall n\\geq 1\\), temos que \\(P(A_n)\\leq P(A_{n+1}),\\) \\(\\forall n\\geq 1\\). Finalmente, tomando limite em (1) quando \\(n \\to \\infty\\), temos que \\(P(A_n) \\uparrow P(A)\\). Para provar ii. note que \\(A_n^c \\uparrow A^c\\), logo pela parte i., segue que \\(P(A_n^c) \\uparrow P(A^c)\\), logo \\(1-P(A_n) \\uparrow 1- P(A) \\iff P(A_n) \\downarrow P(A)\\). Definição 3.3 (conjuntos limites) Seja \\(A_1,A_2,\\ldots\\) uma sequência de eventos em um espaço de probabilidade \\((\\Omega, \\mathcal F, P)\\), definimos os eventos \\[\\begin{align} {\\lim\\inf}_{n\\to\\infty} A_n = \\bigcup_{n=1}^\\infty \\bigcap_{k=n}^\\infty A_k \\label{liminf} \\\\ {\\lim\\sup}_{n\\to\\infty} A_n = \\bigcap_{n=1}^\\infty \\bigcup_{k=n}^\\infty A_k \\label{limsup} \\end{align}\\] Da definição de \\(\\liminf A_n\\), temos que \\[\\begin{align*} \\omega \\in {\\lim\\inf}_{n\\to\\infty} A_n &amp;\\iff \\exists n \\geq 1, \\forall k \\geq n, \\; \\omega \\in A_k \\\\ &amp;\\iff |\\{ n : \\omega \\notin A_n\\}|&lt; \\infty. \\end{align*}\\] Da definição de \\(\\limsup A_n\\), temos que \\[\\begin{align*} \\omega \\in {\\lim\\sup}_{n\\to\\infty} A_n &amp;\\iff \\forall n\\geq 1, \\exists k \\geq n, \\; \\omega \\in A_k \\\\ &amp;\\iff |\\{n: \\omega \\in A_n \\}|=\\infty \\end{align*}\\] Daí, é frequentemente usada a seguinte notação: \\[{\\lim\\sup}_{n\\to\\infty} A_n = [A_n \\text{ ocorre infinitas vezes}]\\] \\[{\\lim\\inf}_{n\\to\\infty} A_n = [A_n \\text{ ocorre para todo $n$ suficientemente grande}]\\] Observação. Observe que \\(\\liminf_{n\\to\\infty} A_n \\subset \\limsup_{n\\to\\infty} A_n\\), logo temos a seguinte definição. Definição 3.4 (Limite de uma sequência) Se \\(\\limsup_{n\\to\\infty} A_n \\subset \\liminf_{n\\to\\infty} A_n\\), então dizemos que \\(\\lim_{n\\to\\infty} A_n = A\\), onde \\(A = \\liminf_{n\\to\\infty} A_n = \\limsup_{n\\to\\infty} A_n\\). Teorema 3.2 (Continuidade da probabilidade) Se \\(\\lim_{n\\to\\infty} A_n = A\\), então \\(\\lim_{n\\to\\infty} P(A_n) = P(\\lim_{n\\to\\infty} A_n) = P(A)\\). Prova. Para \\(n\\geq 1\\), defina \\(\\displaystyle B_n = \\bigcap_{k=n}^\\infty A_k\\) e \\(\\displaystyle C_n = \\bigcup_{k=n}^\\infty A_k\\) \\(\\Rightarrow\\) \\(B_n\\subset A_n \\subset C_n\\), logo, \\(P(B_n) \\leq P(A_n) \\leq P(C_n)\\). Além disso, temos que \\(B_n \\uparrow \\liminf A_n\\) e \\(C_n \\downarrow\\limsup A_n\\), logo \\(P(\\liminf A_n) = \\lim P(B_n)\\) e \\(\\lim P(C_n) = P(\\limsup A_n)\\). Agora, \\[ P(\\liminf A_n) \\leq \\liminf P(A_n) \\leq \\limsup P(A_n) \\leq P(\\limsup A_n), \\] mas \\(P(A) = P(\\liminf A_n) = P(\\limsup A_n)\\), logo se \\(P(A_n)\\) converge, temos que \\(\\lim P(A_n) = P(A)\\). 3.1 Limite superior e inferior de uma sequência de números reais. Seja \\((a_n)_{n\\geq 1}\\) uma sequência limitada de números reais, definimos \\[\\begin{align*} b_n=\\inf_{k \\geq n} a_k \\\\ c_n=\\sup_{k \\geq n} a_k \\end{align*}\\] Primeiro, note que como \\((a_n)_{n\\geq 1}\\) é limitada existem \\(m,M\\in\\mathbb R\\), tais que \\[ m \\leq a_n \\leq M, \\; \\; \\; \\forall n \\geq 1. \\] Portanto \\((b_n)_{n\\geq 1}\\) é uma sequência crescente e limitada superiormente por \\(m\\), enquanto \\((c_n)_{n\\geq 1}\\) é uma sequência decrescente e limitada inferiormente por \\(M\\). Logo, definimos: \\[\\begin{align} \\liminf a_n&amp;:=\\lim b_{n} = \\sup_{n\\geq 1} \\inf_{k\\geq n} a_k, \\label{liminfseq} \\\\ \\limsup a_n &amp;:= \\lim c_n = \\inf_{n\\geq 1} \\sup_{k\\geq n} a_k. \\label{limsupseq} \\end{align}\\] O limite dado em é chamado de limite inferior da sequência \\((a_n)\\), similarmente o limite dado em é chamado de limite superior de \\((a_n)\\). Teorema 3.3 Uma sequência \\((a_n)\\) de números reais converge para \\(a\\in\\mathbb R\\) se, e somente se, \\[\\liminf a_n= \\limsup a_n = a.\\] Prova. (\\(\\Leftarrow\\)) Suponha que \\(\\liminf a_n = \\limsup a_n = a\\). Pela definição, de \\(\\liminf\\) e \\(\\limsup\\) de uma sequência de números reais, temos que \\[ a=\\liminf a_n \\leq a_n \\leq \\limsup a_n = a, \\] o resultado segue pelo Teorema do Sanduíche. \\[0.1cm] (\\(\\Rightarrow\\)) Suponha agora que \\(a_n \\to a, \\; n \\to \\infty\\). Dado \\(\\varepsilon &gt;0\\), existe \\(n_0\\in\\mathbb N\\), tal que para \\(n \\geq n_0\\), \\[ a -\\varepsilon &lt; a_n &lt; a + \\varepsilon. \\] Daí, para \\(n \\geq n_0\\) \\[ a -\\varepsilon &lt; \\inf_{k\\geq n} a_k \\leq \\sup_{k \\geq n} &lt; a + \\varepsilon \\iff a -\\varepsilon &lt; b_n \\leq c_n &lt; a + \\varepsilon .\\] Portanto, \\(\\liminf a_n = \\limsup a_n=a\\). "],["vas.html", "Capítulo 4 Variáveis aleatórias 4.1 Definições 4.2 Função de probabilidade 4.3 Função de distribuição acumulada", " Capítulo 4 Variáveis aleatórias Grosso modo, uma variável aleatória pode ser definida como um característico numérico associada ao resultado de um experimento aleatório. Para esclarecer isso, consideremos o experimento aleatório em que uma moeda é lançada 3 vezes, e registramos os resultados em ordem. O espaço amostral para esse experimento é \\[\\Omega = \\{KKK, CKK, KCK, KKC, CCK, CKC, KCC, CCC\\}.\\] Agora, suponha que estamos interessados em saber o número de caras \\(X\\). Os possíveis valores de \\(X\\) estão resumidos na seguinte tabela \\(\\omega\\) \\(KKK\\) \\(CKK\\) \\(KCK\\) \\(KKC\\) \\(CCK\\) \\(CKC\\) \\(KCC\\) \\(CCC\\) \\(X(\\omega) = x\\) \\(0\\) \\(1\\) \\(1\\) \\(1\\) \\(2\\) \\(2\\) \\(2\\) \\(3\\) Note que para cada \\(\\omega \\in \\Omega\\), associamos um valor \\(X(\\omega) \\in \\{0,1,2,3\\}\\subset \\mathbb R\\). Se atribuímos a cada \\(\\omega \\in \\Omega\\) igual probabilidade, isto é, 1/8, então podemos calcular, por exemplo \\[\\begin{eqnarray*} P(X=1) &amp;=&amp; P(\\{\\omega\\in\\Omega: X(\\omega)=1\\}) \\\\ &amp;=&amp; P(\\{CKK, KCK, KKC\\}) \\\\ &amp;=&amp; \\frac{1}{8} + \\frac{1}{8} + \\frac{1}{8} \\\\ &amp;=&amp;\\frac{3}{8}. \\end{eqnarray*}\\] Aplicando o mesmo raciocínio para \\(x=0,2,3\\), obtemos \\(x\\) \\(0\\) \\(1\\) \\(2\\) \\(3\\) \\(P(X=x)\\) \\(1/8\\) \\(3/8\\) \\(3/8\\) \\(1/8\\) Note que \\(\\displaystyle \\sum_{x=0}^3 P(X=x) = 1\\). 4.1 Definições Uma variável aleatória (v.a.) é uma função a valores reais, definida em \\(\\Omega\\). Variáveis aleatórias são denotadas por letras maiúsculas \\(X,Y,Z,\\ldots\\) Os valores possíveis de uma variável aleatória são denotados por letras minúsculas \\(x,y,z,\\ldots\\) Uma variável aleatória é dita discreta se assumir valores em conjunto finito ou infinito enumerável. Uma variável aleatória é dita contínua se assumir valores em um intervalo de \\(\\mathbb R\\). 4.2 Função de probabilidade Seja \\(X\\) uma v.a. discreta assumindo valores no conjunto \\(\\{x_{1}, x_{2}, \\ldots\\}\\) finito ou enumerável. A função \\[p(x) = P(X=x), \\; \\; x\\in \\mathbb R,\\] é dita função de probabilidade de \\(X\\), se satisfaz as seguintes propriedades Se \\(x\\notin \\{x_{1}, x_{2}, \\ldots\\}\\), então \\(p(x)=0\\). \\(p(x_{i}) \\geq 0\\) para qualquer \\(i=1,2,\\ldots\\) \\(\\sum_{i=1}^{\\infty} p(x_{i})=1\\). Se \\(A\\subset \\mathbb R\\), então \\(\\displaystyle P(X \\in A) = \\sum_{i: x_{i}\\in A}p (x_{i})\\). 4.2.1 Exemplos 4.3 Função de distribuição acumulada Para todo \\(x\\in \\mathbb R\\), defina \\(F(x) = P(X\\leq x)\\), então \\[\\begin{eqnarray*} F(0) &amp;=&amp; P(X \\leq 0) = p(0) = 1/8, \\\\[0.2cm] F(1) &amp;=&amp; P(X \\leq 1) = p(0) + p(1) = 4/8, \\\\[0.2cm] F(2) &amp;=&amp; P(X \\leq 2) = p(0) + p(1) + p(2) =7/8, \\\\[0.2cm] F(3) &amp;=&amp; P(X \\leq 3) = p(0) + p(1) + p(2) + p(3)= 1. \\end{eqnarray*}\\] Definição 4.1 A função de distribuição (acumulada) de uma variável aleatória \\(X\\) é a função \\(F: \\mathbb R \\rightarrow \\mathbb R\\) definida por \\[\\begin{equation*} F(x) = P(X\\leq x) = P(\\{s\\in \\Omega: X(s)\\leq x\\}), \\; x\\in \\mathbb R. \\end{equation*}\\] 4.3.1 Algumas propriedades da função de distribuição \\(F\\) é uma função não-decrescente, isto é \\[\\begin{align*} \\text{Se } x &lt; y, \\text{ então } F(x) \\leq F(y). \\end{align*}\\] Se \\(X\\) é uma v.a. discreta, então \\[\\begin{align*} F(x) = \\sum_{y \\leq x} p(y). \\end{align*}\\] \\(P(X=x) = P(X\\leq x) - P(X &lt; x) = F(x) - F(x^{-})\\) (salto de \\(F\\) no ponto \\(x\\)). Para \\(a,b\\in\\mathbb R\\) com \\(a &lt; b,\\) \\(P(a&lt; X \\leq b) = F(b) - F(a)\\). 4.3.2 Propriedades fundamentais da função de distribuição (F1) \\(F\\) é não decrescente: \\(x&lt;y \\Rightarrow F(x) \\leq F(y)\\). (F2) \\(F\\) é contínua à direita: \\(x_n\\downarrow x \\Rightarrow F(x_n) \\downarrow F(x)\\). (F3) \\(\\lim_{n\\to \\infty}F(n)=1\\) e \\(\\lim_{n\\to-\\infty} F(n) = 0\\). Qualquer função \\(F: \\mathbb R \\rightarrow \\mathbb R\\) satisfazendo as condições (F1), (F2) e (F3) é função de distribuição de alguma variável aleatória. "],["valoresperado.html", "Capítulo 5 Valor esperado 5.1 Motivação 5.2 Funções de variáveis aleatórias 5.3 Variância 5.4 Independência de variáveis aleatórias", " Capítulo 5 Valor esperado Seja \\(X\\) uma variável aleatória discreta com função de probabiliade \\(p(\\cdot)\\) e assumindo valores em \\(\\{x_1, x_2,\\ldots\\}\\). A esperança matemática, média ou valor esperado de \\(X\\) é definida por \\[\\begin{align*} E(X) = \\sum_{i=1}^\\infty x_i\\, p(x_i). \\end{align*}\\] Observação. Note que a esperança de \\(X\\), é uma média ponderada dos valores de \\(x\\), em que cada valor de \\(x\\) é ponderado por sua probabilidade correspondente. Voltando ao exemplo do lançamento da moeda 3 vezes e, definindo \\(X\\) como o número de caras observadas, temos que \\[ E(X) = 0 \\times \\frac{1}{8} + 1 \\times \\frac{3}{8} + 2 \\times \\frac{3}{8} + 3 \\times \\frac{1}{8} = 1,5. \\] Algumas observações sobre a o valor esperado: O valor esperado pode não ser um dos valores possíveis de \\(X\\), Não se deve arredondar \\(E(X)\\) para um número inteiro. Exemplo 5.1 Seja \\(X:\\) Resultado observado no lançamento de um dado honesto. Determine o valor esperado de \\(X\\). Solução. A função de probabilidade de \\(X\\) é \\[ p(x) = \\frac{1}{x}, \\; x=1,\\ldots,6. \\] Logo \\[ E(X) = \\sum_{x=1}^6 x \\frac{1}{6} = \\frac{1}{6}\\sum_{x=1}^6 x= \\frac{6\\times 7}{6 \\times 2} = \\frac{7}{2}. \\] Exemplo 5.2 Um lote contém 3 itens defeituoso e 5 não defeituosos. Retiram-se 2 itens do lote em sequência, sem reposição. Determine o número esperado de itens defeituosos retirados. Solução. Vamos determinar, primeiro, a função de probabilidade de \\(X:\\) número de itens defeituosos retirados. Para isso, seja \\(D_i\\): o i-ésimo item retirado é defeituoso e \\(B_i\\): o i-ésimo item retirado é bom. Logo: \\[\\begin{align*} p(0)=P(X=0) &amp;= P(B_1\\cap B_2) = P(B_1)P(B_2|B_1) = \\frac{5}{8} \\frac{4}{7} = \\frac{20}{56},\\\\ p(1)=P(X=1) &amp;= P(B_1 \\cap D_2) + P(D_1 \\cap B_2) = \\frac{5}{8} \\frac{3}{7} + \\frac{3}{8} \\frac{5}{7} = \\frac{15}{56} + \\frac{15}{56} = \\frac{30}{56},\\\\ p(2)=P(X=2) &amp;= P(D_1 \\cap D_2) =P(D_1)P(D_2|D_1) = \\frac{3}{8} \\frac{2}{7} = \\frac{6}{56}. \\end{align*}\\] Portanto, \\[ E(X) = 0\\times \\frac{20}{56} + 1 \\times \\frac{30}{56} + 2 \\times \\frac{6}{56} = \\frac{3}{4}. \\] 5.1 Motivação Suponha uma variável aleatória discreta \\(X\\) assumindo valores no conjunto \\(\\{x_1,x_2,\\ldots\\}\\). Essa variável aleatória é o resultado de um experimento aleatório. Suponha que repetimos o experimento \\(N\\) vezes. Seja \\(N_i\\) (\\(i=1,2,\\ldots\\)) o número de vezes que observamos o valor \\(x_i\\). Pela interpretação frequentista da probabilidade, para \\(N\\) suficientemente grande temos que \\[ p(x_i) \\approx \\frac{N_i}{N}, \\] e a média aritmética dos valores observados de \\(X\\) é \\[ \\bar{X} = \\sum_{i=1}^\\infty \\frac{N_i\\, x_i}{N} \\approx \\sum_{i=1}^\\infty p(x_i) x_i = E(X) \\] Essas aproximações são adequadamente justificadas pela . 5.2 Funções de variáveis aleatórias Se \\(X\\) é uma variável aleatória e \\(g\\) uma função a valores reais, então \\(Y=g(X)\\), também é uma variável aleatória. Proposição 5.1 Seja \\(X\\) uma v.a. discreta com função de probabilidade \\(p(x)\\). Para qualquer função \\(g\\) a valores reais, \\[ E[g(X)] = \\sum_{x: p(x)&gt;0} g(x) p(x). \\] Observação. Note que esse resultado permite o cálculo da esperança de \\(Y=g(X)\\), mesmo que se desconheça a distribuição de probabilidade de \\(Y\\). Exemplo 5.3 Seja \\(X\\): Número de caras nos três lançamentos de uma moeda justa, então a função de probabilidade de \\(X\\) é \\(x\\) \\(0\\) \\(1\\) \\(2\\) \\(3\\) \\(p(x)\\) \\(1/8\\) \\(3/8\\) \\(3/8\\) \\(1/8\\) E seja \\(Y=X^2\\), logo, \\[\\begin{align*} E(X^2)=E(Y) = \\sum_{x=0}^3 x^2 p(x) = 0^2\\times \\frac{1}{8} + 1^2 \\times \\frac{3}{8} + 2^2 \\times \\frac{3}{8} + 3^2 \\times \\frac{1}{8} = 3. \\end{align*}\\] Observação. Em geral \\(E(X^2) \\neq [E(X)]^2\\) Exemplo 5.4 Suponha que uma moeda é lançada 3 vezes, e que ganhamos ou perdemos R$1 conforme o número de caras seja par ou ímpar. Qual o valor esperado do nosso lucro? Solução. Seja \\(X\\): Número de caras \\(\\Rightarrow\\) \\(Y=(-1)^X\\): Lucro obtido no jogo. Logo, \\[ E(Y)=E[(-1)^X]=(-1)^0\\times \\frac{1}{8} + (-1)^1 \\times \\frac{3}{8} + (-1)^2 \\times \\frac{3}{8} + (-1)^3 \\times \\frac{1}{8}=0. \\] Corolário 5.1 Se \\(a\\) e \\(b\\) são constantes, então Se \\(a\\) e \\(b\\) são constantes, então \\[ E(aX + b) = a E(X) + b \\] Exemplo 5.5 Uma moeda é lançada 3 vezes, e ganhamos R$5 a cada cara obtida e perdemos R$2 a cada coroa. Qual o valor esperado do nosso lucro? Solução. \\(X\\): Número de caras, \\(3-X\\): Número de coroas \\(\\Rightarrow\\) \\(Y=5X - 2(3-X) =7X - 6\\): Lucro. \\[ E(Y)=E(7X-6) = 7E(X) - 6= 7 \\times \\frac{3}{2} - 6 = \\frac{9}{2}. \\] 5.3 Variância Definição 5.1 A variância de uma v.a. \\(X\\) com esperança \\(\\mu\\) é definida por \\[ \\sigma^2=Var(X)=E[(X-\\mu)^2]. \\] Definição 5.2 O desvio padrão de \\(X\\) é definido por \\(\\sigma=DP(X)= \\sqrt{Var (X)}\\). Exemplo 5.6 Seja \\(X\\) o resultado obtido no lançamento de um dado justo, assim \\[ p(i) = 1/6, \\; \\; i =1,2,3,4,5,6. \\] Logo, \\(E(X) = \\displaystyle\\sum_{i=1}^6 i \\, p(i) = \\frac{1}{6}\\sum_{i=1}^6 i =\\frac{1}{6}\\frac{(6)(7)}{2} = \\frac{7}{2}\\). \\[\\begin{align*} \\sigma^2 &amp;= \\sum_{i=1}^6 (i-E(X))^2 p(i)\\\\ &amp;= \\frac{1}{6}\\left[\\left(1-\\frac{7}{2}\\right)^2 + \\left(2-\\frac{7}{2}\\right)^2 + \\cdots + \\left(6-\\frac{7}{2}\\right)^2\\right] \\\\ &amp;=\\frac{35}{12}. \\end{align*}\\] e, \\[ \\sigma = DP(X) = \\sqrt{\\frac{35}{12}} \\approx 1,70. \\] Proposição 5.2 \\(Var(X) = E(X^2) - [E(X)]^2\\) Prova. Seja \\(\\mu = E(X)\\), \\[\\begin{align*} (X-\\mu)^2 = X^2 - 2X\\mu + \\mu^2, \\end{align*}\\] Logo, \\[\\begin{align*} Var(X) = E[(X-\\mu)^2] &amp;= E(X^2) - 2\\mu^2 + \\mu^2 \\\\ &amp;=E(X^2) - \\mu^2 = E(X^2) - [E(X)]^2. \\end{align*}\\] Proposição 5.3 Se \\(a\\) e \\(b\\) são constantes, então \\[ Var(aX+b) = a^2 Var(X) \\] Corolário 5.2 Seja \\(X\\) uma v.a. tal que \\(E(X) = \\mu\\) e \\(Var(X) = \\sigma^2 &gt;0\\). Defina \\(Z=\\frac{X-\\mu}{\\sigma}\\). Então \\[ E(Z) = 0 \\text{ e } Var(Z) = 1. \\] 5.4 Independência de variáveis aleatórias Definição 5.3 As variáveis aleatórias \\(X_1, \\ldots, X_n\\) são independentes se, para qualquer escolha de conjuntos \\(A_1,\\ldots,A_n \\subset \\mathbb R\\), tem-se que \\[ P(X_1 \\in A_1, \\ldots, X_n\\in A_n) = \\prod_{i=1}^n P(X_i \\in A_i). \\] Definição 5.4 (caso discreto) No caso de variáveis aleatórios discretas, a definição anterior é equivalente à condição de que, para qualquer escolha de \\(x_1,\\ldots,x_n \\in \\mathbb R\\), tem-se que \\[ P(X_1 = x_1, \\ldots, X_n = x_n) = \\prod_{i=1}^n P(X_i=x_i). \\] Proposição 5.4 (Linearidade da esperança) Para quaisquer variáveis aleatórias \\(X_1,\\ldots,X_n\\), temos: \\[ E(X_1 + \\ldots + X_n) = E(X_1) + \\cdots + E(X_n) \\] Proposição 5.5 (Linearidade da variância) Sejam \\(X_1,\\ldots,X_n\\) variáveis aleatórias independentes, temos: \\[ Var(X_1 + \\ldots + X_n) = Var(X_1) + \\cdots + Var(X_n) \\] "],["fgm.html", "Capítulo 6 Função geradora de momentos 6.1 Momentos 6.2 Função geradora de momentos 6.3 Exemplos de \\(M_X(t)\\) para algumas distribuições comuns", " Capítulo 6 Função geradora de momentos 6.1 Momentos Definição 6.1 Seja \\(X\\) uma variável aleaória. Para \\(n \\geq 1\\) inteiro, definimos o n-ésimo momento de \\(X\\) como \\[ \\mu_{(n)} = E(X^n). \\] Observação. No caso em que \\(X\\) é uma v.a. discreta com função de probabilidade \\(p(x)\\), temos que \\[ \\mu_{(n)} = \\sum_{x: p(x)&gt;0} x^n p(x) \\] Observação. Note que para \\(n=1\\), temos que \\(\\mu_{(1)}\\) corresponde à média da v.a. \\(X\\) e, que a variância de \\(X\\) é uma função do primeiro e segundo momento, isto é, \\(Var(X) = \\mu_{(2)} - (\\mu_{(1)})^2\\). 6.2 Função geradora de momentos Definição 6.2 Seja \\(X\\) uma variável aleatória. Definimos a função geradora de momentos de \\(X\\) como: \\[ M_{X}(t) = E(e^{tX}), \\; t \\in \\mathbb{R}. \\] Proposição 6.1 Seja \\(X\\) uma variável aleatória, temos que \\[ M_{X}^{(n)}(t)|_{t=0} = E(X^n) \\] Prova. Procedemos por indução em \\(n\\) \\[\\begin{align*} M_X^{\\prime} (t)=\\frac{d}{dt}M_X(t) &amp;= \\frac{d}{dt}E(e^{tX})\\\\ &amp;=E(\\frac{d}{dt} e^{tX})\\\\ &amp;=E(Xe^{tX}) \\end{align*}\\] Assuma que \\(M^{(n-1)}(t)=\\frac{d^{n-1}}{dt^{n-1}} M_X(t) = E(X^{n-1} e^{tX})\\). Logo \\[\\begin{align*} M^{(n)}(t) &amp;= \\frac{d}{dt} M^{(n-1)}(t)\\\\ &amp;=\\frac{d}{dt}E(X^{n-1} e^{tX})\\\\ &amp;=E(\\frac{d}{dt} X^{n-1} e^{tX})\\\\ &amp;=E(X^n e^{tX}) \\end{align*}\\] Para finalizar a prova, basta avaliar \\(M^{(n)}_X(t)\\) em \\(t=0\\). 6.3 Exemplos de \\(M_X(t)\\) para algumas distribuições comuns Exemplo 6.1 (Bernoulli) Seja \\(X\\) uma v.a. e \\(0&lt;p&lt;1\\), tal que \\[p(0) = 1-p, \\; \\; p(1) = p.\\] Logo, para \\(t\\in\\mathbb R\\), a função geradora de momentos é dada por \\[\\begin{align*} M_{X}(t) &amp;= E(e^{tX}) \\\\ &amp;= e^{t\\cdot 0} \\times p(0) + e^{t\\cdot 1} \\times p(1) \\\\ &amp;= (1-p) + p e^{t}, \\; \\end{align*}\\] Exemplo 6.2 (Geométrica) Seja \\(X\\) uma v.a., cuja função de probabilidade é \\[ p(x) = (1-p)^{x-1}p, \\; x=1,2,\\ldots \\] Logo, para \\(t &lt; \\ln\\left(\\frac{1}{1-p}\\right)\\), a função geradora de momentos de \\(X\\) é \\[\\begin{align*} M_{X}(t) &amp;= E(e^{tX})\\\\ &amp;=\\sum_{x=1}^\\infty e^{tx} (1-p)^{x-1}p\\\\ &amp;=\\frac{p}{1-p} \\sum_{x=1}^\\infty e^{tx} (1-p)^{x}\\\\ &amp;=\\frac{p}{1-p} \\sum_{x=1}^\\infty [e^{t} (1-p)]^{x} \\\\ &amp;=\\frac{p}{1-p}\\cdot \\frac{e^{t} (1-p)}{1- e^{t} (1-p)}\\\\ &amp;=\\frac{p e^{t}}{1- e^{t} (1-p)} \\end{align*}\\] Exemplo 6.3 (Poisson) Seja \\(X\\) uma v.a. cuja função de probabilidade é \\[ p(x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}, \\; x=0,1,\\ldots \\] onde \\(\\lambda &gt;0\\) constante. Logo, para \\(t\\in\\mathbb R\\), a função geradora de momentos é dada por \\[\\begin{align*} M_X(t) &amp;= E(e^{tX})\\\\ &amp;=\\sum_{x=0}^\\infty e^{tx} \\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\ &amp;= e^{-\\lambda}\\sum_{x=0}^\\infty \\frac{(\\lambda e^t)^x}{x!}\\\\ &amp;=e^{-\\lambda} e^{\\lambda e^t}\\\\ &amp;=e^{-\\lambda(1-e^t)} \\end{align*}\\] Proposição 6.2 Sejam \\(a,b\\) constantes e \\(Y=aX+b\\), então \\[ M_Y(t) = e^{tb} M_X(ta) \\] Prova. \\[\\begin{align*} M_Y(t) &amp;= E(e^{t(aX+b)}) \\\\ &amp;=E(e^{(ta)X}e^{tb})\\\\ &amp;=e^{tb}E(e^{(ta)X})\\\\ &amp;=e^{tb}M_X(ta) \\end{align*}\\] "],["modelos-discretos.html", "Capítulo 7 Modelos de distribuições discretas 7.1 Distribuição Uniforme Discreta 7.2 Distribuição de Bernoulli 7.3 Distribuição Binomial 7.4 Distribuição Geométrica 7.5 Distribuição Binomial Negativa (Pascal)", " Capítulo 7 Modelos de distribuições discretas Neste capítulo estudaremos vários modelos de distribuições de variáveis aleatórias discretas mais comuns. Ao longo do capítulo usaremos a notação \\(X\\sim\\mathcal D\\) para dizer que \\(X\\) “tem distribuição \\(\\mathcal D\\),” onde \\(\\mathcal D\\) é uma certa distribuição de probabilidade. 7.1 Distribuição Uniforme Discreta Definição 7.1 Dizemos que a v.a. \\(X\\) tem distribuição uniforme discreta sobre o conjunto \\(\\{x_1,\\ldots,x_n\\}\\subset \\mathbb R\\) se tem função de probabilidade dada por \\[ p(x_i) = \\frac{1}{n}, \\; i =1,2,\\ldots,n. \\] \\(X\\) é um elemento escolhido ao acaso no conjunto \\(\\{x_1,\\ldots,x_n\\}\\). Notação: \\(X\\sim\\) Uniforme discreta\\(\\{x_1,\\ldots,x_n\\}\\). Exemplo 7.1 Seja \\(X\\): Número observado no lançamento de um dado honesto, temos que \\[ p(i)=\\frac{1}{6}, \\; i=1,2,3,4,5,6. \\] Proposição 7.1 Seja \\(X\\sim\\) Uniforme discreta\\(\\{1,\\ldots,n\\}\\), então: \\[\\begin{align*} E(X) = \\frac{n+1}{2} \\text{ e } Var(X) = \\frac{(n-1)(n+1)}{12} \\end{align*}\\] Prova. \\[\\begin{align*} E(X) &amp;= \\frac{1}{n} \\sum_{i=1}^n i = \\frac{1}{n} \\frac{n(n+1)}{2} = \\frac{n+1}{2} \\\\ E(X^2) &amp;= \\frac{1}{n} \\sum_{i=1}^n i^2 = \\frac{1}{n} \\frac{n(n+1)(2n+1)}{6} \\\\ Var(X) &amp;= E(X^2) - [E(X)]^2 = \\frac{(n-1)(n+1)}{12} \\end{align*}\\] 7.2 Distribuição de Bernoulli Definição 7.2 (Ensaio de Bernoulli) Um ensaio de Bernoulli é um experimento com somente dois resultados possíveis: sucesso ou fracasso, de modo que a probabilidade de sucesso é igual a \\(p\\in[0,1]\\). Exemplo 7.2 Exemplos de ensaios de Bernoulli são: Lançamento de uma moeda: cara (sucesso) ou coroa (fracasso). Avaliação de um item: item bom (sucesso) ou item defeituoso (fracasso). Resposta de um munícipe sobre o favorecimento a um projeto de lei: sim (sucesso) ou não (fracasso). Dado um evento \\(A \\subset \\Omega\\) com espaço amostral \\(\\Omega\\) associado a um certo experimento aleatório, podemos definir um ensaio de Bernoulli, da seguinte maneira: dizemos que ocorre sucesso, se \\(A\\) ocorre, e dizemos que ocorre fracasso se, \\(A^c\\) ocorre. Por exemplo, considere o lançamento de um dado honesto e, defina \\(A=\\{6\\}\\): observar a face 5, logo \\(A^c=\\{1,2,3,4,5\\}\\). No exemplo, a probabilidade de sucesso é \\(p=1/6\\). Considere um ensaio de Bernoulli, e defina a v.a. \\(X \\in \\{0,1\\}\\) com distribuição de probabilidade: \\[P(X=1)=p \\text{ e } P(X=0)=1-p,\\] de modo que \\(\\{X=1\\}\\) corresponde ao evento em que ocorreu sucesso e o evento \\(\\{X=0\\}\\) corresponde ao evento em que ocorreu fracasso. Dizemos que \\(X\\) é a da ocorrência de sucesso em um ensaio de Bernoulli. No exemplo do lançamento do dado, temos: \\[ X(\\omega)=\\begin{cases} 1, &amp; \\omega \\in A =\\{6\\}, \\\\ 0, &amp; \\omega \\in A^c=\\{1,2,3,4,5\\} \\end{cases} \\] Definição 7.3 A variável aleatória \\(X\\) definida como a indicadora da ocorrência de sucesso em um ensaio de Bernoulli tem uma distribuição de Bernoulli com parâmetro \\(p\\), cuja função de probabilidade de \\(X\\) é dada por: \\[ p(x) = p^x (1-p)^{1-x}, \\; x=0,1. \\] Notação: \\(X \\sim\\) Bernoulli(\\(p\\)), onde \\(p\\) é chamado de parâmetro de sucesso. Exemplo 7.3 A continuação apresentamos alguns exemplos de variáveis aleatórias com distribuição de Bernoulli: Uma pessoa é selecionada ao acaso entre os moradores de uma cidade, e pergunta-se a ela se concorda com um projeto municipal. As respostas possíveis são SIM (sucesso) ou NÃO (fracasso). Defina: \\[ X=\\begin{cases} 1, &amp; \\text{se a pessoa responde SIM}, \\\\ 0, &amp; \\text{se a pessoa responde NÃO} \\end{cases} \\] No lançamento de uma moeda. Defina: \\[ X=\\begin{cases} 1, &amp; \\text{se sair cara}, \\\\ 0, &amp; \\text{se sair coroa} \\end{cases} \\] Na inspecção de um item de um lote. Defina: \\[ X=\\begin{cases} 1, &amp; \\text{se o item for defeituoso}, \\\\ 0, &amp; \\text{se o item não for defeituoso} \\end{cases} \\] Proposição 7.2 Seja \\(X\\sim\\) Bernoulli(\\(p\\)), temos que \\[ E(X) = p \\text{ e } Var(X) = p(1-p) \\] Prova. \\[\\begin{align*} E(X) &amp;= \\sum_{x=0}^1 x\\, p^x (1-p)^{1-x} = p\\\\ E(X^2) &amp;= \\sum_{x=0}^1 x^2 \\, p^x (1-p)^{1-x} = p \\\\ Var(X) &amp;= E(X^2) - [E(X)]^2 = p-p^2= p(1-p) \\end{align*}\\] 7.3 Distribuição Binomial A distribuição binomial, surge da realização sucessiva de \\(n\\geq 1\\) ensaios independentes de Bernoulli. Por exemplo, considere o experimento de lançar uma moeda honestas 10 vezes esse experimento tem as seguintes características: O experimento lançar uma moeda é um ensaio de Bernoulli. O experimento é realizado 3 vezes. Todos os 3 ensaios são idênticos e independentes. A probabilidade \\(p=1/2\\) de obter uma cara, é constante em todos os ensaios. Nesse experimento, definimos a variável aleatória, \\(X\\), definida como o número de caras obtidas nos 3 lançamentos. Sob as condições do experimento podemos determinar a função de probabilidade de \\(X\\). Podemos determinar que a função de probabilidade de \\(X\\) é: \\[ p(x) = \\binom{3}{x}(1/2)^x(1/2)^{n-x}, \\; x=0,1,2,3. \\] Explicação: \\(\\binom{3}{x}\\): corresponde ao número de maneiras de escolher 2 caras. \\((1/2)^{x}\\): corresponde à probabilidade de observar \\(x\\) caras nos \\(n\\) lançamentos (multiplicamos as probabilidades pois os ensaios são independentes). \\((1/2)^{n-x}\\): corresponde à probabilidade de observar \\(n-x\\) coroas nos \\(n\\) lançamentos (multiplicamos as probabilidades pois os ensaios são independentes). Repare que se \\(X\\sim\\) Binomial(\\(n,p\\)), então \\(X= X_1 + \\ldots + X_n\\), onde \\(X_1,\\ldots,X_n \\overset{iid}{\\sim}\\) Bernoulli(\\(p\\)). De modo que \\(X_i = 1\\) se o \\(i\\)-ésimo ensaio for sucesso ou \\(X_i=0\\) se o \\(i\\)-ésimo ensaio for fracasso. Definição 7.4 Considere \\(n\\geq 1\\) ensaios independentes de Bernoulli e seja \\(p\\) a probabilidade de sucesso em cada ensaio. Logo, a variável aleatória \\(X\\) definida como o número de sucessos nos \\(n\\) ensaios tem uma distribuição binomial de parâmetros \\(n\\) e \\(p\\), cuja função de probabilidade é dada por \\[ p(x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\, x=0,1,\\ldots,n. \\] Notação: \\(X\\sim\\) Binomial(\\(n,p\\)). Observação. Note que pelo Teorema Binomial \\(p(x)\\) é de fato uma função de probabilidade. Com efeito: \\[ \\sum_{x=0}^n \\binom{n}{x} p^x (1-p)^{n-x} = (p+(1-p))^n = 1. \\] Proposição 7.3 Seja \\(X\\sim\\)Binomial(\\(n,p\\)), temos que \\[ E(X) = np \\text{ e } Var(X) = np(1-p) \\] Prova. Usamos o fato que \\(X=\\sum_{i=1}^n X_i\\), em que cada \\(X_1, \\ldots, X_n \\sim\\) Bernoulli(\\(p\\)) independentes. Logo \\[\\begin{align*} E(X) = \\sum_{i=1}^n E(X_i) = np, \\\\ Var(X) = \\sum_{i=1}^n Var(X_i) = np(1-p). \\end{align*}\\] Exemplo 7.4 Suponha que 60% da população de uma cidade é a favor de um projeto proposto pelo prefeito. Seleciona-se uma amostra aleatória de 15 pessoas. Qual a probabilidade de que a amostra contenha no máximo duas pessoas favoráveis ao projeto? Quais são o valor esperado e variância do número de pessoas a favor do projeto na amostra? Solução. Seja \\(X\\) o número de pessoas favoráveis ao projeto na amostra. Então, \\(X\\sim\\) Binomial(15,0.6). \\(P(X\\leq 2) = \\binom{15}{0} (0.6)^0 (0.4)^{15} + \\binom{15}{1} (0.6)^1 (0.4)^{14} + \\binom{15}{0} (0.6)^2 (0.4)^{13}\\) \\(E(X) = 15 \\times 0.6 = 9\\) e \\(Var(X)= 15 \\times 0.6 \\times 0.4 =3.6\\). Proposição 7.4 Seja \\(X\\sim\\) Binomial(\\(n,p\\)), então, à medida que \\(x\\) varia de 0 a \\(n\\), \\(p(x)\\) primeiro cresce e depois decresce, atingindo seu valor máximo quando \\(x=\\lfloor (n+1)p \\rfloor\\): maior inteiro menor ou igual que \\((n+1)p\\). 7.4 Distribuição Geométrica Definição 7.5 Consideremos um ensaio de Bernoulli com probabilidade de sucesso \\(p\\) e realizações sucessivas e independentes desse experimento até que ocorra o primeiro sucesso. A variável aleatória definida como o número de ensaios necessários até o primeiro sucesso tem uma distribuição geométrica de parâmetro \\(p\\), cuja função de probabilidade é dada por \\[ p(x) = (1-p)^{x-1}p, \\; x=1,2,3,\\ldots \\] Notação: \\(X\\sim\\) Geom(\\(p\\)) Observação. Pela série geométrica vemos que \\(p(x)\\) é de fato uma função de probabilidade. Com efeito: \\[ \\sum_{x=1}^\\infty (1-p)^{x-1}p = p\\sum_{x=0} (1-p)^x = p \\times \\frac{1}{1-(1-p)} =1. \\] Proposição 7.5 Seja \\(X\\sim\\) Geom(\\(p\\)), temos que \\[ E(X) = \\frac{1}{p} \\text{ e } Var(X) = \\frac{1-p}{p^2} \\] Prova. Seja \\(q=1-p\\), logo \\[\\begin{align*} E(X) &amp;= \\sum_{x=1}^\\infty x q^{x-1} p \\\\ &amp;= \\sum_{x=1}^\\infty (x-1 + 1) q^{x-1} p \\\\ &amp;= \\sum_{x=1}^\\infty (x-1) q^{x-1} p + \\sum_{x=1}^\\infty q^{x-1} p \\\\ &amp;= q\\sum_{y=0}^\\infty y q^{y-1} p + 1 \\\\ &amp;= q E(X) + 1. \\end{align*}\\] Daí, \\((1-q) E(X)= 1 \\Rightarrow E(X) = \\frac{1}{p}\\). \\[\\begin{align*} E(X^2) &amp;= \\sum_{x=1}^\\infty x^2 q^{x-1}p \\\\ &amp;= \\sum_{x=1}^\\infty (x-1 + 1)^2 q^{x-1}p \\\\ &amp;= \\sum_{x=1}^\\infty (x-1)^2 q^{x-1}p + 2 \\sum_{x=1}^\\infty (x-1) q^{x-1}p + \\sum_{x=1}^\\infty q^{x-1}p \\\\ &amp;= q\\sum_{y=0}^\\infty y^2 q^{y-1} p + 2q \\sum_{y=0}^\\infty yq^{y-1}p + 1 \\\\ &amp;=qE(X^2) + 2q E(X) + 1. \\end{align*}\\] Daí, \\(pE(X^2) = \\frac{2q}{p} +1 \\Rightarrow E(X^2) = \\frac{2q+p}{p^2} = \\frac{q+1}{p^2}\\). Portanto, \\[ Var(X) = E(X^2) - [E(X)]^2= \\frac{q+1}{p^2} - \\frac{1}{p^2} = \\frac{q}{p^2} = \\frac{1-p}{p^2}. \\] Exemplo 7.5 Um dado honesto é lançado repetidamente, de modo independente, até que se obtenha a face 6. Determine: a probabilidade de que sejam necessários exatamente 5 lançamentos. a probabilidade de que sejam necessários pelo menos 4 lançamentos. a esperança e variância do número de lançamentos feitos. Solução. Seja \\(X:\\) Número de lançamentos feitos até obter a face 6. Então, \\(X\\sim\\) Geométrica(\\(p = 1/6\\)). \\(P(X=5)= \\left(\\frac{1}{6}\\right)\\left(\\frac{5}{6}\\right)^4 = \\frac{5^4}{6^5} \\approx 0.0804\\). \\(P(X\\geq 4) = \\sum_{x=4}^\\infty \\left(\\frac{1}{6}\\right)\\left(\\frac{5}{6}\\right)^{x-1} = \\left(\\frac{5}{6}\\right)^3 \\approx 0.5787.\\) \\(E(X)=\\frac{1}{1/6} = 6\\) e \\(Var(X)=\\frac{5/6}{(1/6)^2} = 30\\). 7.5 Distribuição Binomial Negativa (Pascal) Definição 7.6 Consideremos um ensaio de Bernoulli com probabilidade de sucesso \\(p\\) e realizações sucessivas e independentes desse experimento até que ocorra o \\(r\\)-ésimo sucesso. A variável aleatória definida como o número de ensaios necessários até o \\(r\\)-ésimo sucesso tem uma distribuição binomial negativa de parâmetros \\(r\\) e \\(p\\), cuja função de probabilidade é dada por \\[ p(x) = \\binom{x-1}{r-1} p^r(1-p)^{x-r}, \\; x=r,r+1,\\ldots \\] Notação: \\(X \\sim\\) BN(\\(r,p\\)) Observação. Seja \\(y=x-r\\), \\(x=r,r+1\\ldots\\) , \\[\\begin{align*} \\binom{x-1}{r-1} &amp;= \\binom{y+r-1}{r-1} \\\\ &amp;=\\frac{(y+r-1)\\cdots r (r-1)!}{(r-1)! y!}\\\\ &amp;=\\frac{(y+r-1)\\cdots r}{y!} \\\\ &amp;=(-1)^y \\frac{(-r)\\cdots (-y-r+1)}{y!}\\\\ &amp;=(-1)^y\\binom{-r}{y} \\end{align*}\\] Daí, o nome de binomial negativa. Da observação anterior se \\(X\\sim\\) BN(\\(r,p\\)), então pode-se escrever a função de probabilidade de \\(X\\) como \\[ p(x) = (-1)^{x-r} \\binom{-r}{x-r}p^rq^{x-r}, \\; x=r,r+1,\\ldots \\] onde \\(q=1-p\\). Observação. Da série binomial \\[ (1+x)^\\beta = \\sum_{y=0}^\\infty \\binom{\\beta}{y} x^y, \\] temos que \\[ p^{-r} = (1-q)^{-r} = \\sum_{y=0}^\\infty \\binom{-r}{y} (-q)^y, \\] Agora, é facil mostrar que \\(p(x)\\) é de fato uma função de probabilidade \\[\\begin{align*} \\sum_{x=r}^\\infty (-1)^{x-r} \\binom{-r}{x-r}p^rq^{x-r} &amp;=\\sum_{y=0}^\\infty (-1)^y \\binom{-r}{y}p^rq^y\\\\ &amp;= \\sum_{y=0}^\\infty \\binom{-r}{y} (-q)^y p^r = p^{-r} p^r = 1. \\end{align*}\\] Observação. Repare que se \\(X\\sim\\) BN(\\(r,p\\)), então \\(X=\\sum_{i=1}^r X_i\\), tal que \\(X_1,\\ldots,X_r \\overset{iid}{\\sim}\\) Geom(\\(p\\)). A interpretação é a seguinte: \\(X_1\\) representa o número de ensaios até o primeiro sucesso, \\(X_2\\) representa o número de ensaios necessários depois do primeiro sucesso para obter o segundo sucesso e assim por diante. Proposição 7.6 Seja \\(X\\sim\\) BN(\\(r,p\\)), temos que \\[ E(X) = \\frac{r}{p} \\text{ e } Var(X) = \\frac{r(1-p)}{p^2} \\] Prova. \\(X=\\sum_{i=1}^r X_i\\), tal que \\(X_1,\\ldots,X_r\\overset{iid}{\\sim}\\) Geom(\\(p\\)), logo \\[\\begin{align*} E(X) &amp;= \\sum_{i=1}^r E(X_i) = \\frac{r}{p}, \\\\ Var(X) &amp;= \\sum_{i=1}^r Var(X_i) = \\frac{r(1-p)}{p^2}. \\end{align*}\\] Exemplo 7.6 Um dado honesto é lançado repetidamente, de modo independente, até que a face 6 seja obtida 4 vezes. Qual a probabilidade de que sejam necessários exatamente 10 lançamentos? Solução. \\(X:\\) Número de lançamentos necessários até que a face 6 seja obtida 4 vezes. Então \\(X\\sim\\) Binomial Negativa(\\(r=4,p=1/6\\)). Logo \\[ P(X=10) = p(10) = \\binom{10-1}{4-1} (1/6)^4(5/6)^{6} = \\binom{9}{3} (1/6)^4(5/6)^{6} \\approx 0,0217. \\] "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
