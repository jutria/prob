[["index.html", "Probabilidade Capítulo 1 Introdução", " Probabilidade Prof. Dr. Jaime Utria 2022-05-19 Capítulo 1 Introdução Este material contém os conceitos básicos para um primeiro curso em Teoria das Probabilidades no nível universitário. O Gitbook visa server de apoio para a disciplina de Probabilidade I do curso de Estatística da Universidade Federal Fluminense. "],["esp-prob.html", "Capítulo 2 Espaços de Probabilidade 2.1 Espaço amostral 2.2 Eventos 2.3 Probabilidade 2.4 Probabilidade Condicional", " Capítulo 2 Espaços de Probabilidade Neste capítulo formulamos um modelo matemático (ou modelo probabilístico) para um experimento aleatório. Começamos definindo o que é um experimento aleatório. Definição 2.1 Um experimento é aleatório se, quando repetido sob as mesmas condições nem sempre gera os mesmos resultados, isto é, não conseguimos prever o resultado do experimento até que ele seja realizado. Exemplos de experimentos aleatorios Lançar um dado e registrar a face superior. Contar o número de pessoas que chegam numa agência bancária durante um período de tempo dado. Medir o tempo de vida útil, em horas, de uma lâmpada. A seguir descreveremos o modelo probabilistíco para um experimento aleatório. 2.1 Espaço amostral Definição 2.2 (Espaço amostral) O conjunto de todos os resultados possíveis de um experimento aleatório é chamado de espaço amostral, e o denotamos por \\(\\Omega\\). A continuação apresentamos um espaço amostral adequado para cada um dos experientos descritos nos exemplos acima: \\(\\Omega = \\{1,2,3,4,5,6\\}\\). \\(\\Omega = \\{0,1,2,3,\\ldots\\}\\) \\(\\Omega = \\{x \\in \\mathbb R : 0\\leq x &lt; \\infty \\}.\\) Note que nos exemplos (i) e (ii), \\(\\Omega\\) é um conjunto no máximo enumerável, quando isso acontece dizemos que \\(\\Omega\\) é um espaço amostral discreto. No entanto, no exemplo (iii) temos um conjunto infinito não-enumerável, nesse caso dizemos que \\(\\Omega\\) é um espaço amostral contínuo. 2.2 Eventos Definição 2.3 (Evento) Informalmente, um evento é qualquer subconjunto \\(A\\subset \\Omega\\). 2.2.1 Relaçoes e operações entre eventos Seja \\(A\\) um evento. Se \\(\\omega\\) é um elemento em \\(\\Omega\\), tal que \\(\\omega \\in A\\), dizemos que \\(A\\) ocorre. Se \\(A=\\{\\omega\\}\\) para algum \\(\\omega \\in \\Omega\\), dizemos que \\(A\\) é um evento elementar. Dados dois eventos \\(A\\) e \\(B\\), dizemos que \\(A\\subset B\\), se \\(\\omega \\in A\\Rightarrow \\omega \\in B\\). Em palavras a ocorrência de \\(A\\) implica a ocorrência de \\(B\\). A união de dois eventos \\(A\\) e \\(B\\) é \\(A \\cup B =\\{\\omega: \\omega \\in A \\text{ ou } \\omega \\in B \\}\\) e representa o evento A intersecção de dois eventos \\(A\\) e \\(B\\) é \\(A\\cap B =\\{\\omega: \\omega \\in A \\text{ e } \\omega \\in B\\}\\) e representa o evento de que ambos \\(A\\) e \\(B\\) ocorrem. A diferença de dois eventos \\(A\\) e \\(B\\) é \\(A\\setminus B = \\{\\omega: \\omega \\in A \\text{ e } \\omega \\notin B\\}\\) e representa o evento de que \\(A\\) ocorre e \\(B\\) não ocorre. Dois eventos \\(A\\) e \\(B\\) são disjuntos ou mutuamente exclusivos se \\(A\\cap B =\\emptyset\\). Isso significa que \\(A\\) e \\(B\\) não ocorrem simultaneamente. Para qualquer evento \\(A\\), o complementar de \\(A\\) é \\(A^c =\\{\\omega: \\omega \\notin A\\}\\) e representa o evento de que \\(A\\) não ocorre. Leis de Morgan: Sejam \\(A_1,A_2,\\ldots,A_n\\) eventos, temos que \\[\\begin{align} \\left( \\bigcup_{i=1}^n A_i\\right)^c = \\bigcap_{i=1}^n A_i^c, \\tag{LM1} \\label{LM1} \\\\ \\left( \\bigcap_{i=1}^n A_i\\right)^c = \\bigcup_{i=1}^n A_i^c. \\label{LM2} \\tag{LM2} \\end{align}\\] Observação. Note que \\(\\eqref{LM1}\\) diz que o complementar de que pelo menos um dos \\(A_i\\)’s ocorre é igual ao evento de que nenhum dos \\(A_i\\)’s ocorra. Enquanto \\(\\eqref{LM2}\\) diz que o complementar de que todos os \\(A_i\\)’s ocorrem é igual ao evento de que pelo menos um dos \\(A_i\\)’s não ocorre. 2.3 Probabilidade Definição 2.4 (Definição clássica) Seja \\(\\Omega =\\{\\omega_1,\\ldots,\\omega_N\\}\\) finito, e suponhamos que cada evento elementar é igualmente provável, isto é, \\[ P(\\omega) = \\frac{1}{N}, \\, \\omega \\in \\Omega. \\] Definimos a probabilidade do evento \\(A\\subset \\Omega\\) como \\[ P(A) = \\frac{|A|}{|\\Omega|}. \\] Definição 2.5 (Definição axiomática) Uma probabilidade é uma função \\(P: \\mathcal F \\rightarrow \\mathbb R\\), em que \\(\\mathcal F\\) é uma classe de eventos de um espaço amostral \\(\\Omega\\), que satisfaz as seguintes condições: \\(P(A) \\geq 0\\), para todo \\(A \\in \\mathcal F\\), \\(P(\\Omega) = 1\\), (Aditividade enumerável). Para qualquer sequência \\(A_1,A_2,\\ldots \\in \\mathcal F\\), tais que \\(A_i \\cap A_j =\\emptyset\\), \\(i\\neq j\\), \\[\\begin{align*} P\\left(\\bigcup_{i=1}^\\infty A_i\\right)= \\sum_{i=1}^\\infty P(A_i). \\end{align*}\\] Observação. Quando \\(\\Omega\\) é infinito não-enumerável, geralmente é impossível associar uma probabilidade bem definida a todos os subconjuntos de \\(\\Omega\\). Para isso, definimos uma probabilidade em uma classe mais restrita de subconjuntos de \\(\\Omega\\) (chamada de \\(\\sigma\\)-álgebra e definida abaixo); e apenas esses subconjuntos são chamados de eventos. Definição 2.6 (sigma-álgebra) Uma classe \\(\\mathcal F \\subset 2^\\Omega\\) é uma \\(\\sigma\\)-álgebra (em \\(\\Omega \\neq \\emptyset\\)) se satisfaz as seguintes condições \\(\\Omega \\in \\mathcal F\\), Se \\(A \\in \\mathcal F\\), então \\(A^c \\in \\mathcal F\\), Se \\(A_1,A_2,\\ldots \\in \\mathcal F\\), então \\(\\displaystyle\\bigcup_{i=1}^\\infty A_i \\in \\mathcal F\\). O trio \\((\\Omega,\\mathcal F, P)\\) é chamado de um espaço de probabilidade. 2.3.1 Propriedades de uma probabilidade \\(P(\\emptyset) = 0\\). Se \\(A_1,A_2,\\ldots,A_n\\) são eventos dois a dois disjuntos, então \\[\\begin{align*} P\\left(\\bigcup_{i=1}^n A_i \\right) = \\sum_{i=1}^n P(A_i) \\end{align*}\\] \\(P(A) = 1- P(A^c)\\) para todo evento \\(A\\). Para quaisquer eventos \\(A\\) e \\(B\\), \\[\\begin{align*} P(B) = P(A \\cap B) + P(A^c \\cap B) \\end{align*}\\] Se \\(A \\subset B\\), então \\(P(A) \\leq P(B)\\). \\(P(A)\\leq 1\\) para todo evento \\(A\\). Para quaisquer eventos \\(A\\) e \\(B\\), \\[\\begin{align*} P(A\\cup B) =P(A) + P(B) - P(A\\cap B). \\end{align*}\\] Princípio da Inclusão-Exclusão \\[\\begin{align*} P\\left(\\bigcup_{i=1}^n A_i \\right) &amp;= \\sum_{i=1}^n P(A_i) - \\sum_{i&lt;j} P(A_i \\cap A_j)\\\\ &amp;+ \\sum_{i&lt;j&lt;k} P(A_i \\cap A_j \\cap A_k) - \\cdots +(-1)^{n+1} P(A_1\\cap \\cdots \\cap A_n) \\end{align*}\\] Subaditividade finita: Para qualquer sequência finita \\(A_1,A_2,\\ldots, A_n\\) de eventos, \\[ P\\left(\\bigcup_{i=1}^n A_i \\right) \\leq \\sum_{i=1}^n P(A_i). \\] Subaditividade enumerável: Para qualquer sequência \\(A_1,A_2,\\ldots\\) de eventos, \\[ P\\left(\\bigcup_{i=1}^\\infty A_i \\right) \\leq \\sum_{i=1}^\\infty P(A_i). \\] As propriedades (ix) e (x), são conhecidas como Desigualdades de Boole. Prova. Para provar i. Defina \\(A_1 = \\Omega\\), \\(A_i = \\emptyset\\), \\(i&gt;1\\), logo \\(\\Omega = \\bigcup _{i=1}^\\infty A_i\\). Além disso, \\[\\begin{align*} 1=P(\\Omega) = P(\\Omega) + \\sum_{i=2}^\\infty P(\\emptyset) \\Rightarrow \\sum_{i=2}^\\infty P(\\emptyset) = 0 \\Rightarrow P(\\emptyset) = 0. \\end{align*}\\] Defina \\(A_i = \\emptyset\\), \\(i&gt;n\\), logo \\(\\bigcup_{i=1}^\\infty A_i = \\bigcup_{i=1}^n A_i\\), pelo axioma (iii) em e a propriedade 1, segue que \\[\\begin{align*} P\\left(\\bigcup_{i=1}^n A_i\\right)=P\\left(\\bigcup_{i=1}^\\infty A_i\\right) = \\sum_{i=1}^n P(A_i) + \\sum_{i=n+1}^\\infty P(\\emptyset) = \\sum_{i=1}^n P(A_i) \\end{align*}\\] Note que para qualquer \\(A\\subset \\Omega\\), temos que \\(\\Omega= A \\cup A^c\\) e \\(A\\cap A^c = \\emptyset\\), logo \\[\\begin{align*} 1=P(\\Omega)=P(A) + P(A^c) \\Rightarrow P(A^c) = 1-P(A) \\end{align*}\\] Note que \\(B = (A\\cap B) \\cup (A^c \\cap B)\\) tal que \\((A\\cap B) \\cap (A^c \\cap B) = \\emptyset\\), logo \\[\\begin{align*} P(B) = P(A\\cap B) + P(A^c \\cap B) \\end{align*}\\] Como \\(A\\subset B\\), temos que \\(B=(B\\setminus A) \\cup A\\), com \\((B\\setminus A) \\cap A = \\emptyset\\), logo \\[\\begin{align*} P(B) = P(A) + P(A\\setminus B) \\geq P(A). \\end{align*}\\] Como \\(A\\subset \\Omega\\), logo \\(P(A) \\leq P(\\Omega) = 1\\). Note que \\(A\\cup B = (A\\setminus B) \\cup (A \\cap B) \\cup (B \\setminus A)\\), logo \\[\\begin{align*} P(A\\cup B) &amp;= P(A\\setminus B) + P(A \\cap B) + P(B\\setminus A) \\\\ &amp;= [P(A\\setminus B) + P(A \\cap B)] + [P(B\\setminus A) + P(A\\cap B)] - P(A\\cap B)\\\\ &amp;= P(A) + P(B) - P(A\\cap B). \\end{align*}\\] Use indução em \\(n\\). Note que para o caso \\(n=3\\), temos \\[\\begin{align*} P(A\\cup B\\cup C) &amp;= P(A) + P(B) + P(C) - P(A\\cap B) - P(A\\cap C) - P(B \\cap C) \\\\ &amp;+ P(A\\cap B \\cap C). \\end{align*}\\] 2.3.2 Calculando probabilidades Exemplo 2.1 Um comitê de 5 pessoas deve ser selecionado de um grupo de 6 homens e 9 mulheres. Se a seleção for feita aleatoriamente, qual a probabilidade de que o comitê seja formado por 3 homens e 2 mulheres? Solução. Como o experimento consiste em escolher 5 pessoas do total de 15, temos que \\(|\\Omega|= \\binom{15}{5}\\). Supondo que todas as \\(\\binom{15}{5}\\) tem a mesma probabilidade e se \\(A\\) representa o evento de que a seleção feita seja formada por 3 homens e 2 mulheres, temos que \\(|A| = \\binom{6}{3} \\binom{9}{2}\\). Portanto, \\[\\begin{align*} P(A) &amp;= \\frac{|A|}{|\\Omega|} \\\\ &amp;= \\frac{\\binom{6}{3}\\binom{9}{2}}{\\binom{15}{5}}=\\frac{240}{1001} \\end{align*}\\] Exemplo 2.2 Numa mão de pôquer de cinco cartas, o full house ocorre quando alguém sai com três cartas de mesmo valor e duas outras cartas do mesmo valor (diferente do primeiro). Assim um full house é formado por uma trinca e um par. Qual a probabilidade de alguém sair com um full house? Solução. Vamos supor que todas \\(\\binom{52}{5}\\) possíveis seleções são equiprováveis. Note que o número de maneiras de escolher um par é \\(13 \\cdot \\binom{4}{2}\\) e uma vez escolhido o par, o número de maneiras de escolher uma trinca é \\(12 \\cdot \\binom{4}{3}\\), logo se \\(A\\) é o evento de sair um full house, temos que \\[\\begin{align*} P(A) = \\frac{13\\cdot 12 \\cdot \\binom{4}{2} \\cdot \\binom{4}{3}}{\\binom{52}{5}} \\approx 0,0014. \\end{align*}\\] Exemplo 2.3 Um estudante possui 5 livros diferentes de Probabilidade, 2 livros diferentes de Estatística e 3 livros diferentes de Computação, que serão dispostos aleatoriamente em uma prateleira. Qual a probabilidade de que os livros de cada assunto fiquem juntos? Solução. Primeiro observe que temos 10! maneiras de dispor os 10 livros na prateleira, logo para garantir que os livros de cada assunto fiquem juntos vamos formar três blocos (um por cada assunto): o primeiro bloco é formado pelos 5 livros de Probabilidade, o segundo pelos 2 livros de Estatística e o terceiro pelos 3 livros de Computação. Assim, para o primeiro bloco temos 5! maneiras de ordenar eles, para o segundo temos 2! e para o terceiro temos 3!, finalmente temos 3! maneiras de ordenar os blocos. Portanto, a probabilidade pedida é \\[\\begin{align*} P(\\text{os livros de cada assunto fiquem juntos}) &amp;= \\frac{5!2!3!3!}{10!}\\\\ &amp;=\\frac{1}{420} \\end{align*}\\] 2.3.3 Espaço de probabilidade no caso \\(\\Omega\\) enumerável Suponha que \\(\\Omega = \\{\\omega_1, \\omega_2,\\ldots\\}\\) seja um conjunto enumerável e assuma que a cada \\(\\omega_i \\in \\Omega\\), atribuimos um peso \\(p(\\omega_i)\\) tal que \\(\\sum_{i=1}^\\infty p(\\omega_i) = 1\\), além disso considere como família de eventos \\(\\mathcal F = 2^\\Omega\\) e para qualquer \\(A \\in \\mathcal F\\), definimos a probabilidade de \\(A\\) como \\[ P(A) = \\sum_{i: \\omega_i \\in A} p(\\omega_i). \\] Exemplo 2.4 Suponha um jogo no qual você ganha \\(k-2\\) reais com probabilidade \\(\\left(\\frac{1}{2}\\right)^k\\) para qualquer \\(k\\geq 1\\) inteiro. Qual a probabilidade de você ganhar mais de dos reais ? Solução. Neste caso o espaço amostral é dado pela quantidade de reais que você pode ganhar no jogo, ou seja, \\[ \\Omega = \\{-1,0,1,2,\\ldots\\}, \\] e \\[ P(\\{\\omega\\})=P(\\omega) = \\left(\\frac{1}{2}\\right)^{\\omega+2}, \\; \\omega \\in \\Omega.\\] Por exemplo, \\(P(\\{-1\\}) = 1/2\\) e \\(P(\\{0\\}) = 1/4\\). O evento de interesse é \\(A=\\{3,4,5,6,\\ldots\\}\\). Portanto, \\[\\begin{align*} P(A) = \\sum_{\\omega = 3}^\\infty P(\\omega) &amp;= \\sum_{\\omega=3}^\\infty \\left(\\frac{1}{2}\\right)^{\\omega + 2}\\\\ &amp;=\\frac{1}{4} \\sum_{\\omega=3}^\\infty \\left(\\frac{1}{2}\\right)^{\\omega} \\\\ &amp;= \\frac{1}{16}. \\end{align*}\\] 2.4 Probabilidade Condicional Considere o experimento que consiste em lançar um dado honesto e defina os eventos \\(A=\\{1,2,3\\}\\) e \\(B=\\{2,4,6\\}\\), temos que \\(P(A) = \\frac{1}{2}\\), essa é a probabilidade a priori de \\(A\\), isto é, antes que o experimento se realize. Suponha que uma vez realizado o experimento alguém nos infrome que o resultado do mesmo é um número par, ou seja que \\(B\\) ocorreu. Com essa nova informação, a probabilidade de \\(A\\) é atualizada, pois para que \\(A\\) aconteça o único resultado possível do experimento deve ter sido 2. O que nos leva a \\[ P(A \\text{ dado } B) = \\frac{|A\\cap B|}{|\\Omega|} = \\frac{1}{3}. \\] Essa probabilidade é chamada de probabilidade a posteriori de \\(A\\) dado \\(B\\). Daqui em diante, vamos chama-la de probabilidade de \\(A\\) dada a ocorrência de \\(B\\) ou simplesmente de probabilidade de \\(A\\) dado \\(B\\). Do exemplo, podemos generalizar com a seguinte definição: Definição 2.7 (Probabilidade condicional) Sejam \\(A,B\\) dois eventos em um espaço de probabilidade \\((\\Omega, \\mathcal F, P)\\), tal que \\(P(B)&gt;0\\), definimos a probabilidade condicional de \\(A\\) dado \\(B\\) como \\[\\begin{align*} P(A|B) = \\frac{P(A\\cap B)}{P(B)}. \\end{align*}\\] Proposição 2.1 Seja \\(B\\) um evento em um espaço de probabilidade \\((\\Omega,\\mathcal F, P)\\), tal que \\(P(B)&gt;0\\), temos que \\(P(\\cdot|B)\\) é uma probabilidade. Prova. Devemos verificar os três axiomas da definição axiomática de probabilidade. Com efeito \\(P(A|B) \\geq 0\\), para qualquer evento \\(A\\) (trivial). \\(P(\\Omega|B) = \\frac{P(\\Omega\\cap B)}{P(B)} = \\frac{P(B)}{P(B)} = 1\\). Aditividade enumerável: Sejam \\(A_1, A_2,\\ldots\\) eventos disjuntos dois a dois, então \\[\\begin{align*} P\\left(\\bigcup_{i=1}^\\infty A_i|B\\right) &amp;= \\frac{P\\left(\\left(\\bigcup_{i=1}^\\infty A_i\\right) \\cap B\\right)}{P(B)}\\\\ &amp;= \\frac{P\\left(\\bigcup_{i=1}^\\infty (A_i \\cap B)\\right)}{P(B)} \\\\ &amp;= \\frac{\\sum_{i=1}^\\infty P(A_i\\cap B)}{P(B)} \\\\ &amp;= \\sum_{i=1}^\\infty P(A_i|B) \\end{align*}\\] Proposição 2.2 (Regra da multiplicação) Se \\(A_1,\\ldots,A_n\\) são eventos em um espaço de probabilidade \\((\\Omega,\\mathcal F, P)\\) com \\(P(A_1\\cap \\ldots \\cap A_{n-1})&gt;0\\), então \\[ P(A_1 \\cap A_2 \\cap \\ldots \\cap A_n) = P(A_1)P(A_2|A_1) \\cdots P(A_n|A_1 \\cap \\ldots \\cap A_{n-1}) \\] 2.4.1 Fórmula da probabilidade total Definição 2.8 (Partição) Seja \\(\\Omega\\neq \\emptyset\\), uma partição de \\(\\Omega\\) é uma sequencia finita de conjuntos (ou eventos) \\(A_1,\\ldots,A_n\\) tais que \\(A_i \\cap A_j = \\emptyset\\) para qualquer \\(i\\neq j\\), \\(i,j=1,\\ldots,n\\), \\(\\displaystyle \\bigcup_{i=1}^n A_i = \\Omega\\). Teorema 2.1 (Fórmula da probabilidade total) Seja \\(\\{A_i\\}_{i=1}^n\\) uma partição do espaço amostral \\(\\Omega\\), tal que \\(P(A_i)&gt;0\\) para qualquer \\(i=1,\\ldots, n\\) e \\(B\\) um evento qualquer, temos que \\[ P(B) = \\sum_{i=1}^n P(B|A_i)P(A_i). \\] Prova. Note que \\(\\displaystyle B = \\bigcup_{i=1}^n (B\\cap A_i)\\) e \\((B\\cap A_i) \\cap (B\\cap A_j)\\) para qualquer \\(i\\neq j\\). Logo \\[ P(B) = \\sum_{i=1}^n P(B\\cap A_i) = \\sum_{i=1}^n P(B|A_i) P(A_i), \\] onde a ultima passagem decorre da regra da multiplicação para dois eventos. Exemplo 2.5 Durante o mês de outubro a probabilidade de chuva em um dia determinado é de 4/10. Um time de futebol ganha um jogo em um dia com chuva com probabilidade 6/10 e em um dia sem chuva com probabilidade de 4/10. Qual a probabilidade de que esse time ganhe um jogo naquele dia de outubro? Solução. Seja \\(A\\): O time ganhe um jogo naquele dia de outubro e \\(B\\): teve chuva naquele dia de outubro, logo \\[ P(A) = P(A|B)P(B) + P(A|B^c)P(B^c) = (6/10)(4/10) + (4/10)(6/10) = 24/50 \\] Exemplo 2.6 Ao responder uma questão em uma prova de múltipla escolha, um estudante sabe a resposta ou a chuta. Seja \\(p\\) a probabilidade de que o estudante saiba a resposta e \\(1-p\\) a probabilidade de que ele chute. Suponha que um estudante que chuta a resposta tem uma probabilidade de acerto de \\(1/m\\), onde \\(m\\) é o número de alternativas em cada questão de múltipla escolha. Qual a probabilidade que ele a tenha respondido corretamente? Solução. Denote por \\(A\\): o estudante tenha respondido corretamente [acerta a resposta] e por \\(B\\): o estudante sabe a resposta, logo \\[ P(A) = P(A|B)P(B) + P(A|B^c)P(B^c) = p\\cdot 1 + (1-p) \\cdot 1/m = p+(1-p)/m. \\] Por exemplo, se \\(p=1/2\\) e \\(m=10\\), temos que \\(P(A) = \\frac{11}{20}\\). Exemplo 2.7 Em uma cidade, os motoristas são parados pela polícia para fazer um teste sobre o teor de álcool no sangue. Suponha que a probabilidade de que um motorista detido esteja embriagado é 5% e que o teste realizado acerta o estado de embriaguez em 80% das ocasiões. Qual a probabilidade de que o teste de um motorista detido resulte positivo? 2.4.2 Fórmula de Bayes Teorema 2.2 (Fórmula de Bayes) Seja \\(\\{A_i\\}_{i=1}^n\\) uma partição do espaço amostral \\(\\Omega\\), tal que \\(P(A_i)&gt;0\\) para qualquer \\(i=1,\\ldots, n\\) e \\(B\\) um evento, temos que \\[ P(A_i|B) = \\frac{P(B|A_i)P(A_i)}{\\sum_{i=1}^n P(B|A_i)P(A_i)} \\] Prova. Para cada \\(i=1,2,\\ldots,n\\), temos que \\[\\begin{align*} P(A_i|B)&amp;=\\frac{P(A_i\\cap B)}{P(B)} \\\\ &amp;=\\frac{P(B|A_i)P(A_i)}{\\sum_{i=1}^n P(B|A_i)P(A_i)} \\end{align*}\\] Na primeira passagem aplicamos a definição de probabilidade condicional, na segunda passagem aplicamos, no numerador, a regra da multiplicação e no denominador o teorema da probabilidade total. Solução. Denote por \\(A\\): teste resulte positivo e por \\(B\\): o motorista está embriagado. \\[P(A) = P(A|B)P(B) + P(A|B^c)P(B^c) = (0,80)(0,05) + (0,20)(0,95) = 23/100.\\] Exemplo 2.8 Nas mesmas condições do exemplo 3, dado que o teste de um motorista resulto negativo, qual a probabilidade de que estava dirigindo com um índice alcoólico acima do permitido? Solução. Defina \\(B\\): embriagado, \\(B^c\\): sóbrio, \\(A^c\\): teste negativo, \\(A\\): teste positivo Pelo Teorema de Bayes, temos que \\[\\begin{align*} P(B|A^c) &amp;=\\frac{P(A^c|B)P(B)}{P(A^c|B)P(B) + P(A^c|B^c)P(B^c)}\\\\ &amp;=\\frac{(0,20)(0,05)}{(0,20)(0,05)+(0,80)(0,95)} \\\\ &amp;\\approx 0.01 \\end{align*}\\] Ou seja, a probabilidade de ocorrer um falso negativo é aproximadamente de 1% . "],["conjuntos-limites-e-continuidade-da-probabilidade.html", "Capítulo 3 Conjuntos limites e continuidade da probabilidade 3.1 Limite superior e inferior de uma sequência de números reais.", " Capítulo 3 Conjuntos limites e continuidade da probabilidade Definição 3.1 (Sequências monótonas de eventos) Sejam \\(A_1,A_2,\\ldots\\) eventos em um espaço de probabilidade \\((\\Omega, \\mathcal F, P)\\). Dizemos que \\((A_n)_{n\\geq 1}\\) é uma sequência de eventos crescente se \\[ A_1 \\subset A_2 \\subset A_3 \\subset \\cdots \\] Dizemos que \\((A_n)_{n\\geq 1}\\) é uma sequência de eventos decrescente se \\[ A_1 \\supset A_2 \\supset A_3 \\supset \\cdots \\] Observação. Se \\((A_n)_{n\\geq 1}\\) é uma sequência crescente ou decrescente, dizemos que é monótona. Definição 3.2 (Limite de sequências monótonas de eventos) Seja \\((A_n)_{n\\geq 1}\\) uma sequência de eventos em um espaço de probabilidade \\((\\Omega,\\mathcal F, P)\\). Denotamos por \\(A_n\\uparrow A\\), se \\((A_n)_{n\\geq 1}\\) é uma sequência crescente de eventos e \\[ A = \\bigcup_{n=1}^\\infty A_n. \\] Denotamos por \\(A_n\\downarrow A\\), se \\((A_n)_{n\\geq 1}\\) é uma sequência crescente de eventos e \\[ A = \\bigcap_{n=1}^\\infty A_n. \\] Teorema 3.1 (Continuidade monótona da probabilidade) Seja \\((A_n)_{n\\geq 1}\\) uma sequência de eventos em um espaço de probabilidade \\((\\Omega,\\mathcal F, P)\\). Se \\(A_n \\uparrow A\\), então \\(P(A_n) \\uparrow P(A)\\) (continuidade por baixo). Se \\(A_n \\downarrow A\\), então \\(P(A_n) \\downarrow P(A)\\) (continuidade por cima). Prova. Para provar i. Defina \\(B_1 = A_1\\), \\(B_k = A_k\\setminus A_{k-1}\\), \\(k\\geq 2\\) e note que os eventos \\(B_1,B_2,\\ldots\\) são disjuntos dois a dois. Além disso, \\[ A_n=\\bigcup_{k=1}^n B_k \\; \\; \\; \\text{e} \\; \\; \\; A = \\bigcup_{n=1}^\\infty A_n = \\bigcup_{n=1}^\\infty B_n \\] Logo, \\[\\begin{align} P(A_n) = \\sum_{k=1}^n P(B_k), \\\\ P(A) =\\sum_{n=1}^\\infty P(B_k). \\end{align}\\] Além disso, como \\(A_n\\subset A_{n+1},\\) \\(\\forall n\\geq 1\\), temos que \\(P(A_n)\\leq P(A_{n+1}),\\) \\(\\forall n\\geq 1\\). Finalmente, tomando limite em (1) quando \\(n \\to \\infty\\), temos que \\(P(A_n) \\uparrow P(A)\\). Para provar ii. note que \\(A_n^c \\uparrow A^c\\), logo pela parte i., segue que \\(P(A_n^c) \\uparrow P(A^c)\\), logo \\(1-P(A_n) \\uparrow 1- P(A) \\iff P(A_n) \\downarrow P(A)\\). Definição 3.3 (conjuntos limites) Seja \\(A_1,A_2,\\ldots\\) uma sequência de eventos em um espaço de probabilidade \\((\\Omega, \\mathcal F, P)\\), definimos os eventos \\[\\begin{align} {\\lim\\inf}_{n\\to\\infty} A_n = \\bigcup_{n=1}^\\infty \\bigcap_{k=n}^\\infty A_k \\label{liminf} \\\\ {\\lim\\sup}_{n\\to\\infty} A_n = \\bigcap_{n=1}^\\infty \\bigcup_{k=n}^\\infty A_k \\label{limsup} \\end{align}\\] Da definição de \\(\\liminf A_n\\), temos que \\[\\begin{align*} \\omega \\in {\\lim\\inf}_{n\\to\\infty} A_n &amp;\\iff \\exists n \\geq 1, \\forall k \\geq n, \\; \\omega \\in A_k \\\\ &amp;\\iff |\\{ n : \\omega \\notin A_n\\}|&lt; \\infty. \\end{align*}\\] Da definição de \\(\\limsup A_n\\), temos que \\[\\begin{align*} \\omega \\in {\\lim\\sup}_{n\\to\\infty} A_n &amp;\\iff \\forall n\\geq 1, \\exists k \\geq n, \\; \\omega \\in A_k \\\\ &amp;\\iff |\\{n: \\omega \\in A_n \\}|=\\infty \\end{align*}\\] Daí, é frequentemente usada a seguinte notação: \\[{\\lim\\sup}_{n\\to\\infty} A_n = [A_n \\text{ ocorre infinitas vezes}]\\] \\[{\\lim\\inf}_{n\\to\\infty} A_n = [A_n \\text{ ocorre para todo $n$ suficientemente grande}]\\] Observação. Observe que \\(\\liminf_{n\\to\\infty} A_n \\subset \\limsup_{n\\to\\infty} A_n\\), logo temos a seguinte definição. Definição 3.4 (Limite de uma sequência) Se \\(\\limsup_{n\\to\\infty} A_n \\subset \\liminf_{n\\to\\infty} A_n\\), então dizemos que \\(\\lim_{n\\to\\infty} A_n = A\\), onde \\(A = \\liminf_{n\\to\\infty} A_n = \\limsup_{n\\to\\infty} A_n\\). Teorema 3.2 (Continuidade da probabilidade) Se \\(\\lim_{n\\to\\infty} A_n = A\\), então \\(\\lim_{n\\to\\infty} P(A_n) = P(\\lim_{n\\to\\infty} A_n) = P(A)\\). Prova. Para \\(n\\geq 1\\), defina \\(\\displaystyle B_n = \\bigcap_{k=n}^\\infty A_k\\) e \\(\\displaystyle C_n = \\bigcup_{k=n}^\\infty A_k\\) \\(\\Rightarrow\\) \\(B_n\\subset A_n \\subset C_n\\), logo, \\(P(B_n) \\leq P(A_n) \\leq P(C_n)\\). Além disso, temos que \\(B_n \\uparrow \\liminf A_n\\) e \\(C_n \\downarrow\\limsup A_n\\), logo \\(P(\\liminf A_n) = \\lim P(B_n)\\) e \\(\\lim P(C_n) = P(\\limsup A_n)\\). Agora, \\[ P(\\liminf A_n) \\leq \\liminf P(A_n) \\leq \\limsup P(A_n) \\leq P(\\limsup A_n), \\] mas \\(P(A) = P(\\liminf A_n) = P(\\limsup A_n)\\), logo se \\(P(A_n)\\) converge, temos que \\(\\lim P(A_n) = P(A)\\). 3.1 Limite superior e inferior de uma sequência de números reais. Seja \\((a_n)_{n\\geq 1}\\) uma sequência limitada de números reais, definimos \\[\\begin{align*} b_n=\\inf_{k \\geq n} a_k \\\\ c_n=\\sup_{k \\geq n} a_k \\end{align*}\\] Primeiro, note que como \\((a_n)_{n\\geq 1}\\) é limitada existem \\(m,M\\in\\mathbb R\\), tais que \\[ m \\leq a_n \\leq M, \\; \\; \\; \\forall n \\geq 1. \\] Portanto \\((b_n)_{n\\geq 1}\\) é uma sequência crescente e limitada superiormente por \\(m\\), enquanto \\((c_n)_{n\\geq 1}\\) é uma sequência decrescente e limitada inferiormente por \\(M\\). Logo, definimos: \\[\\begin{align} \\liminf a_n&amp;:=\\lim b_{n} = \\sup_{n\\geq 1} \\inf_{k\\geq n} a_k, \\label{liminfseq} \\\\ \\limsup a_n &amp;:= \\lim c_n = \\inf_{n\\geq 1} \\sup_{k\\geq n} a_k. \\label{limsupseq} \\end{align}\\] O limite dado em é chamado de limite inferior da sequência \\((a_n)\\), similarmente o limite dado em é chamado de limite superior de \\((a_n)\\). Teorema 3.3 Uma sequência \\((a_n)\\) de números reais converge para \\(a\\in\\mathbb R\\) se, e somente se, \\[\\liminf a_n= \\limsup a_n = a.\\] Prova. (\\(\\Leftarrow\\)) Suponha que \\(\\liminf a_n = \\limsup a_n = a\\). Pela definição, de \\(\\liminf\\) e \\(\\limsup\\) de uma sequência de números reais, temos que \\[ a=\\liminf a_n \\leq a_n \\leq \\limsup a_n = a, \\] o resultado segue pelo Teorema do Sanduíche. (\\(\\Rightarrow\\)) Suponha agora que \\(a_n \\to a, \\; n \\to \\infty\\). Dado \\(\\varepsilon &gt;0\\), existe \\(n_0\\in\\mathbb N\\), tal que para \\(n \\geq n_0\\), \\[ a -\\varepsilon &lt; a_n &lt; a + \\varepsilon. \\] Daí, para \\(n \\geq n_0\\) \\[ a -\\varepsilon &lt; \\inf_{k\\geq n} a_k \\leq \\sup_{k \\geq n} &lt; a + \\varepsilon \\iff a -\\varepsilon &lt; b_n \\leq c_n &lt; a + \\varepsilon .\\] Portanto, \\(\\liminf a_n = \\limsup a_n=a\\). "],["vas.html", "Capítulo 4 Variáveis aleatórias 4.1 Definições 4.2 Função de probabilidade 4.3 Função de distribuição acumulada", " Capítulo 4 Variáveis aleatórias Grosso modo, uma variável aleatória pode ser definida como um característico numérico associada ao resultado de um experimento aleatório. Para esclarecer isso, consideremos o experimento aleatório em que uma moeda é lançada 3 vezes, e registramos os resultados em ordem. O espaço amostral para esse experimento é \\[\\Omega = \\{KKK, CKK, KCK, KKC, CCK, CKC, KCC, CCC\\}.\\] Agora, suponha que estamos interessados em saber o número de caras \\(X\\). Os possíveis valores de \\(X\\) estão resumidos na seguinte tabela \\(\\omega\\) \\(KKK\\) \\(CKK\\) \\(KCK\\) \\(KKC\\) \\(CCK\\) \\(CKC\\) \\(KCC\\) \\(CCC\\) \\(X(\\omega) = x\\) \\(0\\) \\(1\\) \\(1\\) \\(1\\) \\(2\\) \\(2\\) \\(2\\) \\(3\\) Note que para cada \\(\\omega \\in \\Omega\\), associamos um valor \\(X(\\omega) \\in \\{0,1,2,3\\}\\subset \\mathbb R\\). Se atribuímos a cada \\(\\omega \\in \\Omega\\) igual probabilidade, isto é, 1/8, então podemos calcular, por exemplo \\[\\begin{eqnarray*} P(X=1) &amp;=&amp; P(\\{\\omega\\in\\Omega: X(\\omega)=1\\}) \\\\ &amp;=&amp; P(\\{CKK, KCK, KKC\\}) \\\\ &amp;=&amp; \\frac{1}{8} + \\frac{1}{8} + \\frac{1}{8} \\\\ &amp;=&amp;\\frac{3}{8}. \\end{eqnarray*}\\] Aplicando o mesmo raciocínio para \\(x=0,2,3\\), obtemos \\(x\\) \\(0\\) \\(1\\) \\(2\\) \\(3\\) \\(P(X=x)\\) \\(1/8\\) \\(3/8\\) \\(3/8\\) \\(1/8\\) Note que \\(\\displaystyle \\sum_{x=0}^3 P(X=x) = 1\\). 4.1 Definições Uma variável aleatória (v.a.) é uma função a valores reais, definida em \\(\\Omega\\). Variáveis aleatórias são denotadas por letras maiúsculas \\(X,Y,Z,\\ldots\\) Os valores possíveis de uma variável aleatória são denotados por letras minúsculas \\(x,y,z,\\ldots\\) Uma variável aleatória é dita discreta se assumir valores em conjunto finito ou infinito enumerável. Uma variável aleatória é dita contínua se assumir valores em um intervalo de \\(\\mathbb R\\). 4.2 Função de probabilidade Seja \\(X\\) uma v.a. discreta assumindo valores no conjunto \\(\\{x_{1}, x_{2}, \\ldots\\}\\) finito ou enumerável. A função \\[p(x) = P(X=x), \\; \\; x\\in \\mathbb R,\\] é dita função de probabilidade de \\(X\\), se satisfaz as seguintes propriedades Se \\(x\\notin \\{x_{1}, x_{2}, \\ldots\\}\\), então \\(p(x)=0\\). \\(p(x_{i}) \\geq 0\\) para qualquer \\(i=1,2,\\ldots\\) \\(\\sum_{i=1}^{\\infty} p(x_{i})=1\\). Se \\(A\\subset \\mathbb R\\), então \\(\\displaystyle P(X \\in A) = \\sum_{i: x_{i}\\in A}p (x_{i})\\). 4.2.1 Exemplos Exemplo 4.1 Três bolas são selecionadas aleatoriamente de uma urna que contém 20 bolas numeradas de 1 a 20. Se apostamos que pelo menos uma das bolas retiradas tem o número maior ou igual a 17, qual a probabilidade de ganharmos? Solução. Seja \\(X\\) o maior número sorteado. Por exemplo, Se \\(\\omega = \\{3,10,5,\\}\\), então \\(X(\\omega) = 10\\) (perdemos a aposta). Se \\(\\omega&#39; = \\{2,5,16\\}\\), então \\(X(\\omega&#39;) = 16\\) (ganhamos a aposta). Agora, suponha que todas as \\(\\binom{20}{3}\\) possíveis seleções são igualmente prováveis. Logo, para \\(x\\in \\{3,\\ldots, 20\\}\\) \\[\\begin{align*} p(x) = P(X=x) = \\frac{\\binom{x-1}{2}}{\\binom{20}{3}}. \\end{align*}\\] Finalmente, queremos obter \\(P(X \\geq 17)\\) \\[\\begin{align*} P(X\\geq 17) &amp;= p(17) + p(18) + p(19) + p(20) \\\\ &amp;= \\frac{\\binom{16}{2}}{\\binom{20}{3}} + \\frac{\\binom{17}{2}}{\\binom{20}{3}} + \\frac{\\binom{18}{2}}{\\binom{20}{3}} + \\frac{\\binom{19}{2}}{\\binom{20}{3}}\\\\ &amp;\\approx 0,105 + 0,119 + 0,134 + 0,150 = 0,508. \\end{align*}\\] Exemplo 4.2 O número de pessoas que entram em uma academia durante um minuto é uma v.a. discreta \\(X\\) com função de probabilidade dada por \\[ p(k) = \\frac{c \\, 4^k}{k!}, \\; k = 0,1,\\ldots \\] Determine: (a) o valor de \\(c\\) \\(P(X&gt;2)\\). Solução. Seja \\(X\\): Número de pessoas que entram naquela academia durante um minuto. Logo \\(\\displaystyle \\sum_{k=0}^\\infty p(k) = 1 \\Rightarrow c \\displaystyle \\sum_{k=0}^\\infty \\frac{4^k}{k!} = 1 \\Rightarrow c e^4 \\Rightarrow c =e^{-4}\\). Portanto, \\[p(k) = \\frac{e^{-4}\\, 4^k}{k!}, \\; k = 0,1,\\ldots \\] \\(P(X&gt;2) = 1- P(X\\leq 2) = 1-[p(0) + p(1) + p(2)] = 1-13\\,e^{-4} \\approx 0,7619\\). 4.3 Função de distribuição acumulada Para todo \\(x\\in \\mathbb R\\), defina \\(F(x) = P(X\\leq x)\\), então \\[\\begin{eqnarray*} F(0) &amp;=&amp; P(X \\leq 0) = p(0) = 1/8, \\\\[0.2cm] F(1) &amp;=&amp; P(X \\leq 1) = p(0) + p(1) = 4/8, \\\\[0.2cm] F(2) &amp;=&amp; P(X \\leq 2) = p(0) + p(1) + p(2) =7/8, \\\\[0.2cm] F(3) &amp;=&amp; P(X \\leq 3) = p(0) + p(1) + p(2) + p(3)= 1. \\end{eqnarray*}\\] Definição 4.1 A função de distribuição (acumulada) de uma variável aleatória \\(X\\) é a função \\(F: \\mathbb R \\rightarrow \\mathbb R\\) definida por \\[\\begin{equation*} F(x) = P(X\\leq x) = P(\\{s\\in \\Omega: X(s)\\leq x\\}), \\; x\\in \\mathbb R. \\end{equation*}\\] 4.3.1 Algumas propriedades da função de distribuição \\(F\\) é uma função não-decrescente, isto é \\[\\begin{align*} \\text{Se } x &lt; y, \\text{ então } F(x) \\leq F(y). \\end{align*}\\] Se \\(X\\) é uma v.a. discreta, então \\[\\begin{align*} F(x) = \\sum_{y \\leq x} p(y). \\end{align*}\\] \\(P(X=x) = P(X\\leq x) - P(X &lt; x) = F(x) - F(x^{-})\\) (salto de \\(F\\) no ponto \\(x\\)). Para \\(a,b\\in\\mathbb R\\) com \\(a &lt; b,\\) \\(P(a&lt; X \\leq b) = F(b) - F(a)\\). 4.3.2 Propriedades fundamentais da função de distribuição (F1) \\(F\\) é não decrescente: \\(x&lt;y \\Rightarrow F(x) \\leq F(y)\\). (F2) \\(F\\) é contínua à direita: \\(x_n\\downarrow x \\Rightarrow F(x_n) \\downarrow F(x)\\). (F3) \\(\\lim_{n\\to \\infty}F(n)=1\\) e \\(\\lim_{n\\to-\\infty} F(n) = 0\\). Qualquer função \\(F: \\mathbb R \\rightarrow \\mathbb R\\) satisfazendo as condições (F1), (F2) e (F3) é função de distribuição de alguma variável aleatória. "],["valoresperado.html", "Capítulo 5 Valor esperado 5.1 Motivação 5.2 Funções de variáveis aleatórias 5.3 Variância 5.4 Independência de variáveis aleatórias", " Capítulo 5 Valor esperado Seja \\(X\\) uma variável aleatória discreta com função de probabiliade \\(p(\\cdot)\\) e assumindo valores em \\(\\{x_1, x_2,\\ldots\\}\\). A esperança matemática, média ou valor esperado de \\(X\\) é definida por \\[\\begin{align*} E(X) = \\sum_{i=1}^\\infty x_i\\, p(x_i). \\end{align*}\\] Observação. Note que a esperança de \\(X\\), é uma média ponderada dos valores de \\(x\\), em que cada valor de \\(x\\) é ponderado por sua probabilidade correspondente. Voltando ao exemplo do lançamento da moeda 3 vezes e, definindo \\(X\\) como o número de caras observadas, temos que \\[ E(X) = 0 \\times \\frac{1}{8} + 1 \\times \\frac{3}{8} + 2 \\times \\frac{3}{8} + 3 \\times \\frac{1}{8} = 1,5. \\] Algumas observações sobre a o valor esperado: O valor esperado pode não ser um dos valores possíveis de \\(X\\), Não se deve arredondar \\(E(X)\\) para um número inteiro. Exemplo 5.1 Seja \\(X:\\) Resultado observado no lançamento de um dado honesto. Determine o valor esperado de \\(X\\). Solução. A função de probabilidade de \\(X\\) é \\[ p(x) = \\frac{1}{x}, \\; x=1,\\ldots,6. \\] Logo \\[ E(X) = \\sum_{x=1}^6 x \\frac{1}{6} = \\frac{1}{6}\\sum_{x=1}^6 x= \\frac{6\\times 7}{6 \\times 2} = \\frac{7}{2}. \\] Exemplo 5.2 Um lote contém 3 itens defeituoso e 5 não defeituosos. Retiram-se 2 itens do lote em sequência, sem reposição. Determine o número esperado de itens defeituosos retirados. Solução. Vamos determinar, primeiro, a função de probabilidade de \\(X:\\) número de itens defeituosos retirados. Para isso, seja \\(D_i\\): o i-ésimo item retirado é defeituoso e \\(B_i\\): o i-ésimo item retirado é bom. Logo: \\[\\begin{align*} p(0)=P(X=0) &amp;= P(B_1\\cap B_2) = P(B_1)P(B_2|B_1) = \\frac{5}{8} \\frac{4}{7} = \\frac{20}{56},\\\\ p(1)=P(X=1) &amp;= P(B_1 \\cap D_2) + P(D_1 \\cap B_2) = \\frac{5}{8} \\frac{3}{7} + \\frac{3}{8} \\frac{5}{7} = \\frac{15}{56} + \\frac{15}{56} = \\frac{30}{56},\\\\ p(2)=P(X=2) &amp;= P(D_1 \\cap D_2) =P(D_1)P(D_2|D_1) = \\frac{3}{8} \\frac{2}{7} = \\frac{6}{56}. \\end{align*}\\] Portanto, \\[ E(X) = 0\\times \\frac{20}{56} + 1 \\times \\frac{30}{56} + 2 \\times \\frac{6}{56} = \\frac{3}{4}. \\] 5.1 Motivação Suponha uma variável aleatória discreta \\(X\\) assumindo valores no conjunto \\(\\{x_1,x_2,\\ldots\\}\\). Essa variável aleatória é o resultado de um experimento aleatório. Suponha que repetimos o experimento \\(N\\) vezes. Seja \\(N_i\\) (\\(i=1,2,\\ldots\\)) o número de vezes que observamos o valor \\(x_i\\). Pela interpretação frequentista da probabilidade, para \\(N\\) suficientemente grande temos que \\[ p(x_i) \\approx \\frac{N_i}{N}, \\] e a média aritmética dos valores observados de \\(X\\) é \\[ \\bar{X} = \\sum_{i=1}^\\infty \\frac{N_i\\, x_i}{N} \\approx \\sum_{i=1}^\\infty p(x_i) x_i = E(X) \\] Essas aproximações são adequadamente justificadas pela Lei dos grandes números. 5.2 Funções de variáveis aleatórias Se \\(X\\) é uma variável aleatória e \\(g\\) uma função a valores reais, então \\(Y=g(X)\\), também é uma variável aleatória. Proposição 5.1 Seja \\(X\\) uma v.a. discreta com função de probabilidade \\(p(x)\\). Para qualquer função \\(g\\) a valores reais, \\[ E[g(X)] = \\sum_{x: p(x)&gt;0} g(x) p(x). \\] Observação. Note que esse resultado permite o cálculo da esperança de \\(Y=g(X)\\), mesmo que se desconheça a distribuição de probabilidade de \\(Y\\). Exemplo 5.3 Seja \\(X\\): Número de caras nos três lançamentos de uma moeda justa, então a função de probabilidade de \\(X\\) é \\(x\\) \\(0\\) \\(1\\) \\(2\\) \\(3\\) \\(p(x)\\) \\(1/8\\) \\(3/8\\) \\(3/8\\) \\(1/8\\) E seja \\(Y=X^2\\), logo, \\[\\begin{align*} E(X^2)=E(Y) = \\sum_{x=0}^3 x^2 p(x) = 0^2\\times \\frac{1}{8} + 1^2 \\times \\frac{3}{8} + 2^2 \\times \\frac{3}{8} + 3^2 \\times \\frac{1}{8} = 3. \\end{align*}\\] Observação. Em geral \\(E(X^2) \\neq [E(X)]^2\\) Exemplo 5.4 Suponha que uma moeda é lançada 3 vezes, e que ganhamos ou perdemos R$1 conforme o número de caras seja par ou ímpar. Qual o valor esperado do nosso lucro? Solução. Seja \\(X\\): Número de caras \\(\\Rightarrow\\) \\(Y=(-1)^X\\): Lucro obtido no jogo. Logo, \\[ E(Y)=E[(-1)^X]=(-1)^0\\times \\frac{1}{8} + (-1)^1 \\times \\frac{3}{8} + (-1)^2 \\times \\frac{3}{8} + (-1)^3 \\times \\frac{1}{8}=0. \\] Corolário 5.1 Se \\(a\\) e \\(b\\) são constantes, então Se \\(a\\) e \\(b\\) são constantes, então \\[ E(aX + b) = a E(X) + b \\] Exemplo 5.5 Uma moeda é lançada 3 vezes, e ganhamos R$5 a cada cara obtida e perdemos R$2 a cada coroa. Qual o valor esperado do nosso lucro? Solução. \\(X\\): Número de caras, \\(3-X\\): Número de coroas \\(\\Rightarrow\\) \\(Y=5X - 2(3-X) =7X - 6\\): Lucro. \\[ E(Y)=E(7X-6) = 7E(X) - 6= 7 \\times \\frac{3}{2} - 6 = \\frac{9}{2}. \\] 5.3 Variância Definição 5.1 A variância de uma v.a. \\(X\\) com esperança \\(\\mu\\) é definida por \\[ \\sigma^2=Var(X)=E[(X-\\mu)^2]. \\] Definição 5.2 O desvio padrão de \\(X\\) é definido por \\(\\sigma=DP(X)= \\sqrt{Var (X)}\\). Exemplo 5.6 Seja \\(X\\) o resultado obtido no lançamento de um dado justo, assim \\[ p(i) = 1/6, \\; \\; i =1,2,3,4,5,6. \\] Logo, \\(E(X) = \\displaystyle\\sum_{i=1}^6 i \\, p(i) = \\frac{1}{6}\\sum_{i=1}^6 i =\\frac{1}{6}\\frac{(6)(7)}{2} = \\frac{7}{2}\\). \\[\\begin{align*} \\sigma^2 &amp;= \\sum_{i=1}^6 (i-E(X))^2 p(i)\\\\ &amp;= \\frac{1}{6}\\left[\\left(1-\\frac{7}{2}\\right)^2 + \\left(2-\\frac{7}{2}\\right)^2 + \\cdots + \\left(6-\\frac{7}{2}\\right)^2\\right] \\\\ &amp;=\\frac{35}{12}. \\end{align*}\\] e, \\[ \\sigma = DP(X) = \\sqrt{\\frac{35}{12}} \\approx 1,70. \\] Proposição 5.2 \\(Var(X) = E(X^2) - [E(X)]^2\\) Prova. Seja \\(\\mu = E(X)\\), \\[\\begin{align*} (X-\\mu)^2 = X^2 - 2X\\mu + \\mu^2, \\end{align*}\\] Logo, \\[\\begin{align*} Var(X) = E[(X-\\mu)^2] &amp;= E(X^2) - 2\\mu^2 + \\mu^2 \\\\ &amp;=E(X^2) - \\mu^2 = E(X^2) - [E(X)]^2. \\end{align*}\\] Proposição 5.3 Se \\(a\\) e \\(b\\) são constantes, então \\[ Var(aX+b) = a^2 Var(X) \\] Corolário 5.2 Seja \\(X\\) uma v.a. tal que \\(E(X) = \\mu\\) e \\(Var(X) = \\sigma^2 &gt;0\\). Defina \\(Z=\\frac{X-\\mu}{\\sigma}\\). Então \\[ E(Z) = 0 \\text{ e } Var(Z) = 1. \\] 5.4 Independência de variáveis aleatórias Definição 5.3 As variáveis aleatórias \\(X_1, \\ldots, X_n\\) são independentes se, para qualquer escolha de conjuntos \\(A_1,\\ldots,A_n \\subset \\mathbb R\\), tem-se que \\[ P(X_1 \\in A_1, \\ldots, X_n\\in A_n) = \\prod_{i=1}^n P(X_i \\in A_i). \\] Definição 5.4 (caso discreto) No caso de variáveis aleatórios discretas, a definição anterior é equivalente à condição de que, para qualquer escolha de \\(x_1,\\ldots,x_n \\in \\mathbb R\\), tem-se que \\[ P(X_1 = x_1, \\ldots, X_n = x_n) = \\prod_{i=1}^n P(X_i=x_i). \\] Proposição 5.4 (Linearidade da esperança) Para quaisquer variáveis aleatórias \\(X_1,\\ldots,X_n\\), temos: \\[ E(X_1 + \\ldots + X_n) = E(X_1) + \\cdots + E(X_n) \\] Proposição 5.5 (Linearidade da variância) Sejam \\(X_1,\\ldots,X_n\\) variáveis aleatórias independentes, temos: \\[ Var(X_1 + \\ldots + X_n) = Var(X_1) + \\cdots + Var(X_n) \\] "],["fgm.html", "Capítulo 6 Função geradora de momentos 6.1 Momentos 6.2 Função geradora de momentos 6.3 Exemplos de \\(M_X(t)\\) para algumas distribuições comuns", " Capítulo 6 Função geradora de momentos 6.1 Momentos Definição 6.1 Seja \\(X\\) uma variável aleaória. Para \\(n \\geq 1\\) inteiro, definimos o n-ésimo momento de \\(X\\) como \\[ \\mu_{(n)} = E(X^n). \\] Observação. No caso em que \\(X\\) é uma v.a. discreta com função de probabilidade \\(p(x)\\), temos que \\[ \\mu_{(n)} = \\sum_{x: p(x)&gt;0} x^n p(x) \\] Observação. Note que para \\(n=1\\), temos que \\(\\mu_{(1)}\\) corresponde à média da v.a. \\(X\\) e, que a variância de \\(X\\) é uma função do primeiro e segundo momento, isto é, \\(Var(X) = \\mu_{(2)} - (\\mu_{(1)})^2\\). 6.2 Função geradora de momentos Definição 6.2 Seja \\(X\\) uma variável aleatória. Definimos a função geradora de momentos de \\(X\\) como: \\[ M_{X}(t) = E(e^{tX}), \\; t \\in \\mathbb{R}. \\] Proposição 6.1 Seja \\(X\\) uma variável aleatória, temos que \\[ M_{X}^{(n)}(t)|_{t=0} = E(X^n) \\] Prova. Procedemos por indução em \\(n\\) \\[\\begin{align*} M_X^{\\prime} (t)=\\frac{d}{dt}M_X(t) &amp;= \\frac{d}{dt}E(e^{tX})\\\\ &amp;=E(\\frac{d}{dt} e^{tX})\\\\ &amp;=E(Xe^{tX}) \\end{align*}\\] Assuma que \\(M^{(n-1)}(t)=\\frac{d^{n-1}}{dt^{n-1}} M_X(t) = E(X^{n-1} e^{tX})\\). Logo \\[\\begin{align*} M^{(n)}(t) &amp;= \\frac{d}{dt} M^{(n-1)}(t)\\\\ &amp;=\\frac{d}{dt}E(X^{n-1} e^{tX})\\\\ &amp;=E(\\frac{d}{dt} X^{n-1} e^{tX})\\\\ &amp;=E(X^n e^{tX}) \\end{align*}\\] Para finalizar a prova, basta avaliar \\(M^{(n)}_X(t)\\) em \\(t=0\\). 6.3 Exemplos de \\(M_X(t)\\) para algumas distribuições comuns Exemplo 6.1 (Bernoulli) Seja \\(X\\) uma v.a. e \\(0&lt;p&lt;1\\), tal que \\[p(0) = 1-p, \\; \\; p(1) = p.\\] Logo, para \\(t\\in\\mathbb R\\), a função geradora de momentos é dada por \\[\\begin{align*} M_{X}(t) &amp;= E(e^{tX}) \\\\ &amp;= e^{t\\cdot 0} \\times p(0) + e^{t\\cdot 1} \\times p(1) \\\\ &amp;= (1-p) + p e^{t}, \\; \\end{align*}\\] Exemplo 6.2 (Geométrica) Seja \\(X\\) uma v.a., cuja função de probabilidade é \\[ p(x) = (1-p)^{x-1}p, \\; x=1,2,\\ldots \\] Logo, para \\(t &lt; \\ln\\left(\\frac{1}{1-p}\\right)\\), a função geradora de momentos de \\(X\\) é \\[\\begin{align*} M_{X}(t) &amp;= E(e^{tX})\\\\ &amp;=\\sum_{x=1}^\\infty e^{tx} (1-p)^{x-1}p\\\\ &amp;=\\frac{p}{1-p} \\sum_{x=1}^\\infty e^{tx} (1-p)^{x}\\\\ &amp;=\\frac{p}{1-p} \\sum_{x=1}^\\infty [e^{t} (1-p)]^{x} \\\\ &amp;=\\frac{p}{1-p}\\cdot \\frac{e^{t} (1-p)}{1- e^{t} (1-p)}\\\\ &amp;=\\frac{p e^{t}}{1- e^{t} (1-p)} \\end{align*}\\] Exemplo 6.3 (Poisson) Seja \\(X\\) uma v.a. cuja função de probabilidade é \\[ p(x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}, \\; x=0,1,\\ldots \\] onde \\(\\lambda &gt;0\\) constante. Logo, para \\(t\\in\\mathbb R\\), a função geradora de momentos é dada por \\[\\begin{align*} M_X(t) &amp;= E(e^{tX})\\\\ &amp;=\\sum_{x=0}^\\infty e^{tx} \\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\ &amp;= e^{-\\lambda}\\sum_{x=0}^\\infty \\frac{(\\lambda e^t)^x}{x!}\\\\ &amp;=e^{-\\lambda} e^{\\lambda e^t}\\\\ &amp;=e^{-\\lambda(1-e^t)} \\end{align*}\\] Proposição 6.2 Sejam \\(a,b\\) constantes e \\(Y=aX+b\\), então \\[ M_Y(t) = e^{tb} M_X(ta) \\] Prova. \\[\\begin{align*} M_Y(t) &amp;= E(e^{t(aX+b)}) \\\\ &amp;=E(e^{(ta)X}e^{tb})\\\\ &amp;=e^{tb}E(e^{(ta)X})\\\\ &amp;=e^{tb}M_X(ta) \\end{align*}\\] "],["modelos-discretos.html", "Capítulo 7 Modelos de distribuições discretas 7.1 Distribuição Uniforme Discreta 7.2 Distribuição de Bernoulli 7.3 Distribuição Binomial 7.4 Distribuição Geométrica 7.5 Distribuição Binomial Negativa (Pascal) 7.6 Distribuição Hipergeométrica 7.7 Distribuição de Poisson 7.8 Aproximação de Poisson à Binomial", " Capítulo 7 Modelos de distribuições discretas Neste capítulo estudaremos vários modelos de distribuições de variáveis aleatórias discretas mais comuns. Ao longo do capítulo usaremos a notação \\(X\\sim\\mathcal D\\) para dizer que \\(X\\) “tem distribuição \\(\\mathcal D\\),” onde \\(\\mathcal D\\) é uma certa distribuição de probabilidade. 7.1 Distribuição Uniforme Discreta Definição 7.1 Dizemos que a v.a. \\(X\\) tem distribuição uniforme discreta sobre o conjunto \\(\\{x_1,\\ldots,x_n\\}\\subset \\mathbb R\\) se tem função de probabilidade dada por \\[ p(x_i) = \\frac{1}{n}, \\; i =1,2,\\ldots,n. \\] \\(X\\) é um elemento escolhido ao acaso no conjunto \\(\\{x_1,\\ldots,x_n\\}\\). Notação: \\(X\\sim\\) Uniforme discreta\\(\\{x_1,\\ldots,x_n\\}\\). Exemplo 7.1 Seja \\(X\\): Número observado no lançamento de um dado honesto, temos que \\[ p(i)=\\frac{1}{6}, \\; i=1,2,3,4,5,6. \\] Proposição 7.1 Seja \\(X\\sim\\) Uniforme discreta\\(\\{1,\\ldots,n\\}\\), então: \\[\\begin{align*} E(X) = \\frac{n+1}{2} \\text{ e } Var(X) = \\frac{(n-1)(n+1)}{12} \\end{align*}\\] Prova. \\[\\begin{align*} E(X) &amp;= \\frac{1}{n} \\sum_{i=1}^n i = \\frac{1}{n} \\frac{n(n+1)}{2} = \\frac{n+1}{2} \\\\ E(X^2) &amp;= \\frac{1}{n} \\sum_{i=1}^n i^2 = \\frac{1}{n} \\frac{n(n+1)(2n+1)}{6} \\\\ Var(X) &amp;= E(X^2) - [E(X)]^2 = \\frac{(n-1)(n+1)}{12} \\end{align*}\\] 7.2 Distribuição de Bernoulli Definição 7.2 (Ensaio de Bernoulli) Um ensaio de Bernoulli é um experimento com somente dois resultados possíveis: sucesso ou fracasso, de modo que a probabilidade de sucesso é igual a \\(p\\in[0,1]\\). Exemplo 7.2 Exemplos de ensaios de Bernoulli são: Lançamento de uma moeda: cara (sucesso) ou coroa (fracasso). Avaliação de um item: item bom (sucesso) ou item defeituoso (fracasso). Resposta de um munícipe sobre o favorecimento a um projeto de lei: sim (sucesso) ou não (fracasso). Dado um evento \\(A \\subset \\Omega\\) com espaço amostral \\(\\Omega\\) associado a um certo experimento aleatório, podemos definir um ensaio de Bernoulli, da seguinte maneira: dizemos que ocorre sucesso, se \\(A\\) ocorre, e dizemos que ocorre fracasso se, \\(A^c\\) ocorre. Por exemplo, considere o lançamento de um dado honesto e, defina \\(A=\\{6\\}\\): observar a face 5, logo \\(A^c=\\{1,2,3,4,5\\}\\). No exemplo, a probabilidade de sucesso é \\(p=1/6\\). Considere um ensaio de Bernoulli, e defina a v.a. \\(X \\in \\{0,1\\}\\) com distribuição de probabilidade: \\[P(X=1)=p \\text{ e } P(X=0)=1-p,\\] de modo que \\(\\{X=1\\}\\) corresponde ao evento em que ocorreu sucesso e o evento \\(\\{X=0\\}\\) corresponde ao evento em que ocorreu fracasso. Dizemos que \\(X\\) é a da ocorrência de sucesso em um ensaio de Bernoulli. No exemplo do lançamento do dado, temos: \\[ X(\\omega)=\\begin{cases} 1, &amp; \\omega \\in A =\\{6\\}, \\\\ 0, &amp; \\omega \\in A^c=\\{1,2,3,4,5\\} \\end{cases} \\] Definição 7.3 A variável aleatória \\(X\\) definida como a indicadora da ocorrência de sucesso em um ensaio de Bernoulli tem uma distribuição de Bernoulli com parâmetro \\(p\\), cuja função de probabilidade de \\(X\\) é dada por: \\[ p(x) = p^x (1-p)^{1-x}, \\; x=0,1. \\] Notação: \\(X \\sim\\) Bernoulli(\\(p\\)), onde \\(p\\) é chamado de parâmetro de sucesso. Exemplo 7.3 A continuação apresentamos alguns exemplos de variáveis aleatórias com distribuição de Bernoulli: Uma pessoa é selecionada ao acaso entre os moradores de uma cidade, e pergunta-se a ela se concorda com um projeto municipal. As respostas possíveis são SIM (sucesso) ou NÃO (fracasso). Defina: \\[ X=\\begin{cases} 1, &amp; \\text{se a pessoa responde SIM}, \\\\ 0, &amp; \\text{se a pessoa responde NÃO} \\end{cases} \\] No lançamento de uma moeda. Defina: \\[ X=\\begin{cases} 1, &amp; \\text{se sair cara}, \\\\ 0, &amp; \\text{se sair coroa} \\end{cases} \\] Na inspecção de um item de um lote. Defina: \\[ X=\\begin{cases} 1, &amp; \\text{se o item for defeituoso}, \\\\ 0, &amp; \\text{se o item não for defeituoso} \\end{cases} \\] Proposição 7.2 Seja \\(X\\sim\\) Bernoulli(\\(p\\)), temos que \\[ E(X) = p \\text{ e } Var(X) = p(1-p) \\] Prova. \\[\\begin{align*} E(X) &amp;= \\sum_{x=0}^1 x\\, p^x (1-p)^{1-x} = p\\\\ E(X^2) &amp;= \\sum_{x=0}^1 x^2 \\, p^x (1-p)^{1-x} = p \\\\ Var(X) &amp;= E(X^2) - [E(X)]^2 = p-p^2= p(1-p) \\end{align*}\\] 7.3 Distribuição Binomial A distribuição binomial, surge da realização sucessiva de \\(n\\geq 1\\) ensaios independentes de Bernoulli. Por exemplo, considere o experimento de lançar uma moeda honestas 10 vezes esse experimento tem as seguintes características: O experimento lançar uma moeda é um ensaio de Bernoulli. O experimento é realizado 3 vezes. Todos os 3 ensaios são idênticos e independentes. A probabilidade \\(p=1/2\\) de obter uma cara, é constante em todos os ensaios. Nesse experimento, definimos a variável aleatória, \\(X\\), definida como o número de caras obtidas nos 3 lançamentos. Sob as condições do experimento podemos determinar a função de probabilidade de \\(X\\). Podemos determinar que a função de probabilidade de \\(X\\) é: \\[ p(x) = \\binom{3}{x}(1/2)^x(1/2)^{n-x}, \\; x=0,1,2,3. \\] Explicação: \\(\\binom{3}{x}\\): corresponde ao número de maneiras de escolher 2 caras. \\((1/2)^{x}\\): corresponde à probabilidade de observar \\(x\\) caras nos \\(n\\) lançamentos (multiplicamos as probabilidades pois os ensaios são independentes). \\((1/2)^{n-x}\\): corresponde à probabilidade de observar \\(n-x\\) coroas nos \\(n\\) lançamentos (multiplicamos as probabilidades pois os ensaios são independentes). Repare que se \\(X\\sim\\) Binomial(\\(n,p\\)), então \\(X= X_1 + \\ldots + X_n\\), onde \\(X_1,\\ldots,X_n \\overset{iid}{\\sim}\\) Bernoulli(\\(p\\)). De modo que \\(X_i = 1\\) se o \\(i\\)-ésimo ensaio for sucesso ou \\(X_i=0\\) se o \\(i\\)-ésimo ensaio for fracasso. Definição 7.4 Considere \\(n\\geq 1\\) ensaios independentes de Bernoulli e seja \\(p\\) a probabilidade de sucesso em cada ensaio. Logo, a variável aleatória \\(X\\) definida como o número de sucessos nos \\(n\\) ensaios tem uma distribuição binomial de parâmetros \\(n\\) e \\(p\\), cuja função de probabilidade é dada por \\[ p(x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\, x=0,1,\\ldots,n. \\] Notação: \\(X\\sim\\) Binomial(\\(n,p\\)). Observação. Note que pelo Teorema Binomial \\(p(x)\\) é de fato uma função de probabilidade. Com efeito: \\[ \\sum_{x=0}^n \\binom{n}{x} p^x (1-p)^{n-x} = (p+(1-p))^n = 1. \\] Proposição 7.3 Seja \\(X\\sim\\)Binomial(\\(n,p\\)), temos que \\[ E(X) = np \\text{ e } Var(X) = np(1-p) \\] Prova. Usamos o fato que \\(X=\\sum_{i=1}^n X_i\\), em que cada \\(X_1, \\ldots, X_n \\sim\\) Bernoulli(\\(p\\)) independentes. Logo \\[\\begin{align*} E(X) = \\sum_{i=1}^n E(X_i) = np, \\\\ Var(X) = \\sum_{i=1}^n Var(X_i) = np(1-p). \\end{align*}\\] Exemplo 7.4 Suponha que 60% da população de uma cidade é a favor de um projeto proposto pelo prefeito. Seleciona-se uma amostra aleatória de 15 pessoas. Qual a probabilidade de que a amostra contenha no máximo duas pessoas favoráveis ao projeto? Quais são o valor esperado e variância do número de pessoas a favor do projeto na amostra? Solução. Seja \\(X\\) o número de pessoas favoráveis ao projeto na amostra. Então, \\(X\\sim\\) Binomial(15,0.6). \\(P(X\\leq 2) = \\binom{15}{0} (0.6)^0 (0.4)^{15} + \\binom{15}{1} (0.6)^1 (0.4)^{14} + \\binom{15}{0} (0.6)^2 (0.4)^{13}\\) \\(E(X) = 15 \\times 0.6 = 9\\) e \\(Var(X)= 15 \\times 0.6 \\times 0.4 =3.6\\). Proposição 7.4 Seja \\(X\\sim\\) Binomial(\\(n,p\\)), então, à medida que \\(x\\) varia de 0 a \\(n\\), \\(p(x)\\) primeiro cresce e depois decresce, atingindo seu valor máximo quando \\(x=\\lfloor (n+1)p \\rfloor\\): maior inteiro menor ou igual que \\((n+1)p\\). 7.4 Distribuição Geométrica Definição 7.5 Consideremos um ensaio de Bernoulli com probabilidade de sucesso \\(p\\) e realizações sucessivas e independentes desse experimento até que ocorra o primeiro sucesso. A variável aleatória definida como o número de ensaios necessários até o primeiro sucesso tem uma distribuição geométrica de parâmetro \\(p\\), cuja função de probabilidade é dada por \\[ p(x) = (1-p)^{x-1}p, \\; x=1,2,3,\\ldots \\] Notação: \\(X\\sim\\) Geom(\\(p\\)) Observação. Pela série geométrica vemos que \\(p(x)\\) é de fato uma função de probabilidade. Com efeito: \\[ \\sum_{x=1}^\\infty (1-p)^{x-1}p = p\\sum_{x=0} (1-p)^x = p \\times \\frac{1}{1-(1-p)} =1. \\] Proposição 7.5 Seja \\(X\\sim\\) Geom(\\(p\\)), temos que \\[ E(X) = \\frac{1}{p} \\text{ e } Var(X) = \\frac{1-p}{p^2} \\] Prova. Seja \\(q=1-p\\), logo \\[\\begin{align*} E(X) &amp;= \\sum_{x=1}^\\infty x q^{x-1} p \\\\ &amp;= \\sum_{x=1}^\\infty (x-1 + 1) q^{x-1} p \\\\ &amp;= \\sum_{x=1}^\\infty (x-1) q^{x-1} p + \\sum_{x=1}^\\infty q^{x-1} p \\\\ &amp;= q\\sum_{y=0}^\\infty y q^{y-1} p + 1 \\\\ &amp;= q E(X) + 1. \\end{align*}\\] Daí, \\((1-q) E(X)= 1 \\Rightarrow E(X) = \\frac{1}{p}\\). \\[\\begin{align*} E(X^2) &amp;= \\sum_{x=1}^\\infty x^2 q^{x-1}p \\\\ &amp;= \\sum_{x=1}^\\infty (x-1 + 1)^2 q^{x-1}p \\\\ &amp;= \\sum_{x=1}^\\infty (x-1)^2 q^{x-1}p + 2 \\sum_{x=1}^\\infty (x-1) q^{x-1}p + \\sum_{x=1}^\\infty q^{x-1}p \\\\ &amp;= q\\sum_{y=0}^\\infty y^2 q^{y-1} p + 2q \\sum_{y=0}^\\infty yq^{y-1}p + 1 \\\\ &amp;=qE(X^2) + 2q E(X) + 1. \\end{align*}\\] Daí, \\(pE(X^2) = \\frac{2q}{p} +1 \\Rightarrow E(X^2) = \\frac{2q+p}{p^2} = \\frac{q+1}{p^2}\\). Portanto, \\[ Var(X) = E(X^2) - [E(X)]^2= \\frac{q+1}{p^2} - \\frac{1}{p^2} = \\frac{q}{p^2} = \\frac{1-p}{p^2}. \\] Exemplo 7.5 Um dado honesto é lançado repetidamente, de modo independente, até que se obtenha a face 6. Determine: a probabilidade de que sejam necessários exatamente 5 lançamentos. a probabilidade de que sejam necessários pelo menos 4 lançamentos. a esperança e variância do número de lançamentos feitos. Solução. Seja \\(X:\\) Número de lançamentos feitos até obter a face 6. Então, \\(X\\sim\\) Geométrica(\\(p = 1/6\\)). \\(P(X=5)= \\left(\\frac{1}{6}\\right)\\left(\\frac{5}{6}\\right)^4 = \\frac{5^4}{6^5} \\approx 0.0804\\). \\(P(X\\geq 4) = \\sum_{x=4}^\\infty \\left(\\frac{1}{6}\\right)\\left(\\frac{5}{6}\\right)^{x-1} = \\left(\\frac{5}{6}\\right)^3 \\approx 0.5787.\\) \\(E(X)=\\frac{1}{1/6} = 6\\) e \\(Var(X)=\\frac{5/6}{(1/6)^2} = 30\\). 7.5 Distribuição Binomial Negativa (Pascal) Definição 7.6 Consideremos um ensaio de Bernoulli com probabilidade de sucesso \\(p\\) e realizações sucessivas e independentes desse experimento até que ocorra o \\(r\\)-ésimo sucesso. A variável aleatória definida como o número de ensaios necessários até o \\(r\\)-ésimo sucesso tem uma distribuição binomial negativa de parâmetros \\(r\\) e \\(p\\), cuja função de probabilidade é dada por \\[ p(x) = \\binom{x-1}{r-1} p^r(1-p)^{x-r}, \\; x=r,r+1,\\ldots \\] Notação: \\(X \\sim\\) BN(\\(r,p\\)) Observação. Seja \\(y=x-r\\), \\(x=r,r+1\\ldots\\) , \\[\\begin{align*} \\binom{x-1}{r-1} &amp;= \\binom{y+r-1}{r-1} \\\\ &amp;=\\frac{(y+r-1)\\cdots r (r-1)!}{(r-1)! y!}\\\\ &amp;=\\frac{(y+r-1)\\cdots r}{y!} \\\\ &amp;=(-1)^y \\frac{(-r)\\cdots (-y-r+1)}{y!}\\\\ &amp;=(-1)^y\\binom{-r}{y} \\end{align*}\\] Daí, o nome de binomial negativa. Da observação anterior se \\(X\\sim\\) BN(\\(r,p\\)), então pode-se escrever a função de probabilidade de \\(X\\) como \\[ p(x) = (-1)^{x-r} \\binom{-r}{x-r}p^rq^{x-r}, \\; x=r,r+1,\\ldots \\] onde \\(q=1-p\\). Observação. Da série binomial \\[ (1+x)^\\beta = \\sum_{y=0}^\\infty \\binom{\\beta}{y} x^y, \\] temos que \\[ p^{-r} = (1-q)^{-r} = \\sum_{y=0}^\\infty \\binom{-r}{y} (-q)^y, \\] Agora, é facil mostrar que \\(p(x)\\) é de fato uma função de probabilidade \\[\\begin{align*} \\sum_{x=r}^\\infty (-1)^{x-r} \\binom{-r}{x-r}p^rq^{x-r} &amp;=\\sum_{y=0}^\\infty (-1)^y \\binom{-r}{y}p^rq^y\\\\ &amp;= \\sum_{y=0}^\\infty \\binom{-r}{y} (-q)^y p^r = p^{-r} p^r = 1. \\end{align*}\\] Observação. Repare que se \\(X\\sim\\) BN(\\(r,p\\)), então \\(X=\\sum_{i=1}^r X_i\\), tal que \\(X_1,\\ldots,X_r \\overset{iid}{\\sim}\\) Geom(\\(p\\)). A interpretação é a seguinte: \\(X_1\\) representa o número de ensaios até o primeiro sucesso, \\(X_2\\) representa o número de ensaios necessários depois do primeiro sucesso para obter o segundo sucesso e assim por diante. Proposição 7.6 Seja \\(X\\sim\\) BN(\\(r,p\\)), temos que \\[ E(X) = \\frac{r}{p} \\text{ e } Var(X) = \\frac{r(1-p)}{p^2} \\] Prova. \\(X=\\sum_{i=1}^r X_i\\), tal que \\(X_1,\\ldots,X_r\\overset{iid}{\\sim}\\) Geom(\\(p\\)), logo \\[\\begin{align*} E(X) &amp;= \\sum_{i=1}^r E(X_i) = \\frac{r}{p}, \\\\ Var(X) &amp;= \\sum_{i=1}^r Var(X_i) = \\frac{r(1-p)}{p^2}. \\end{align*}\\] Exemplo 7.6 Um dado honesto é lançado repetidamente, de modo independente, até que a face 6 seja obtida 4 vezes. Qual a probabilidade de que sejam necessários exatamente 10 lançamentos? Solução. \\(X:\\) Número de lançamentos necessários até que a face 6 seja obtida 4 vezes. Então \\(X\\sim\\) Binomial Negativa(\\(r=4,p=1/6\\)). Logo \\[ P(X=10) = p(10) = \\binom{10-1}{4-1} (1/6)^4(5/6)^{6} = \\binom{9}{3} (1/6)^4(5/6)^{6} \\approx 0,0217. \\] 7.6 Distribuição Hipergeométrica Definição 7.7 Considere uma urna com \\(N\\) bolas das quais \\(R\\leq N\\) são vermelhas e \\(N-R\\) são pretas. Suponha que selecionamos uma amostra de tamanho \\(n\\leq N\\) sem reposição. A variável aleatória definida como o número de bolas vermelhas selecionadas na amostra tem uma distribuição hipergeométrica de parâmetros \\(n\\), \\(R\\) e \\(N\\) cuja função de probabilidade é dada por \\[ p(x) = \\frac{\\binom{R}{x} \\binom{N-R}{n-x}}{\\binom{N}{n}}, \\; x=0,1,\\ldots n. \\] Notação: \\(X\\sim\\) Hipergeométrica(\\(n,R,N\\)). Observação. Embora tenhamos definido \\(p(x)\\) para qualquer \\(x\\) entre 0 e \\(n\\) simplesmente por mera conveniência, o verdadeiro suporte da distribuição são os valores de \\(x\\) inteiros tais que \\(\\textrm{máx}(0,n-(N-R))\\leq x \\leq \\textrm{mín}(n,R).\\) Exemplo 7.7 Um aluno estuda 12 exercícios, dos quais o professor vai escolher 6 aleatoriamente para uma prova. O estudante sabe resolver 9 dos 12 problemas. Seja \\(X\\) o número de exercícios resolvidos por ele na prova. Qual a distribuição de \\(X\\)? Calcule a probabilidade de que o aluno resolva ao menos 5 exercícios da prova. Solução. Seja X: Número de exercícios resolvidos pelo estudante na prova. \\(X\\sim\\) Hipergeométrica(6,9,12). \\(P(X\\geq 5) = p(5) + p(6) = 1/2.\\) Proposição 7.7 Seja \\(X\\sim\\) Hipergeométrica(\\(n,R,N\\)) e seja \\(p=\\frac{R}{N}\\), então \\[ E(X)=np \\text{ e } Var(X) = \\left(\\frac{N-n}{N-1}\\right) np(1-p) \\] Prova. Seja \\(p=\\frac{R}{N}\\), \\[\\begin{align*} E(X) &amp;= \\sum_{x=1}^n x \\frac{\\binom{R}{x} \\binom{N-R}{n-x}}{\\binom{N}{n}} \\end{align*}\\] Usando as identidades \\[\\begin{align*} x\\binom{R}{x} = R \\binom{R-1}{x-1} \\text{ e } n\\binom{N}{n} = N \\binom{N-1}{n-1} \\end{align*}\\] obtemos \\[\\begin{align*} E(X) &amp;=\\frac{nR}{N} \\sum_{x=1}^n \\end{align*}\\] 7.7 Distribuição de Poisson Definição 7.8 Uma variável aleatória tem distribuição de Poisson de parâmetro \\(\\lambda &gt;0\\) se sua função de probabilidade é \\[ p(x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\; x=0,1,2, \\ldots \\] Notação: \\(X\\sim\\) Poisson(\\(\\lambda\\)) Exemplo 7.8 Alguns exemplos de variáveis que podem ser modeladas por uma distribuição de Poisson são: O número de erros de impressão em uma página. O número de clientes que chegam em uma agência bancária. O número de gols na copa do mundo. O número de partículas \\(\\alpha\\) emitidas por um material radioativo em um período de tempo determinado. Observação. Geralmente a distribuição de Poisson é usada para modelar uma contagem de indivíduos que se distribuem aleatoriamente no tempo ou no espaço. Proposição 7.8 Seja \\(X\\sim\\) Poisson(\\(\\lambda\\)), temos que \\[ E(X) = \\lambda \\text{ e } Var(X)=\\lambda \\] Prova. \\[\\begin{align*} E(X) &amp;=\\sum_{x=0}^\\infty x \\frac{e^{-\\lambda} \\lambda^x}{x!} \\\\ &amp;=\\sum_{x=1}^\\infty \\frac{e^{-\\lambda} \\lambda^x}{(x-1)!}\\\\ &amp;= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda} \\lambda^{x-1}}{(x-1)!}\\\\ &amp;= \\lambda \\sum_{y=0}^\\infty \\frac{e^{-\\lambda} \\lambda^y}{y!}\\\\ &amp;=\\lambda. \\end{align*}\\] \\[\\begin{align*} E(X^2) &amp;=\\sum_{x=0}^\\infty x^2 \\frac{e^{-\\lambda} \\lambda^x}{x!} \\\\ &amp;=\\lambda \\sum_{x=1}^\\infty x \\frac{e^{-\\lambda} \\lambda^{x-1}}{(x-1)!} \\\\ &amp;= \\lambda \\sum_{y=0}^\\infty (y+1) \\frac{e^{-\\lambda} \\lambda^y}{y!}\\\\ &amp;= \\lambda \\left[\\sum_{y=0}^\\infty y \\frac{e^{-\\lambda} \\lambda^y}{y!} + \\sum_{y=0}^\\infty \\frac{e^{-\\lambda} \\lambda^y}{y!} \\right]\\\\ &amp;=\\lambda(\\lambda + 1). \\end{align*}\\] Portanto, \\(Var(X) = \\lambda(\\lambda + 1) - \\lambda^2 = \\lambda\\). Exemplo 7.9 Suponha que o número de erros tipográficos em uma única página deste livro tenha uma distribuição de Poisson com \\(\\lambda = 1/2\\). Calcule a probabilidade de que exista pelo menos um erro nesta página. Solução. Seja \\(X\\): Número de erros nesta página, logo \\[ P(X\\geq 1) = 1- P(X\\leq 0) = 1-e^{-1/2} \\approx 0,393. \\] Exemplo 7.10 O número de partículas que uma fonte radioativa emite por minuto é uma variável aleatória com distribuição de Poisson com média igual a 5. Qual a probabilidade de que pelo menos três partículas sejam emitidas em um minuto. Solução. \\[ P(X\\geq 3) = 1-e^{-5}-5e^{-5} -\\frac{5^2e^{-5}}{2!} = 1-\\frac{37}{2}e^{-5} \\approx 0,8753. \\] 7.8 Aproximação de Poisson à Binomial Seja \\(X\\sim\\) Binomial(\\(n,p\\)), com \\(n\\) grande e \\(p\\) pequeno, de modo que o valor \\(\\lambda = np\\) é moderado. E seja \\(Y\\sim\\) Poisson(\\(\\lambda=np\\)), então para qualquer inteiro \\(x\\) entre 0 e \\(n\\), \\[ P(X=x) \\approx P(Y=x) = \\frac{e^{-np} (np)^x}{x!} \\] Essa aproximação decorre do Teorema de Poisson (1832). Observação. Empiricamente, temos as seguintes regras práticas: \\(n\\geq 20\\) e \\(p\\leq 0,05\\) ou \\(n\\geq 100\\) e \\(np \\leq 10\\) Exemplo 7.11 Seja \\(X\\sim\\) Binomial(100,0.065) \\[ P(X=10) = \\binom{100}{10} (0.065)^{10}(0.935)^{90} \\approx 0.05502 \\] Pela aproximação de Poisson à Binomial, usamos \\(Y\\sim\\) Poisson(\\(100\\times 0.065 = 6.5\\)), logo \\[ P(X=10) \\approx P(Y=10) = \\frac{e^{-6.5} (6.5)^{10}}{10!} \\approx 0.05578 \\] "],["vas-continuas.html", "Capítulo 8 Variáveis aleatórias contínuas 8.1 Função de distribuição 8.2 Obtenção de \\(f\\) a partir de \\(F\\) 8.3 Percentis de uma variável aleatória contínua 8.4 Esperança de uma variável aleatória contínua 8.5 Esperança de uma função de uma v.a. contínua 8.6 Variância de uma variável aleatória contínua 8.7 Função geradora de momentos de uma variável aleatória contínua", " Capítulo 8 Variáveis aleatórias contínuas Lembre que uma variável aleatória é dita contínua se assume valores em um intervalo de \\(\\mathbb R\\). Por exemplo, o tempo de vida de um aparelho eletrônico, a temperatura em um determinado dia, a altura de uma pessoa ou o peso de um bebê recém-nascido. Para caracterizar uma variável aleatória usamos a chamada função de densidade, definida a continuação: Definição 8.1 (Função de densidade) Uma função \\(f:\\mathbb R \\rightarrow \\mathbb R\\), é uma função de densidade se satisfaz as seguintes condições: \\(f(x) \\geq 0\\), para qualquer \\(x\\in\\mathbb R\\) \\(\\int_{-\\infty}^\\infty f(x) dx = 1\\). Definição 8.2 Dizemos que \\(X\\) é uma variável (absolutamente) contínua se existir uma função de densidade \\(f\\) tal que para qualquer \\(A \\subset \\mathbb R\\) \\[ P(X\\in A) = \\int_{A} f(x) dx \\] Por exemplo, se quisermos calcular a probabilidade de \\(X\\) pertencer a um intervalo da reta \\([a,b]\\), basta calcular: \\[ P(a\\leq X \\leq b)=\\int_a^b f(x) dx. \\] Exemplo 8.1 Verifique se as seguintes funções são funções de densidade: \\[\\begin{align*} f(x) = \\begin{cases} \\frac{1}{2}, \\; 0 \\leq x \\leq 2\\\\ 0, \\text{caso contrário}. \\end{cases} \\end{align*}\\] \\[\\begin{align*} f(x) = \\begin{cases} e^{-x}, \\; x &gt; 0 \\\\ 0, \\text{caso contrário} \\end{cases} \\end{align*}\\] Apresentamos os gráficos das funções em a. e b., a seguir: Solução. Claramente as funções acima são não negativas para qualquer valor de \\(x\\). Agora, vamos verificar se integram 1. Com efeito: \\[\\begin{align*} \\int_{0}^2 \\frac{1}{2} dx &amp;= \\frac{1}{2} \\left. x\\right|_{0}^{2} \\\\ &amp;= \\frac{1}{2} \\times 2 =1 \\end{align*}\\] \\[\\begin{align*} \\int_0^\\infty e^{-x} dx &amp;= \\left.-e^{-x}\\right|_{0}^\\infty \\\\ &amp;= -(e^{-\\infty} - 1) = 1. \\end{align*}\\] Portanto, as duas funções são funções de densidade. Exemplo 8.2 Suponha que \\(X\\) seja uma variável aleatória contínua cuja função de densidade é dada por \\[ f(x) = \\begin{cases} c(4x - 2x^2) &amp; 0&lt;x&lt;2,\\\\ 0 &amp; \\text{caso contrário} \\end{cases} \\] Qual o valor de \\(c\\)? Determine \\(P(X&gt;1).\\) Solução. Para responder à letra a. usamos o fato que \\(\\int_{-\\infty}^\\infty f(x)=1\\). Com efeito, \\[\\begin{align*} c\\int_0^2 (4x - 2x^2) dx=1, \\end{align*}\\] logo, \\[\\begin{align*} c \\left[2x^2 - \\frac{2x^3}{3}\\right]_{0}^{2} &amp;= 1\\\\ c \\left[8 - \\frac{16}{3}\\right] = 1 \\iff c \\left(\\frac{8}{3}\\right) = 1. \\end{align*}\\] Portanto, \\(c=\\frac{3}{8}\\). \\[\\begin{align*} P(X &gt; 1) = \\int_{1}^{2} \\frac{3}{8} (4x - 2x^2) = 0.5. \\end{align*}\\] Exemplo 8.3 A quantidade de tempo em horas que a bateria de um smartphone funciona sem desligar é uma variável aleatória contínua com função de densidade dada por \\[ f(x) = \\begin{cases} \\frac{1}{10} e^{-1/10}, \\; x &gt; 0,\\\\ 0, \\text{caso contrário} \\end{cases} \\] Qual a probabilidade de que o smartphone funcione entre 5 e 15 horas antes de desligar? ele funciones menos de 10 horas? Solução. Seja \\(X\\): A quantidade de tempo em horas que a bateria de um smartphone funciona sem desligar. \\[\\begin{align*} P(10 &lt; X &lt; 15) &amp;= \\int_5^{15} \\frac{1}{10} e^{-x/10} dx \\\\ &amp;=\\left. -e^{-x/10} \\right|_5^15 = -e^{-3/2} + e^{-1/2} \\approx 0,384. \\end{align*}\\] \\[P(X&lt;10) = \\int_{0}^10 \\frac{1}{10} e^{-x/10} dx = \\left. -e^{-x/10}\\right|_0^10 = 1-e^{-1} \\approx 0,633.\\] Observação. Note que a probabilidade de que uma variável aleatória contínua assuma qualquer valor especifíco é zero, ou seja, se \\(a\\in\\mathbb R\\), então \\(P(X=a)=0\\), pois \\[ P(X=a)=\\int_a^a f(x) dx= 0. \\] Da anterior observação podemos concluir que para \\(a,b\\in\\mathbb R\\) com \\(a&lt;b\\), tem-se que \\[ P(a&lt;X&lt;b) = P(a&lt;X\\leq b) = P(a \\leq X&lt; b)=P(a&lt;X&lt;b). \\] 8.1 Função de distribuição Recorde que a função de distribuição de uma variável aleatória é definida por \\(F(x) = P(X\\leq x)\\), para qualquer \\(x\\in\\mathbb R\\). No caso em que \\(X\\) é uma variável contínua, tem-se que \\[ F(x) = \\int_{-\\infty}^x f(t)dt. \\] Observação. Note que \\(P(a \\leq X \\leq b) = F(b) - F(a)\\). 8.2 Obtenção de \\(f\\) a partir de \\(F\\) Anteriormente, definimos a função de distribuição de uma variável aleatória continua como: \\[ F(x) = \\int_{-\\infty}^x f(t) dt. \\] Ou seja, mostramos como pode-se obter a função de distribuição a partir do conhecimento da função de densidade. O seguinte teorema mostra como pode-se obter a função de densidade a partir da função de distribuição. Teorema 8.1 Se \\(F(x)\\) é a função de distribuição de uma variável aleatória contínua \\(X\\), então \\(f(x)\\) é dada por \\[ f(x) =F^\\prime(x), \\] sempre que exista a derivada. Exemplo 8.4 Suponha que \\[ F(x) = \\begin{cases} 0, \\; x&lt;0 \\\\ x, \\; 0\\leq x \\leq 1 \\\\ 1, \\; x&gt;1 \\end{cases} \\] Logo, \\[ f(x) =F&#39;(x) = \\begin{cases} 0, \\; x&lt;0 \\\\ 1, \\; 0\\leq x \\leq 1 \\\\ 0, \\; x&gt;1 \\end{cases} \\] Exemplo 8.5 Se \\(X\\) é uma variável aleatoria com função de densidade dada por \\[ f(x) = \\begin{cases} 3x^2, \\; 0\\leq x \\leq 1 \\\\ 0, \\; \\text{caso contrário} \\end{cases} \\] Encontre \\(F(x)\\). Solução. Como \\[ F(x) = \\int_{-\\infty}^x f(t) dt, \\] temos que \\[\\begin{align*} F(x)=\\begin{cases} 0, \\; x &lt;0, \\\\ x^3, \\; 0\\leq x\\leq 1, \\\\ 1 \\; x&gt;1 \\end{cases} \\end{align*}\\] 8.3 Percentis de uma variável aleatória contínua Quando dizemos que o salário de um indivíduo esteve no 85-ésimo percentil de uma empresa, queremos dizer que 85% dos salários de toda a empresa estiveram por abaixo desse salário e 15% por em cima. Definição 8.3 Seja \\(p\\in (0,100)\\) um número inteiro. O \\(p\\)-ésimo percentil da distribuição \\(F\\) de uma variável aleatória contínua \\(X\\), denotado por \\(\\eta(p)\\) é definido por \\[ \\frac{p}{100}= F(\\eta(p)) = \\int_{-\\infty}^{\\eta(p)} f(x) dx \\] O 50-ésimo percentil da distribuição \\(F\\) de \\(X\\) chama-se a de \\(F\\) (ou de \\(X\\)), e é denotado por \\(\\tilde{\\mu}\\). Observação. \\(\\eta(p)\\) é o valor no eixo horizontal, tal que \\(p\\)% da área sob o gráfico de \\(f\\) está à esquerda de \\(\\eta(p)\\) e \\((100-p)\\)% está à direita. Exemplo 8.6 A função de distribuição de uma variável aleatória contínua \\(X\\) é \\[\\begin{align*} F(x) = \\begin{cases} 0, &amp; x&lt;0,\\\\ \\frac{x}{2}, &amp; 0 \\leq x \\leq 2 \\\\ 1, &amp; x&gt;2 \\end{cases} \\end{align*}\\] Determine a mediana, \\(\\tilde{\\mu}\\), de \\(F\\). Solução. A mediana \\(\\tilde{\\mu}\\) deve satisfazer a relação \\(0,5 = F(\\tilde\\mu)\\), logo \\(0,5=\\frac{\\tilde\\mu}{2}\\), portanto \\(\\tilde\\mu =1\\). Exemplo 8.7 A função de distribuição de uma variável aleatória contínua \\(X\\) é \\[\\begin{align*} F(x) = \\begin{cases} 1-e^{-2x}, &amp; x\\geq 0,\\\\ 0, &amp; x&lt;0 \\end{cases} \\end{align*}\\] Determine a mediana, \\(\\tilde{\\mu}\\), de \\(F\\). Solução. A mediana \\(\\tilde\\mu\\) satisfaz \\(0.5 = F(\\tilde\\mu)\\), logo \\(0,5=1-e^{-2\\tilde\\mu}\\), portanto \\(\\tilde\\mu = \\frac{\\ln(2)}{2}\\) 8.4 Esperança de uma variável aleatória contínua No capítulo 5, definimos a esperança de uma variável aleatória discreta, \\(X\\), como a soma (sobre os valores de \\(x\\)) do produto \\(x p(x)\\), onde \\(p(x)\\) é a função de probabilidade de \\(X\\). No caso contínuo procederemos de maneira semelhante, porém trocaremos a soma por uma integral e a função de probabilidade pela função de densidade. Daí, temos a seguinte definição. Definição 8.4 Seja \\(X\\) uma variável aleatória contínua com função de densidade \\(f\\), definimos a esperança (valor esperado ou média) de \\(X\\) como \\[ \\mu=E(X)=\\int_{-\\infty}^\\infty x f(x) dx \\] Exemplo 8.8 Considere uma variável aleatória contínua \\(X\\), cuja função de densidade é dada por \\[\\begin{align*} f(x) = \\begin{cases} 1, &amp; 0\\leq x \\leq 1 \\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\end{align*}\\] Encontre \\(E(X)\\). Solução. \\[\\begin{align*} E(X) &amp;= \\int_{0}^1 x dx \\\\ &amp;=\\left.\\frac{x^2}{2}\\right|_0^1 \\\\ &amp;=\\frac{1}{2}. \\end{align*}\\] Exemplo 8.9 Seja \\(X\\) o tempo de vida útil, em meses, de uma lâmpada, cuja função de densidade é dada por \\[\\begin{align*} f(x) = \\begin{cases} e^{-x} &amp; x\\geq 0 \\\\ 0 &amp; \\text{caso contrário} \\end{cases} \\end{align*}\\] Determine \\(E(X)\\). Solução. Procederemos por integração por partes. Seja \\(u=x\\) e \\(dv=e^{-x}\\), logo \\(du=dx\\) e \\(v=-e^{-x}\\) \\[\\begin{align*} E(X) &amp;= \\int_0^\\infty x e^{-x}\\\\ &amp;=\\left.-xe^{-x}\\right|_0^\\infty + \\int_0^\\infty e^{-x} dx \\\\ &amp;=\\left. -e^{-x}\\right|_0^\\infty\\\\ &amp;=1. \\end{align*}\\] 8.5 Esperança de uma função de uma v.a. contínua Suponha que \\(X\\) seja uma variável aleatória contínua e consideremos a variável aleatória \\(h(X)\\) onde \\(h\\) é uma função a valores reais. Logo, podemos calcular a esperança de \\(h(X)\\) através da seguinte proposição. Proposição 8.1 Seja \\(X\\) uma variável aleatória contínua com função de densidade \\(f(x)\\) e \\(h\\) uma função a valores reais, então \\[ E(h(X)) = \\int_{-\\infty}^\\infty h(x)f(x) dx. \\] A anterior proposição é a lei do estatístico inconsciente no caso contínuo. Exemplo 8.10 Duas espécies competem em uma região para controlar uma limitada quantidade de certo recurso. Seja \\(X\\) a v.a. contínua que representa a proporção do recurso controlado pela primeira especie, e suponha que a função de densidade de \\(X\\) é \\[ f(x) = \\begin{cases} 1, &amp; 0 \\leq x\\leq 1 \\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\] Seja \\(h(X)\\) a maior proporção controlada por uma das especies. Calcule a \\(E(h(X))\\). Solução. \\[\\begin{align*} h(X) = \\max\\{X,1-X\\} = \\begin{cases} 1-X, &amp; 0\\leq X\\leq 1/2 \\\\ X, &amp; 1/2\\leq X \\leq 1 \\end{cases} \\end{align*}\\] \\[\\begin{align*} E(h(X)) &amp;= \\int_0^{1/2} (1-x) dx + \\int_{1/2}^{1} x dx\\\\ &amp;= \\left[ x - \\frac{x^2}{2}\\right]_0^{1/2} + \\left.\\frac{x^2}{2}\\right|_{1/2}^{1} = \\frac{3}{4}. \\end{align*}\\] 8.6 Variância de uma variável aleatória contínua Lembre que no caso discreto definimos a variância de uma variável aleatória discreta com função de probabilidade \\(p(x)\\) e média \\(\\mu\\) como a soma dos produtos \\((x-\\mu)^2 p(x)\\). Em caso que \\(X\\) seja uma v.a. contínua definimos a variância de \\(X\\) como segue. Definição 8.5 Seja \\(X\\) uma v.a. contínua com função de densidade \\(f(x)\\) e média \\(\\mu\\), a variância de \\(X\\) é dada por \\[\\begin{align*} Var(X) = E[(X-\\mu)^2] = \\int_{-\\infty}^\\infty (x-\\mu)^2 f(x) dx. \\end{align*}\\] Proposição 8.2 Se \\(X\\) é uma v.a. contínua com função de densidade \\(f(x)\\), então \\[\\begin{align*} Var(X) = E(X^2) - [E(X)]^2 = \\int_{-\\infty}^\\infty x^2 f(x) dx - \\left(\\int_{-\\infty}^\\infty x f(x)\\right)^2dx. \\end{align*}\\] Proposição 8.3 (propriedades da média e da variância) Seja \\(X\\) uma v.a. contínua e \\(a,b\\in \\mathbb R\\), então \\(E(aX + b) = aE(X)+b\\). \\(E(b) = b\\). \\(Var(aX+b)=a^2 Var(X)\\). \\(Var(b)=0\\). 8.7 Função geradora de momentos de uma variável aleatória contínua Seja \\(X\\) uma v.a. contínua com função de densidade \\(f(x)\\). Para \\(n\\geq 1\\) inteiro, o \\(n\\)-ésimo momento de \\(X\\) é definido por \\[ \\mu_{(n)} = E(X^n) = \\int_{-\\infty}^\\infty x^n f(x) dx. \\] Definição 8.6 Seja \\(X\\) uma v.a. contínua com função de densidade \\(f(x)\\), a função geradora de momentos de \\(X\\) é \\[ M_X(t) = E(e^{tX}) = \\int_{-\\infty}^\\infty e^{tx} f(x) dx. \\] Exemplo 8.11 Seja \\(X\\) uma variável aleatória contínua cuja função de densidade é dada por \\[ f(x) = \\begin{cases} 1, &amp; 0\\leq x \\leq 1,\\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\] Encontre \\(M_X(t)\\). Solução. Seja \\(t\\neq 0\\). Logo \\[\\begin{align*} M_X(t) &amp;= \\int_0^1 e^{tx} dx \\\\ &amp;=\\left. e^{tx}\\right|_0^t \\\\ &amp;=\\frac{e^t-1}{t}. \\end{align*}\\] Portanto, \\[ M_X(t) = \\begin{cases} \\frac{e^t-1}{t} &amp; t\\neq 0 \\\\ 1 &amp; t=0. \\end{cases} \\] Exemplo 8.12 Seja \\(X\\) a precipitação pluviométrica de um município em um certo dia, cuja função de densidade é dada por \\[\\begin{align*} f(x) = \\begin{cases} \\lambda e^{-\\lambda x} &amp; x\\geq 0 \\\\ 0 &amp; \\text{caso contrário} \\end{cases} \\end{align*}\\] onde \\(\\lambda &gt;0\\) é uma constante. Encontre \\(M_X(t)\\). Solução. Seja \\(t&lt;\\lambda\\). Logo \\[\\begin{align*} M_X(t)&amp;=\\lambda \\int_0^\\infty e^{tx} e^{-\\lambda x} dx\\\\ &amp;=\\lambda \\int_0^\\infty e^{-(\\lambda-t)x} dx\\\\ &amp;=\\lambda \\frac{1}{\\lambda-t} \\left. e^{-(\\lambda-t)x}\\right|_{x=0}^{x=\\infty} \\\\ &amp;=\\frac{\\lambda}{\\lambda-t} \\end{align*}\\] "],["modelos-continuos.html", "Capítulo 9 Modelos de distribuições contínuas 9.1 Distribuição uniforme contínua 9.2 Distribuição exponencial 9.3 Distribuição normal 9.4 Quantis da distribuição normal 9.5 Aproximação normal à binomial 9.6 A curtose e a distribuição normal", " Capítulo 9 Modelos de distribuições contínuas 9.1 Distribuição uniforme contínua Definição 9.1 Dizemos que a variável aleatória \\(X\\) tem distribuição uniforme contínua no intervalo \\([a,b]\\), se sua função de densidade é \\[ f(x) = \\begin{cases} \\frac{1}{b-a} &amp; a \\leq x \\leq b, \\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\] Notação: \\(X\\sim\\) Uniforme Contínua(\\([a,b]\\)) A função de distribuição de uma variável uniforme contínua no intervalo \\([a,b]\\) é \\[ F(x) = \\begin{cases} 0, &amp; x&lt;a\\\\ \\frac{x-a}{b-a}, &amp; a\\leq x \\leq b\\\\ 1, &amp; x \\geq b \\end{cases} \\] Proposição 9.1 Se \\(X \\sim\\) Uniforme Contínua(\\([a,b]\\)), então \\[ E(X) = \\frac{a+b}{2} \\text{ e } Var(X) = \\frac{(b-a)^2}{12} \\] Exemplo 9.1 A eficiência \\(X\\) de um certo componente eletrico é modelada por uma variável aleatória contínua com distribuição uniforme no intervalo \\([0,100]\\). Qual a probabilidade de que \\(X\\) esteja entre 60 e 80 unidades seja menor que 90 unidades Solução. Seja \\(X\\): eficiencia do componente eletrico \\(P(60 \\leq X \\leq 80) = F(80) - F(60) = 0,20\\). \\(P(X\\leq 90) = F(90)=0,90.\\) 9.2 Distribuição exponencial Definição 9.2 Dizemos que a variável aleatória \\(X\\) tem distribuição exponencial de parâmetro \\(\\lambda &gt; 0\\) se, sua função de densidade é \\[ f(x) = \\begin{cases} \\lambda e^{-\\lambda x} &amp; x \\geq 0 \\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\] Notação: \\(X\\sim\\) Exponencial(\\(\\lambda\\)). A função de distribuição de uma variável exponencial de parâmetro \\(\\lambda\\) é \\[\\begin{align*} F(x) = \\begin{cases} 1-e^{-\\lambda x}, &amp; x \\geq 0 \\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\end{align*}\\] Proposição 9.2 Se \\(X \\sim\\) Exponencial(\\(\\lambda\\)), então \\[ E(X) = \\frac{1}{\\lambda} \\text{ e } Var(X) = \\frac{1}{\\lambda^2} \\] Exemplo 9.2 O tempo de atendimento, em minutos, a um cliente em um serviço de informação de uma biblioteca é uma variável aleatória contínua com distribuição exponencial, com um tempo médio de atendimendo de 5 minutos. Qual a probabilidade de que o atendimento a um cliente dure mais de 10 minutos ? Solução. Seja \\(X\\): Tempo de atendimento, em minutos, a um cliente em um serviço de informação de uma biblioteca \\(\\sim\\) Exponencial(\\(\\lambda = 1/5\\)). \\[ P(X &gt; 10) = 1- P(X\\leq 10) = 1-F(10) = e^{-10/5} = 0,1353.\\] 9.3 Distribuição normal A distribuição normal é a distribuição contínua utilizada com mais frequência nas aplicações da teoria da probabilidade. Ela constitui a base para o desenvolvimento de muitos dos métodos da Estatística. Definição 9.3 Dizemos que a variável aleatória \\(X\\) tem uma distribuição normal de parâmetros \\(\\mu \\in \\mathbb R\\) e \\(\\sigma^2&gt;0\\), se sua função de densidade é \\[ f(x) = \\frac{1}{\\sqrt{2\\pi} \\sigma} e^{-(x-\\mu)^2/2\\sigma^2}, \\; x \\in \\mathbb R \\] Notação: \\(X\\sim\\) N(\\(\\mu\\),\\(\\sigma^2\\)). A distribuição normal também é conhecida como a distribuição de Laplace-Gauss. No seguinte gráfico apresentamos várias curvas da normal para diferentes valores dos parâmetros \\(\\mu\\) e \\(\\sigma^2\\). Proposição 9.3 Se \\(X\\sim\\) N(\\(\\mu,\\sigma^2\\)), então \\[ E(X) = \\mu \\text{ e } Var(X) = \\sigma^2. \\] A função de distribuição da normal é \\[ F(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\int_{-\\infty}^x e^{-(t-\\mu)^2/2\\sigma^2} dt, \\; x\\in \\mathbb R. \\] 9.3.1 Propriedades da distribuição normal A densidade \\(f\\) é simétrica em torno de \\(\\mu\\), isto é: \\(f(\\mu+ x) = f(\\mu - x)\\) para qualquer \\(x\\in \\mathbb R\\). Para qualquer \\(x\\in\\mathbb R\\), \\(F(\\mu + x) + F(\\mu-x) = 1\\). \\(x=\\mu\\) é o único ponto de máximos de \\(f\\), e o valor máximo é \\(\\frac{1}{\\sigma \\sqrt{2\\pi}}\\). \\(f\\) tem dois pontos de inflexão: \\(x=\\mu - \\sigma\\) e \\(x=\\mu + \\sigma\\). \\(\\lim_{x\\to \\pm \\infty} f(x) = 0\\). O desvio padrão \\(\\sigma\\) determina a largura da curva da normal: quanto maior \\(\\sigma\\) tem-se uma curva mais larga e achatada, dito de ooutra maneira, quanto maior \\(\\sigma\\) menos concentrada perto de \\(\\mu\\) a densidade é (veja a figura a continuação). 9.3.2 A distribuição normal padrão A distribuição normal padrão resulta quando os parâmetros de uma distribuição normal correspondem a \\(\\mu = 0\\) e \\(\\sigma^2 = 1\\). Ou seja, dizemos que a variável \\(X\\sim\\) N(0,1) se sua função de densidade é \\[ \\phi(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}, \\; x\\in \\mathbb R. \\] A função de distribuição de uma normal padrão é denotada pela letra grega \\(\\Phi\\) maiúscula e é dada por \\[ \\Phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^z e^{-t^2/2} dt, \\; x\\in\\mathbb R. \\] Observação. Os valores de \\(\\Phi(z)\\) não são possíveis de obter analiticamente, no entanto, podem ser aproximados numericamente e encontram-se tabelados para os valores de \\(z\\geq 0\\). Note que se \\(z&lt;0\\), podemos calcular \\(\\Phi(z)\\) através de \\(\\Phi(z) = 1-\\Phi(-z)\\). A continuação apresentamos alguns resultados úteis para o cálculo de probabilidades envolvendo uma distribuição normal. Proposição 9.4 Seja \\(X\\) uma variável aleatória com média \\(\\mu\\) e variância \\(0&lt;\\sigma^2&lt;\\infty\\). Se \\[ Z = \\frac{X-\\mu}{\\sigma}, \\] então \\(E(Z) = 0\\) e \\(Var(Z)=1\\). Proposição 9.5 Seja \\(X\\sim\\) N(\\(\\mu,\\sigma^2\\)), e defina \\(Y=aX + b\\), então \\(Y\\sim\\) N(\\(a\\mu + b\\), \\(a^2 \\sigma^2\\)). Prova. \\[\\begin{align*} F_Y(Y\\leq y) &amp;= P(Y \\leq y) \\\\ &amp;= P(aX + b \\leq y) \\\\ &amp;=P\\left(X\\leq\\frac{y-b}{a}\\right)\\\\ &amp;=F_X\\left(\\frac{y-b}{a}\\right) \\end{align*}\\] Logo, \\[\\begin{align*} f_Y(y) &amp;= F_Y&#39;(y)\\\\ &amp;=\\frac{1}{a} F_X&#39;\\left(\\frac{y-b}{a}\\right) \\\\ &amp;=\\frac{1}{a}f_X\\left(\\frac{y-b}{a}\\right)\\\\ &amp;=\\frac{1}{\\sqrt{2\\pi} (a\\sigma)} e^{-(y-(a\\mu + b))^2/2(a^2\\sigma^2)} \\end{align*}\\] Corolário 9.1 Seja \\(X\\sim\\) N(\\(\\mu,\\sigma^2\\)), então \\(Z=\\frac{X-\\mu}{\\sigma}\\sim\\) N(0,1). 9.3.3 Calculando probabilidades de uma \\(N(\\mu,\\sigma^2)\\) a partir da \\(N(0,1)\\) Seja \\(F\\) a função de distribuição de uma variável aleatória normal com média \\(\\mu\\) e variância \\(\\sigma^2\\), e \\(\\Phi\\) a função de distribuição de uma normal padrão, para qualquer \\(a\\in \\mathbb R\\), tem-se que \\[ F(a)=P(X\\leq a) = P\\left(Z \\leq \\frac{a-\\mu}{\\sigma}\\right) = \\Phi\\left(\\frac{a-\\mu}{\\sigma}\\right). \\] Exemplo 9.3 Suponha que os diâmetros das bolas de golf produzidas por uma companhia seguem uma distribuição normal com \\(\\mu = 1,96\\) polegadas e \\(\\sigma = 0,04\\) polegadas. Uma bola de golf é considerada defeituosa se seu diâmetro é menor que 1,90 polegadas ou maior que 2,02 polegadas. Qual a porcentagem de bolas de golf fabricadas pela companhia? Solução. Seja \\(X\\): Diâmetro de uma bola de golf fabricada pela companhia. Logo, \\[\\begin{align*} P(X &lt; 1,90 \\text{ ou } X&gt; 2,02) &amp;= 1- P(1,90 \\leq X \\leq 2,02) \\\\ &amp;=1-[F(2,02)-F(1,90)]\\\\ &amp;=1-\\left[\\Phi\\left(\\frac{2,02 -1,96}{0,04}\\right) -\\Phi\\left(\\frac{1,90 -1,96}{0,04}\\right)\\right]\\\\ &amp;=1-[\\Phi(1,5)-\\Phi(-1,5)]\\\\ &amp;=2-2\\Phi(1,5)\\\\ &amp;=2-2(0,9331)=0,1336 \\end{align*}\\] 9.4 Quantis da distribuição normal Seja \\(X\\) uma variável aleatória com função de distribuição \\(F\\) e seja \\(p\\in(0,1)\\), definimos o \\(p\\)-ésimo quantil como o valor \\(Q(p)\\) tal que \\(F(Q(p)) = p\\). No caso de \\(X \\sim\\) \\(N(\\mu,\\sigma^2)\\), temos que \\[\\begin{align*} F(Q(p)) = \\Phi\\left(\\frac{Q(p) - \\mu}{\\sigma}\\right) = p. \\end{align*}\\] Assim, devemos encontrar o valor de \\(z(p) = \\frac{Q(p) - \\mu}{\\sigma}\\) tal que a área sob a curva da normal padrão abaixo de \\(z(p)\\) seja igual a \\(p\\), logo \\(Q(p) = \\sigma z(p) + \\mu\\). Por exemplo, se \\(p=0.05\\), queremos achar o valor \\(z(p)\\) tal que \\(\\Phi(z(p)) = p = 0.05\\), Neste caso, procurando na tabela da normal, temos que \\(z(0.05)=-1.64\\). Veja a figura a seguir: Em Inferência Estatística, os quantis de uma distribuição normal padrão recebem o nome de valores críticos e frequentemente é usada a notação: \\(z_\\alpha= z(1-\\alpha), \\; \\alpha \\in (0,1)\\) e eles tem um papel fundamental na definição de intervalos de confiança e a região crítica de testes de hipóteses. Exemplo 9.4 Numa população o nível sérico de colesterol em adultos (medido em mg/dl) é uma variável aleatória com distribuição normal com parâmetros \\(\\mu=225\\) e \\(\\sigma=75\\). Calcule o valor acima do qual se encontra o colesterol de 10% da população que tem os níveis mais elevados. Solução. Seja \\(X\\): Nível de colesterol de uma pessoa selecionada aleatoriamente dessa população \\(\\sim\\) N(225,\\(75^2\\)), logo \\[ Z = \\frac{X - 225}{75} \\sim \\text{N(0,1)}. \\] Queremos achar valor \\(a\\) tal que \\(P(X &gt; a) = 0.10 \\iff P(X \\leq a)=0.90\\), ou seja, \\(a=Q(0.90)\\). Logo, \\(a=\\sigma z(0.90) + \\mu = 75 \\times 1,28 + 225 = 321\\). Portanto, 10% da população tem um nível de colesterol acima de 321 mg/dl. 9.5 Aproximação normal à binomial Lembre que uma variável aleatória \\(X\\) tem distribuição binomial com parâmetros \\(n\\) e \\(p\\) se sua função de probabilidade é dada por \\[ p(x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\; x=0,1,\\ldots, n. \\] Quando \\(n\\) é muito grande por veces resulta inviável calcular a probabilidade de que \\(X\\) assuma um certo conjunto de valores. Consideremos o seguinte exemplo: Exemplo 9.5 Durante um longo período tem se determinado que 70% dos advogados que apresentam o exame da OAB são aprovados. Suponha que 500 advogados que apresentam o exame, qual a probabilidade de que pelo menos 370 deles sejam aprovados. Seja \\(X\\): Número de advogados que aprovam o exame dentre os 500 \\(\\sim\\) Binomial(500,0.70). \\[ P(X \\geq 370) = \\sum_{x=370}^{500} \\binom{500}{x} (0.70)^x (0.30)^{500-x} \\] Nesse caso teriamos que calcular 131 probabilidades binomiais, o que resulta uma tarefa bastante tediosa se tivessemos que usar uma calculadora ou pior se tivessemos que realizar o cálculo “à mão.” Diante dessa situação podemos usar a distribuição normal para aproximar probabilidades binomiais. O seguinte teorema mostra como isso pode ser feito. Teorema 9.1 Seja \\(X\\sim\\) Binomial(\\(n,p\\)). Se \\(n\\) é suficientemente grande, então para \\(x=0,1,\\ldots,n\\) \\[\\begin{align*} P(X \\leq x) = P(X \\leq x+0,5) &amp;\\approx \\Phi\\left( \\frac{x + 0,5 - np}{\\sqrt{np(1-p)}} \\right) \\\\ P(x \\leq X \\leq y) = P(x - 0,5\\leq X \\leq y+0,5) &amp;\\approx \\Phi\\left(\\frac{ y + 0,5 - np}{\\sqrt{np(1-p)}}\\right) - \\Phi\\left(\\frac{ x - 0,5 - np}{\\sqrt{np(1-p)}}\\right) \\end{align*}\\] Observação. O procedimento de substrair e somar 0,5 é conhecido como correção de continuidade de Fisher e fornece uma aproximação mais precisa, especialmente quando \\(n\\) não for muito grande. Dois critérios que oferecem uma boa aproximação comumente usados são: \\(np\\geq 5\\) e \\(n(1-p) \\geq 5\\) ou \\(np(1-p)\\geq 10\\). A continuação apresentamos a função de probabilidade de uma distribuição binomial e a densidade da distribuição normal para diferentes valores de \\(n\\) e \\(p\\). Agora, usaremos o Teorema 9.1. para responder ao Exemplo 9.4. Nesse caso \\(\\mu = 500\\times 0.70 = 350\\) e \\(\\sigma^2 = 500 \\times 0.70 \\times 0.30 = 105\\) \\[\\begin{align*} P(X\\geq 370) &amp;= 1 - P(X \\leq 369) \\\\ &amp;=1-\\Phi\\left( \\frac{369 +0,5 - 350}{\\sqrt{105}} \\right)\\\\ &amp;=1-\\Phi(1.90)\\\\ &amp;=1-0,9713\\\\ &amp;=0.0287. \\end{align*}\\] Portanto, a probabilidade de pelo menos 370 advogados aprovem o exame da OAB é aproximadamente de 2%. Exemplo 9.6 Um fabricante sabe por experiência que o 4% de um lote contendo um certo produto é rejeitado por defeitos. Se um novo lote de 800 unidades vai ser inspecionado. Qual a probabilidade aproximada de que menos de 35 unidades sejam rejeitadas? Solução. Seja \\(X\\): Número de produtos rejeitados por defeito \\(\\sim\\) Binomial(800,0,04), podemos usar a distribuição normal com \\(\\mu = 800 \\times 0,04 = 32\\) e \\(\\sigma^2 = 800 \\times 0,04 \\times 0,96 = 30,72\\). Logo, \\[ P(X&lt;35) = P(X\\leq 34) = \\Phi\\left( \\frac{34+0,5 - 32}{\\sqrt{30,72}}\\right) = \\Phi(0,45)=0,6736. \\] Exemplo 9.7 O tamanho ideal de uma turma de primeiro ano em uma faculdade particular é de 150 alunos. A faculdade, sabendo de experiências anteriores que, em média, apenas 30% dos alunos aceitos vão de fato seguir o curso, usa a prática de aprovar os pedidos de matrícula de 450 estudantes. Calcule a probabilidade de que mais de 150 estudantes de primeiro ano frequente as aulas nesta faculdade. Solução. Seja \\(X\\): Número de estudantes que seguem o curso, então \\(X\\) é uma variável binomial com distribuição binomial com parâmetros \\(n=450\\) e \\(p=0,3\\). Usando a aproximação normal à binomial, temos que \\[\\begin{align*} P(X\\geq 150) &amp;\\approx 1-\\Phi\\left( \\frac{150 + 0,5 - (450)(0,3)}{\\sqrt{(450)(0,3)(0,7)}} \\right) \\\\ &amp;=1-\\Phi(1,59) \\\\ \\approx 0,0559. \\end{align*}\\] Portanto, menos do 6% das vezes mais que 150 dos 450 estudantes aceitos vão de fato seguir o curso. 9.6 A curtose e a distribuição normal A curtose é uma medida de forma que mostra o achatamento da curva da função de densidade de probabilidade de uma variável aleatória. Definição 9.4 Tomando a distribuição normal como referência, diremos que uma distribuição pode ser menos “achatada” que a normal (LEPTOCÚRTICA) ou mais “achatada” que a normal (PLATICÚRTICA). A distribuição normal desde o ponto de vista da curtose, é chamada de MESOCÚRTICA. Definição 9.5 Seja \\(X\\) uma variável aleatória (discreta ou contínua) com média \\(\\mu\\) e variância \\(\\sigma^2\\). Então, o coeficiente de curtose de \\(X\\) é definida como \\[ \\kappa = \\frac{E[(X-\\mu)^4]}{\\sigma^4} - 3 \\] Critério Se \\(\\kappa &lt; 0\\), então a distribuição de \\(X\\) é leptocúrtica. Se \\(\\kappa = 0\\), então a distribuição de \\(X\\) é mesocúrtica. Se \\(\\kappa &gt; 0\\), então a distribuição de \\(X\\) é platicúrtica. "],["tabelas.html", "Capítulo 10 Tabelas 10.1 Tabela da normal padrão", " Capítulo 10 Tabelas 10.1 Tabela da normal padrão 0.5000 0.5040 0.5080 0.5120 0.5160 0.5199 0.5239 0.5279 0.5319 0.5359 0.5398 0.5438 0.5478 0.5517 0.5557 0.5596 0.5636 0.5675 0.5714 0.5753 0.5793 0.5832 0.5871 0.5910 0.5948 0.5987 0.6026 0.6064 0.6103 0.6141 0.6179 0.6217 0.6255 0.6293 0.6331 0.6368 0.6406 0.6443 0.6480 0.6517 0.6554 0.6591 0.6628 0.6664 0.6700 0.6736 0.6772 0.6808 0.6844 0.6879 0.6915 0.6950 0.6985 0.7019 0.7054 0.7088 0.7123 0.7157 0.7190 0.7224 0.7257 0.7291 0.7324 0.7357 0.7389 0.7422 0.7454 0.7486 0.7517 0.7549 0.7580 0.7611 0.7642 0.7673 0.7704 0.7734 0.7764 0.7794 0.7823 0.7852 0.7881 0.7910 0.7939 0.7967 0.7995 0.8023 0.8051 0.8078 0.8106 0.8133 0.8159 0.8186 0.8212 0.8238 0.8264 0.8289 0.8315 0.8340 0.8365 0.8389 0.8413 0.8438 0.8461 0.8485 0.8508 0.8531 0.8554 0.8577 0.8599 0.8621 0.8643 0.8665 0.8686 0.8708 0.8729 0.8749 0.8770 0.8790 0.8810 0.8830 0.8849 0.8869 0.8888 0.8907 0.8925 0.8944 0.8962 0.8980 0.8997 0.9015 0.9032 0.9049 0.9066 0.9082 0.9099 0.9115 0.9131 0.9147 0.9162 0.9177 0.9192 0.9207 0.9222 0.9236 0.9251 0.9265 0.9279 0.9292 0.9306 0.9319 0.9332 0.9345 0.9357 0.9370 0.9382 0.9394 0.9406 0.9418 0.9429 0.9441 0.9452 0.9463 0.9474 0.9484 0.9495 0.9505 0.9515 0.9525 0.9535 0.9545 0.9554 0.9564 0.9573 0.9582 0.9591 0.9599 0.9608 0.9616 0.9625 0.9633 0.9641 0.9649 0.9656 0.9664 0.9671 0.9678 0.9686 0.9693 0.9699 0.9706 0.9713 0.9719 0.9726 0.9732 0.9738 0.9744 0.9750 0.9756 0.9761 0.9767 0.9772 0.9778 0.9783 0.9788 0.9793 0.9798 0.9803 0.9808 0.9812 0.9817 0.9821 0.9826 0.9830 0.9834 0.9838 0.9842 0.9846 0.9850 0.9854 0.9857 0.9861 0.9864 0.9868 0.9871 0.9875 0.9878 0.9881 0.9884 0.9887 0.9890 0.9893 0.9896 0.9898 0.9901 0.9904 0.9906 0.9909 0.9911 0.9913 0.9916 0.9918 0.9920 0.9922 0.9925 0.9927 0.9929 0.9931 0.9932 0.9934 0.9936 0.9938 0.9940 0.9941 0.9943 0.9945 0.9946 0.9948 0.9949 0.9951 0.9952 0.9953 0.9955 0.9956 0.9957 0.9959 0.9960 0.9961 0.9962 0.9963 0.9964 0.9965 0.9966 0.9967 0.9968 0.9969 0.9970 0.9971 0.9972 0.9973 0.9974 0.9974 0.9975 0.9976 0.9977 0.9977 0.9978 0.9979 0.9979 0.9980 0.9981 0.9981 0.9982 0.9982 0.9983 0.9984 0.9984 0.9985 0.9985 0.9986 0.9986 0.9987 0.9987 0.9987 0.9988 0.9988 0.9989 0.9989 0.9989 0.9990 0.9990 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
