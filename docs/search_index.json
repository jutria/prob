[["index.html", "Probabilidade Prefácio", " Probabilidade Jaime Utria 2022-06-25 Prefácio Na linguagem cotidiana, o termo probabilidade entende-se como uma medida de nossa confiança de que ocorra um evento futuro. Aceitamos essa afirmação como uma maneira prática de interpretar a probabilidade, no entanto, buscamos entender com mais profundidade seu contexto, como se mede e a maneira em que contribui na realização de inferências. O conceito de probabilidade é necessário quando abordamos experiências físicas, biológicas ou sociais que geram observações que não podem ser previstas com certeza, por exemplo, o número de pessoas que chegaram em uma agência bancária num determinado horário, o tempo de vida útil de um componente eletrônico ou o preço de uma ação negociada na bolsa de valores. Esses fenômenos ou experimentos sujeitos à incerteza são o objeto de estudo da Teoria de Probabilidade. O material aqui apresentado visa ser uma introdução à Teoria de Probabilidade no nível universitário. Os assuntos aqui tratados são: Espaço de Probabilidade, Variáveis Aleatórias, Modelos de distribuições discretos e contínuos frequentemente usados em diversas aplicações e Transformações de variáveis aleatórias. "],["esp-prob.html", "Capítulo 1 Espaços de Probabilidade 1.1 Espaço amostral 1.2 Eventos 1.3 Probabilidade 1.4 Probabilidade Condicional", " Capítulo 1 Espaços de Probabilidade Neste capítulo formulamos um modelo matemático (ou modelo probabilístico) para um experimento aleatório. Começamos definindo o que é um experimento aleatório. Definição 1.1 Um experimento é aleatório se, quando repetido sob as mesmas condições nem sempre gera os mesmos resultados, isto é, não conseguimos prever o resultado do experimento até que ele seja realizado. Exemplos de experimentos aleatorios Lançar um dado e registrar a face superior. Contar o número de pessoas que chegam numa agência bancária durante um período de tempo dado. Medir o tempo de vida útil, em horas, de uma lâmpada. A seguir descreveremos o modelo probabilistíco para um experimento aleatório. 1.1 Espaço amostral Definição 1.2 (Espaço amostral) O conjunto de todos os resultados possíveis de um experimento aleatório é chamado de espaço amostral, e o denotamos por \\(\\Omega\\). A continuação apresentamos um espaço amostral adequado para cada um dos experientos descritos nos exemplos acima: \\(\\Omega = \\{1,2,3,4,5,6\\}\\). \\(\\Omega = \\{0,1,2,3,\\ldots\\}\\) \\(\\Omega = \\{x \\in \\mathbb R : 0\\leq x &lt; \\infty \\}.\\) Note que nos exemplos (i) e (ii), \\(\\Omega\\) é um conjunto no máximo enumerável, quando isso acontece dizemos que \\(\\Omega\\) é um espaço amostral discreto. No entanto, no exemplo (iii) temos um conjunto infinito não-enumerável, nesse caso dizemos que \\(\\Omega\\) é um espaço amostral contínuo. 1.2 Eventos Definição 1.3 (Evento) Informalmente, um evento é qualquer subconjunto \\(A\\subset \\Omega\\). 1.2.1 Relaçoes e operações entre eventos Seja \\(A\\) um evento. Se \\(\\omega\\) é um elemento em \\(\\Omega\\), tal que \\(\\omega \\in A\\), dizemos que \\(A\\) ocorre. Se \\(A=\\{\\omega\\}\\) para algum \\(\\omega \\in \\Omega\\), dizemos que \\(A\\) é um evento elementar. Dados dois eventos \\(A\\) e \\(B\\), dizemos que \\(A\\subset B\\), se \\(\\omega \\in A\\Rightarrow \\omega \\in B\\). Em palavras a ocorrência de \\(A\\) implica a ocorrência de \\(B\\). A união de dois eventos \\(A\\) e \\(B\\) é \\(A \\cup B =\\{\\omega: \\omega \\in A \\text{ ou } \\omega \\in B \\}\\) e representa o evento A intersecção de dois eventos \\(A\\) e \\(B\\) é \\(A\\cap B =\\{\\omega: \\omega \\in A \\text{ e } \\omega \\in B\\}\\) e representa o evento de que ambos \\(A\\) e \\(B\\) ocorrem. A diferença de dois eventos \\(A\\) e \\(B\\) é \\(A\\setminus B = \\{\\omega: \\omega \\in A \\text{ e } \\omega \\notin B\\}\\) e representa o evento de que \\(A\\) ocorre e \\(B\\) não ocorre. Dois eventos \\(A\\) e \\(B\\) são disjuntos ou mutuamente exclusivos se \\(A\\cap B =\\emptyset\\). Isso significa que \\(A\\) e \\(B\\) não ocorrem simultaneamente. Para qualquer evento \\(A\\), o complementar de \\(A\\) é \\(A^c =\\{\\omega: \\omega \\notin A\\}\\) e representa o evento de que \\(A\\) não ocorre. Leis de Morgan: Sejam \\(A_1,A_2,\\ldots,A_n\\) eventos, temos que \\[\\begin{align} \\left( \\bigcup_{i=1}^n A_i\\right)^c = \\bigcap_{i=1}^n A_i^c, \\tag{LM1} \\label{LM1} \\\\ \\left( \\bigcap_{i=1}^n A_i\\right)^c = \\bigcup_{i=1}^n A_i^c. \\label{LM2} \\tag{LM2} \\end{align}\\] Observação. Note que \\(\\eqref{LM1}\\) diz que o complementar de que pelo menos um dos \\(A_i\\)’s ocorre é igual ao evento de que nenhum dos \\(A_i\\)’s ocorra. Enquanto \\(\\eqref{LM2}\\) diz que o complementar de que todos os \\(A_i\\)’s ocorrem é igual ao evento de que pelo menos um dos \\(A_i\\)’s não ocorre. 1.3 Probabilidade Definição 1.4 (Definição clássica) Seja \\(\\Omega =\\{\\omega_1,\\ldots,\\omega_N\\}\\) finito, e suponhamos que cada evento elementar é igualmente provável, isto é, \\[ P(\\omega) = \\frac{1}{N}, \\, \\omega \\in \\Omega. \\] Definimos a probabilidade do evento \\(A\\subset \\Omega\\) como \\[ P(A) = \\frac{|A|}{|\\Omega|}. \\] Definição 1.5 (Definição axiomática) Uma probabilidade é uma função \\(P: \\mathcal F \\rightarrow \\mathbb R\\), em que \\(\\mathcal F\\) é uma classe de eventos de um espaço amostral \\(\\Omega\\), que satisfaz as seguintes condições: \\(P(A) \\geq 0\\), para todo \\(A \\in \\mathcal F\\), \\(P(\\Omega) = 1\\), (Aditividade enumerável). Para qualquer sequência \\(A_1,A_2,\\ldots \\in \\mathcal F\\), tais que \\(A_i \\cap A_j =\\emptyset\\), \\(i\\neq j\\), \\[\\begin{align*} P\\left(\\bigcup_{i=1}^\\infty A_i\\right)= \\sum_{i=1}^\\infty P(A_i). \\end{align*}\\] Observação. Quando \\(\\Omega\\) é infinito não-enumerável, geralmente é impossível associar uma probabilidade bem definida a todos os subconjuntos de \\(\\Omega\\). Para isso, definimos uma probabilidade em uma classe mais restrita de subconjuntos de \\(\\Omega\\) (chamada de \\(\\sigma\\)-álgebra e definida abaixo); e apenas esses subconjuntos são chamados de eventos. Definição 1.6 (sigma-álgebra) Uma classe \\(\\mathcal F \\subset 2^\\Omega\\) é uma \\(\\sigma\\)-álgebra (em \\(\\Omega \\neq \\emptyset\\)) se satisfaz as seguintes condições \\(\\Omega \\in \\mathcal F\\), Se \\(A \\in \\mathcal F\\), então \\(A^c \\in \\mathcal F\\), Se \\(A_1,A_2,\\ldots \\in \\mathcal F\\), então \\(\\displaystyle\\bigcup_{i=1}^\\infty A_i \\in \\mathcal F\\). O trio \\((\\Omega,\\mathcal F, P)\\) é chamado de um espaço de probabilidade. 1.3.1 Propriedades de uma probabilidade \\(P(\\emptyset) = 0\\). Se \\(A_1,A_2,\\ldots,A_n\\) são eventos dois a dois disjuntos, então \\[\\begin{align*} P\\left(\\bigcup_{i=1}^n A_i \\right) = \\sum_{i=1}^n P(A_i) \\end{align*}\\] \\(P(A) = 1- P(A^c)\\) para todo evento \\(A\\). Para quaisquer eventos \\(A\\) e \\(B\\), \\[\\begin{align*} P(B) = P(A \\cap B) + P(A^c \\cap B) \\end{align*}\\] Se \\(A \\subset B\\), então \\(P(A) \\leq P(B)\\). \\(P(A)\\leq 1\\) para todo evento \\(A\\). Para quaisquer eventos \\(A\\) e \\(B\\), \\[\\begin{align*} P(A\\cup B) =P(A) + P(B) - P(A\\cap B). \\end{align*}\\] Princípio da Inclusão-Exclusão \\[\\begin{align*} P\\left(\\bigcup_{i=1}^n A_i \\right) &amp;= \\sum_{i=1}^n P(A_i) - \\sum_{i&lt;j} P(A_i \\cap A_j)\\\\ &amp;+ \\sum_{i&lt;j&lt;k} P(A_i \\cap A_j \\cap A_k) - \\cdots +(-1)^{n+1} P(A_1\\cap \\cdots \\cap A_n) \\end{align*}\\] Subaditividade finita: Para qualquer sequência finita \\(A_1,A_2,\\ldots, A_n\\) de eventos, \\[ P\\left(\\bigcup_{i=1}^n A_i \\right) \\leq \\sum_{i=1}^n P(A_i). \\] Subaditividade enumerável: Para qualquer sequência \\(A_1,A_2,\\ldots\\) de eventos, \\[ P\\left(\\bigcup_{i=1}^\\infty A_i \\right) \\leq \\sum_{i=1}^\\infty P(A_i). \\] As propriedades (ix) e (x), são conhecidas como Desigualdades de Boole. Prova. Para provar i. Defina \\(A_1 = \\Omega\\), \\(A_i = \\emptyset\\), \\(i&gt;1\\), logo \\(\\Omega = \\bigcup _{i=1}^\\infty A_i\\). Além disso, \\[\\begin{align*} 1=P(\\Omega) = P(\\Omega) + \\sum_{i=2}^\\infty P(\\emptyset) \\Rightarrow \\sum_{i=2}^\\infty P(\\emptyset) = 0 \\Rightarrow P(\\emptyset) = 0. \\end{align*}\\] Defina \\(A_i = \\emptyset\\), \\(i&gt;n\\), logo \\(\\bigcup_{i=1}^\\infty A_i = \\bigcup_{i=1}^n A_i\\), pelo axioma (iii) em \\(\\ref{}\\) e a propriedade 1, segue que \\[\\begin{align*} P\\left(\\bigcup_{i=1}^n A_i\\right)=P\\left(\\bigcup_{i=1}^\\infty A_i\\right) = \\sum_{i=1}^n P(A_i) + \\sum_{i=n+1}^\\infty P(\\emptyset) = \\sum_{i=1}^n P(A_i) \\end{align*}\\] Note que para qualquer \\(A\\subset \\Omega\\), temos que \\(\\Omega= A \\cup A^c\\) e \\(A\\cap A^c = \\emptyset\\), logo \\[\\begin{align*} 1=P(\\Omega)=P(A) + P(A^c) \\Rightarrow P(A^c) = 1-P(A) \\end{align*}\\] Note que \\(B = (A\\cap B) \\cup (A^c \\cap B)\\) tal que \\((A\\cap B) \\cap (A^c \\cap B) = \\emptyset\\), logo \\[\\begin{align*} P(B) = P(A\\cap B) + P(A^c \\cap B) \\end{align*}\\] Como \\(A\\subset B\\), temos que \\(B=(B\\setminus A) \\cup A\\), com \\((B\\setminus A) \\cap A = \\emptyset\\), logo \\[\\begin{align*} P(B) = P(A) + P(A\\setminus B) \\geq P(A). \\end{align*}\\] Como \\(A\\subset \\Omega\\), logo \\(P(A) \\leq P(\\Omega) = 1\\). Note que \\(A\\cup B = (A\\setminus B) \\cup (A \\cap B) \\cup (B \\setminus A)\\), logo \\[\\begin{align*} P(A\\cup B) &amp;= P(A\\setminus B) + P(A \\cap B) + P(B\\setminus A) \\\\ &amp;= [P(A\\setminus B) + P(A \\cap B)] + [P(B\\setminus A) + P(A\\cap B)] - P(A\\cap B)\\\\ &amp;= P(A) + P(B) - P(A\\cap B). \\end{align*}\\] Use indução em \\(n\\). Note que para o caso \\(n=3\\), temos \\[\\begin{align*} P(A\\cup B\\cup C) &amp;= P(A) + P(B) + P(C) - P(A\\cap B) - P(A\\cap C) - P(B \\cap C) \\\\ &amp;+ P(A\\cap B \\cap C). \\end{align*}\\] 1.3.2 Calculando probabilidades Exemplo 1.1 Um comitê de 5 pessoas deve ser selecionado de um grupo de 6 homens e 9 mulheres. Se a seleção for feita aleatoriamente, qual a probabilidade de que o comitê seja formado por 3 homens e 2 mulheres? Solução. Como o experimento consiste em escolher 5 pessoas do total de 15, temos que \\(|\\Omega|= \\binom{15}{5}\\). Supondo que todas as \\(\\binom{15}{5}\\) tem a mesma probabilidade e se \\(A\\) representa o evento de que a seleção feita seja formada por 3 homens e 2 mulheres, temos que \\(|A| = \\binom{6}{3} \\binom{9}{2}\\). Portanto, \\[\\begin{align*} P(A) &amp;= \\frac{|A|}{|\\Omega|} \\\\ &amp;= \\frac{\\binom{6}{3}\\binom{9}{2}}{\\binom{15}{5}}=\\frac{240}{1001} \\end{align*}\\] Exemplo 1.2 Numa mão de pôquer de cinco cartas, o full house ocorre quando alguém sai com três cartas de mesmo valor e duas outras cartas do mesmo valor (diferente do primeiro). Assim um full house é formado por uma trinca e um par. Qual a probabilidade de alguém sair com um full house? Solução. Vamos supor que todas \\(\\binom{52}{5}\\) possíveis seleções são equiprováveis. Note que o número de maneiras de escolher um par é \\(13 \\cdot \\binom{4}{2}\\) e uma vez escolhido o par, o número de maneiras de escolher uma trinca é \\(12 \\cdot \\binom{4}{3}\\), logo se \\(A\\) é o evento de sair um full house, temos que \\[\\begin{align*} P(A) = \\frac{13\\cdot 12 \\cdot \\binom{4}{2} \\cdot \\binom{4}{3}}{\\binom{52}{5}} \\approx 0,0014. \\end{align*}\\] Exemplo 1.3 Um estudante possui 5 livros diferentes de Probabilidade, 2 livros diferentes de Estatística e 3 livros diferentes de Computação, que serão dispostos aleatoriamente em uma prateleira. Qual a probabilidade de que os livros de cada assunto fiquem juntos? Solução. Primeiro observe que temos 10! maneiras de dispor os 10 livros na prateleira, logo para garantir que os livros de cada assunto fiquem juntos vamos formar três blocos (um por cada assunto): o primeiro bloco é formado pelos 5 livros de Probabilidade, o segundo pelos 2 livros de Estatística e o terceiro pelos 3 livros de Computação. Assim, para o primeiro bloco temos 5! maneiras de ordenar eles, para o segundo temos 2! e para o terceiro temos 3!, finalmente temos 3! maneiras de ordenar os blocos. Portanto, a probabilidade pedida é \\[\\begin{align*} P(\\text{os livros de cada assunto fiquem juntos}) &amp;= \\frac{5!2!3!3!}{10!}\\\\ &amp;=\\frac{1}{420} \\end{align*}\\] 1.3.3 Espaço de probabilidade no caso \\(\\Omega\\) enumerável Suponha que \\(\\Omega = \\{\\omega_1, \\omega_2,\\ldots\\}\\) seja um conjunto enumerável e assuma que a cada \\(\\omega_i \\in \\Omega\\), atribuimos um peso \\(p(\\omega_i)\\) tal que \\(\\sum_{i=1}^\\infty p(\\omega_i) = 1\\), além disso considere como família de eventos \\(\\mathcal F = 2^\\Omega\\) e para qualquer \\(A \\in \\mathcal F\\), definimos a probabilidade de \\(A\\) como \\[ P(A) = \\sum_{i: \\omega_i \\in A} p(\\omega_i). \\] Exemplo 1.4 Suponha um jogo no qual você ganha \\(k-2\\) reais com probabilidade \\(\\left(\\frac{1}{2}\\right)^k\\) para qualquer \\(k\\geq 1\\) inteiro. Qual a probabilidade de você ganhar mais de dos reais ? Solução. Neste caso o espaço amostral é dado pela quantidade de reais que você pode ganhar no jogo, ou seja, \\[ \\Omega = \\{-1,0,1,2,\\ldots\\}, \\] e \\[ P(\\{\\omega\\})=P(\\omega) = \\left(\\frac{1}{2}\\right)^{\\omega+2}, \\; \\omega \\in \\Omega.\\] Por exemplo, \\(P(\\{-1\\}) = 1/2\\) e \\(P(\\{0\\}) = 1/4\\). O evento de interesse é \\(A=\\{3,4,5,6,\\ldots\\}\\). Portanto, \\[\\begin{align*} P(A) = \\sum_{\\omega = 3}^\\infty P(\\omega) &amp;= \\sum_{\\omega=3}^\\infty \\left(\\frac{1}{2}\\right)^{\\omega + 2}\\\\ &amp;=\\frac{1}{4} \\sum_{\\omega=3}^\\infty \\left(\\frac{1}{2}\\right)^{\\omega} \\\\ &amp;= \\frac{1}{16}. \\end{align*}\\] 1.4 Probabilidade Condicional Considere o experimento que consiste em lançar um dado honesto e defina os eventos \\(A=\\{1,2,3\\}\\) e \\(B=\\{2,4,6\\}\\), temos que \\(P(A) = \\frac{1}{2}\\), essa é a probabilidade a priori de \\(A\\), isto é, antes que o experimento se realize. Suponha que uma vez realizado o experimento alguém nos infrome que o resultado do mesmo é um número par, ou seja que \\(B\\) ocorreu. Com essa nova informação, a probabilidade de \\(A\\) é atualizada, pois para que \\(A\\) aconteça o único resultado possível do experimento deve ter sido 2. O que nos leva a \\[ P(A \\text{ dado } B) = \\frac{|A\\cap B|}{|\\Omega|} = \\frac{1}{3}. \\] Essa probabilidade é chamada de probabilidade a posteriori de \\(A\\) dado \\(B\\). Daqui em diante, vamos chama-la de probabilidade de \\(A\\) dada a ocorrência de \\(B\\) ou simplesmente de probabilidade de \\(A\\) dado \\(B\\). Do exemplo, podemos generalizar com a seguinte definição: Definição 1.7 (Probabilidade condicional) Sejam \\(A,B\\) dois eventos em um espaço de probabilidade \\((\\Omega, \\mathcal F, P)\\), tal que \\(P(B)&gt;0\\), definimos a probabilidade condicional de \\(A\\) dado \\(B\\) como \\[\\begin{align*} P(A|B) = \\frac{P(A\\cap B)}{P(B)}. \\end{align*}\\] Proposição 1.1 Seja \\(B\\) um evento em um espaço de probabilidade \\((\\Omega,\\mathcal F, P)\\), tal que \\(P(B)&gt;0\\), temos que \\(P(\\cdot|B)\\) é uma probabilidade. Prova. Devemos verificar os três axiomas da definição axiomática de probabilidade. Com efeito \\(P(A|B) \\geq 0\\), para qualquer evento \\(A\\) (trivial). \\(P(\\Omega|B) = \\frac{P(\\Omega\\cap B)}{P(B)} = \\frac{P(B)}{P(B)} = 1\\). Aditividade enumerável: Sejam \\(A_1, A_2,\\ldots\\) eventos disjuntos dois a dois, então \\[\\begin{align*} P\\left(\\bigcup_{i=1}^\\infty A_i|B\\right) &amp;= \\frac{P\\left(\\left(\\bigcup_{i=1}^\\infty A_i\\right) \\cap B\\right)}{P(B)}\\\\ &amp;= \\frac{P\\left(\\bigcup_{i=1}^\\infty (A_i \\cap B)\\right)}{P(B)} \\\\ &amp;= \\frac{\\sum_{i=1}^\\infty P(A_i\\cap B)}{P(B)} \\\\ &amp;= \\sum_{i=1}^\\infty P(A_i|B) \\end{align*}\\] Proposição 1.2 (Regra da multiplicação) Se \\(A_1,\\ldots,A_n\\) são eventos em um espaço de probabilidade \\((\\Omega,\\mathcal F, P)\\) com \\(P(A_1\\cap \\ldots \\cap A_{n-1})&gt;0\\), então \\[ P(A_1 \\cap A_2 \\cap \\ldots \\cap A_n) = P(A_1)P(A_2|A_1) \\cdots P(A_n|A_1 \\cap \\ldots \\cap A_{n-1}) \\] 1.4.1 Fórmula da probabilidade total Definição 1.8 (Partição) Seja \\(\\Omega\\neq \\emptyset\\), uma partição de \\(\\Omega\\) é uma sequencia finita de conjuntos (ou eventos) \\(A_1,\\ldots,A_n\\) tais que \\(A_i \\cap A_j = \\emptyset\\) para qualquer \\(i\\neq j\\), \\(i,j=1,\\ldots,n\\), \\(\\displaystyle \\bigcup_{i=1}^n A_i = \\Omega\\). Teorema 1.1 (Fórmula da probabilidade total) Seja \\(\\{A_i\\}_{i=1}^n\\) uma partição do espaço amostral \\(\\Omega\\), tal que \\(P(A_i)&gt;0\\) para qualquer \\(i=1,\\ldots, n\\) e \\(B\\) um evento qualquer, temos que \\[ P(B) = \\sum_{i=1}^n P(B|A_i)P(A_i). \\] Prova. Note que \\(\\displaystyle B = \\bigcup_{i=1}^n (B\\cap A_i)\\) e \\((B\\cap A_i) \\cap (B\\cap A_j)\\) para qualquer \\(i\\neq j\\). Logo \\[ P(B) = \\sum_{i=1}^n P(B\\cap A_i) = \\sum_{i=1}^n P(B|A_i) P(A_i), \\] onde a ultima passagem decorre da regra da multiplicação para dois eventos. Exemplo 1.5 Durante o mês de outubro a probabilidade de chuva em um dia determinado é de 4/10. Um time de futebol ganha um jogo em um dia com chuva com probabilidade 6/10 e em um dia sem chuva com probabilidade de 4/10. Qual a probabilidade de que esse time ganhe um jogo naquele dia de outubro? Solução. Seja \\(A\\): O time ganhe um jogo naquele dia de outubro e \\(B\\): teve chuva naquele dia de outubro, logo \\[ P(A) = P(A|B)P(B) + P(A|B^c)P(B^c) = (6/10)(4/10) + (4/10)(6/10) = 24/50 \\] Exemplo 1.6 Ao responder uma questão em uma prova de múltipla escolha, um estudante sabe a resposta ou a chuta. Seja \\(p\\) a probabilidade de que o estudante saiba a resposta e \\(1-p\\) a probabilidade de que ele chute. Suponha que um estudante que chuta a resposta tem uma probabilidade de acerto de \\(1/m\\), onde \\(m\\) é o número de alternativas em cada questão de múltipla escolha. Qual a probabilidade que ele a tenha respondido corretamente? Solução. Denote por \\(A\\): o estudante tenha respondido corretamente [acerta a resposta] e por \\(B\\): o estudante sabe a resposta, logo \\[ P(A) = P(A|B)P(B) + P(A|B^c)P(B^c) = p\\cdot 1 + (1-p) \\cdot 1/m = p+(1-p)/m. \\] Por exemplo, se \\(p=1/2\\) e \\(m=10\\), temos que \\(P(A) = \\frac{11}{20}\\). Exemplo 1.7 Em uma cidade, os motoristas são parados pela polícia para fazer um teste sobre o teor de álcool no sangue. Suponha que a probabilidade de que um motorista detido esteja embriagado é 5% e que o teste realizado acerta o estado de embriaguez em 80% das ocasiões. Qual a probabilidade de que o teste de um motorista detido resulte positivo? 1.4.2 Fórmula de Bayes Teorema 1.2 (Fórmula de Bayes) Seja \\(\\{A_i\\}_{i=1}^n\\) uma partição do espaço amostral \\(\\Omega\\), tal que \\(P(A_i)&gt;0\\) para qualquer \\(i=1,\\ldots, n\\) e \\(B\\) um evento, temos que \\[ P(A_i|B) = \\frac{P(B|A_i)P(A_i)}{\\sum_{i=1}^n P(B|A_i)P(A_i)} \\] Prova. Para cada \\(i=1,2,\\ldots,n\\), temos que \\[\\begin{align*} P(A_i|B)&amp;=\\frac{P(A_i\\cap B)}{P(B)} \\\\ &amp;=\\frac{P(B|A_i)P(A_i)}{\\sum_{i=1}^n P(B|A_i)P(A_i)} \\end{align*}\\] Na primeira passagem aplicamos a definição de probabilidade condicional, na segunda passagem aplicamos, no numerador, a regra da multiplicação e no denominador o teorema da probabilidade total. Solução. Denote por \\(A\\): teste resulte positivo e por \\(B\\): o motorista está embriagado. \\[P(A) = P(A|B)P(B) + P(A|B^c)P(B^c) = (0,80)(0,05) + (0,20)(0,95) = 23/100.\\] Exemplo 1.8 Nas mesmas condições do exemplo 3, dado que o teste de um motorista resulto negativo, qual a probabilidade de que estava dirigindo com um índice alcoólico acima do permitido? Solução. Defina \\(B\\): embriagado, \\(B^c\\): sóbrio, \\(A^c\\): teste negativo, \\(A\\): teste positivo Pelo Teorema de Bayes, temos que \\[\\begin{align*} P(B|A^c) &amp;=\\frac{P(A^c|B)P(B)}{P(A^c|B)P(B) + P(A^c|B^c)P(B^c)}\\\\ &amp;=\\frac{(0,20)(0,05)}{(0,20)(0,05)+(0,80)(0,95)} \\\\ &amp;\\approx 0.01 \\end{align*}\\] Ou seja, a probabilidade de ocorrer um falso negativo é aproximadamente de 1% . "],["conjuntos-limites-e-continuidade-da-probabilidade.html", "Capítulo 2 Conjuntos limites e continuidade da probabilidade 2.1 Limite superior e inferior de uma sequência de números reais.", " Capítulo 2 Conjuntos limites e continuidade da probabilidade Definição 2.1 (Sequências monótonas de eventos) Sejam \\(A_1,A_2,\\ldots\\) eventos em um espaço de probabilidade \\((\\Omega, \\mathcal F, P)\\). Dizemos que \\((A_n)_{n\\geq 1}\\) é uma sequência de eventos crescente se \\[ A_1 \\subset A_2 \\subset A_3 \\subset \\cdots \\] Dizemos que \\((A_n)_{n\\geq 1}\\) é uma sequência de eventos decrescente se \\[ A_1 \\supset A_2 \\supset A_3 \\supset \\cdots \\] Observação. Se \\((A_n)_{n\\geq 1}\\) é uma sequência crescente ou decrescente, dizemos que é monótona. Definição 2.2 (Limite de sequências monótonas de eventos) Seja \\((A_n)_{n\\geq 1}\\) uma sequência de eventos em um espaço de probabilidade \\((\\Omega,\\mathcal F, P)\\). Denotamos por \\(A_n\\uparrow A\\), se \\((A_n)_{n\\geq 1}\\) é uma sequência crescente de eventos e \\[ A = \\bigcup_{n=1}^\\infty A_n. \\] Denotamos por \\(A_n\\downarrow A\\), se \\((A_n)_{n\\geq 1}\\) é uma sequência crescente de eventos e \\[ A = \\bigcap_{n=1}^\\infty A_n. \\] Teorema 2.1 (Continuidade monótona da probabilidade) Seja \\((A_n)_{n\\geq 1}\\) uma sequência de eventos em um espaço de probabilidade \\((\\Omega,\\mathcal F, P)\\). Se \\(A_n \\uparrow A\\), então \\(P(A_n) \\uparrow P(A)\\) (continuidade por baixo). Se \\(A_n \\downarrow A\\), então \\(P(A_n) \\downarrow P(A)\\) (continuidade por cima). Prova. Para provar i. Defina \\(B_1 = A_1\\), \\(B_k = A_k\\setminus A_{k-1}\\), \\(k\\geq 2\\) e note que os eventos \\(B_1,B_2,\\ldots\\) são disjuntos dois a dois. Além disso, \\[ A_n=\\bigcup_{k=1}^n B_k \\; \\; \\; \\text{e} \\; \\; \\; A = \\bigcup_{n=1}^\\infty A_n = \\bigcup_{n=1}^\\infty B_n \\] Logo, \\[\\begin{align} P(A_n) = \\sum_{k=1}^n P(B_k), \\\\ P(A) =\\sum_{n=1}^\\infty P(B_k). \\end{align}\\] Além disso, como \\(A_n\\subset A_{n+1},\\) \\(\\forall n\\geq 1\\), temos que \\(P(A_n)\\leq P(A_{n+1}),\\) \\(\\forall n\\geq 1\\). Finalmente, tomando limite em (1) quando \\(n \\to \\infty\\), temos que \\(P(A_n) \\uparrow P(A)\\). Para provar ii. note que \\(A_n^c \\uparrow A^c\\), logo pela parte i., segue que \\(P(A_n^c) \\uparrow P(A^c)\\), logo \\(1-P(A_n) \\uparrow 1- P(A) \\iff P(A_n) \\downarrow P(A)\\). Definição 2.3 (conjuntos limites) Seja \\(A_1,A_2,\\ldots\\) uma sequência de eventos em um espaço de probabilidade \\((\\Omega, \\mathcal F, P)\\), definimos os eventos \\[\\begin{align} {\\lim\\inf}_{n\\to\\infty} A_n = \\bigcup_{n=1}^\\infty \\bigcap_{k=n}^\\infty A_k \\label{liminf} \\\\ {\\lim\\sup}_{n\\to\\infty} A_n = \\bigcap_{n=1}^\\infty \\bigcup_{k=n}^\\infty A_k \\label{limsup} \\end{align}\\] Da definição de \\(\\liminf A_n\\), temos que \\[\\begin{align*} \\omega \\in {\\lim\\inf}_{n\\to\\infty} A_n &amp;\\iff \\exists n \\geq 1, \\forall k \\geq n, \\; \\omega \\in A_k \\\\ &amp;\\iff |\\{ n : \\omega \\notin A_n\\}|&lt; \\infty. \\end{align*}\\] Da definição de \\(\\limsup A_n\\), temos que \\[\\begin{align*} \\omega \\in {\\lim\\sup}_{n\\to\\infty} A_n &amp;\\iff \\forall n\\geq 1, \\exists k \\geq n, \\; \\omega \\in A_k \\\\ &amp;\\iff |\\{n: \\omega \\in A_n \\}|=\\infty \\end{align*}\\] Daí, é frequentemente usada a seguinte notação: \\[{\\lim\\sup}_{n\\to\\infty} A_n = [A_n \\text{ ocorre infinitas vezes}]\\] \\[{\\lim\\inf}_{n\\to\\infty} A_n = [A_n \\text{ ocorre para todo $n$ suficientemente grande}]\\] Observação. Observe que \\(\\liminf_{n\\to\\infty} A_n \\subset \\limsup_{n\\to\\infty} A_n\\), logo temos a seguinte definição. Definição 2.4 (Limite de uma sequência) Se \\(\\limsup_{n\\to\\infty} A_n \\subset \\liminf_{n\\to\\infty} A_n\\), então dizemos que \\(\\lim_{n\\to\\infty} A_n = A\\), onde \\(A = \\liminf_{n\\to\\infty} A_n = \\limsup_{n\\to\\infty} A_n\\). Teorema 2.2 (Continuidade da probabilidade) Se \\(\\lim_{n\\to\\infty} A_n = A\\), então \\(\\lim_{n\\to\\infty} P(A_n) = P(\\lim_{n\\to\\infty} A_n) = P(A)\\). Prova. Para \\(n\\geq 1\\), defina \\(\\displaystyle B_n = \\bigcap_{k=n}^\\infty A_k\\) e \\(\\displaystyle C_n = \\bigcup_{k=n}^\\infty A_k\\) \\(\\Rightarrow\\) \\(B_n\\subset A_n \\subset C_n\\), logo, \\(P(B_n) \\leq P(A_n) \\leq P(C_n)\\). Além disso, temos que \\(B_n \\uparrow \\liminf A_n\\) e \\(C_n \\downarrow\\limsup A_n\\), logo \\(P(\\liminf A_n) = \\lim P(B_n)\\) e \\(\\lim P(C_n) = P(\\limsup A_n)\\). Agora, \\[ P(\\liminf A_n) \\leq \\liminf P(A_n) \\leq \\limsup P(A_n) \\leq P(\\limsup A_n), \\] mas \\(P(A) = P(\\liminf A_n) = P(\\limsup A_n)\\), logo se \\(P(A_n)\\) converge, temos que \\(\\lim P(A_n) = P(A)\\). 2.1 Limite superior e inferior de uma sequência de números reais. Seja \\((a_n)_{n\\geq 1}\\) uma sequência limitada de números reais, definimos \\[\\begin{align*} b_n=\\inf_{k \\geq n} a_k \\\\ c_n=\\sup_{k \\geq n} a_k \\end{align*}\\] Primeiro, note que como \\((a_n)_{n\\geq 1}\\) é limitada existem \\(m,M\\in\\mathbb R\\), tais que \\[ m \\leq a_n \\leq M, \\; \\; \\; \\forall n \\geq 1. \\] Portanto \\((b_n)_{n\\geq 1}\\) é uma sequência crescente e limitada superiormente por \\(m\\), enquanto \\((c_n)_{n\\geq 1}\\) é uma sequência decrescente e limitada inferiormente por \\(M\\). Logo, definimos: \\[\\begin{align} \\liminf a_n&amp;:=\\lim b_{n} = \\sup_{n\\geq 1} \\inf_{k\\geq n} a_k, \\label{liminfseq} \\\\ \\limsup a_n &amp;:= \\lim c_n = \\inf_{n\\geq 1} \\sup_{k\\geq n} a_k. \\label{limsupseq} \\end{align}\\] O limite dado em \\(\\eqref{liminfseq}\\) é chamado de limite inferior da sequência \\((a_n)\\), similarmente o limite dado em \\(\\eqref{limsupseq}\\) é chamado de limite superior de \\((a_n)\\). Teorema 2.3 Uma sequência \\((a_n)\\) de números reais converge para \\(a\\in\\mathbb R\\) se, e somente se, \\[\\liminf a_n= \\limsup a_n = a.\\] Prova. (\\(\\Leftarrow\\)) Suponha que \\(\\liminf a_n = \\limsup a_n = a\\). Pela definição, de \\(\\liminf\\) e \\(\\limsup\\) de uma sequência de números reais, temos que \\[ a=\\liminf a_n \\leq a_n \\leq \\limsup a_n = a, \\] o resultado segue pelo Teorema do Sanduíche. (\\(\\Rightarrow\\)) Suponha agora que \\(a_n \\to a, \\; n \\to \\infty\\). Dado \\(\\varepsilon &gt;0\\), existe \\(n_0\\in\\mathbb N\\), tal que para \\(n \\geq n_0\\), \\[ a -\\varepsilon &lt; a_n &lt; a + \\varepsilon. \\] Daí, para \\(n \\geq n_0\\) \\[ a -\\varepsilon &lt; \\inf_{k\\geq n} a_k \\leq \\sup_{k \\geq n} &lt; a + \\varepsilon \\iff a -\\varepsilon &lt; b_n \\leq c_n &lt; a + \\varepsilon .\\] Portanto, \\(\\liminf a_n = \\limsup a_n=a\\). "],["vas.html", "Capítulo 3 Variáveis aleatórias 3.1 Definições 3.2 Função de probabilidade 3.3 Função de distribuição acumulada", " Capítulo 3 Variáveis aleatórias Grosso modo, uma variável aleatória pode ser definida como um característico numérico associada ao resultado de um experimento aleatório. Para esclarecer isso, consideremos o experimento aleatório em que uma moeda é lançada 3 vezes, e registramos os resultados em ordem. O espaço amostral para esse experimento é \\[\\Omega = \\{KKK, CKK, KCK, KKC, CCK, CKC, KCC, CCC\\}.\\] Agora, suponha que estamos interessados em saber o número de caras \\(X\\). Os possíveis valores de \\(X\\) estão resumidos na seguinte tabela \\(\\omega\\) \\(KKK\\) \\(CKK\\) \\(KCK\\) \\(KKC\\) \\(CCK\\) \\(CKC\\) \\(KCC\\) \\(CCC\\) \\(X(\\omega) = x\\) \\(0\\) \\(1\\) \\(1\\) \\(1\\) \\(2\\) \\(2\\) \\(2\\) \\(3\\) Note que para cada \\(\\omega \\in \\Omega\\), associamos um valor \\(X(\\omega) \\in \\{0,1,2,3\\}\\subset \\mathbb R\\). Se atribuímos a cada \\(\\omega \\in \\Omega\\) igual probabilidade, isto é, 1/8, então podemos calcular, por exemplo \\[\\begin{eqnarray*} P(X=1) &amp;=&amp; P(\\{\\omega\\in\\Omega: X(\\omega)=1\\}) \\\\ &amp;=&amp; P(\\{CKK, KCK, KKC\\}) \\\\ &amp;=&amp; \\frac{1}{8} + \\frac{1}{8} + \\frac{1}{8} \\\\ &amp;=&amp;\\frac{3}{8}. \\end{eqnarray*}\\] Aplicando o mesmo raciocínio para \\(x=0,2,3\\), obtemos \\(x\\) \\(0\\) \\(1\\) \\(2\\) \\(3\\) \\(P(X=x)\\) \\(1/8\\) \\(3/8\\) \\(3/8\\) \\(1/8\\) Note que \\(\\displaystyle \\sum_{x=0}^3 P(X=x) = 1\\). 3.1 Definições Uma variável aleatória (v.a.) é uma função a valores reais, definida em \\(\\Omega\\). Variáveis aleatórias são denotadas por letras maiúsculas \\(X,Y,Z,\\ldots\\) Os valores possíveis de uma variável aleatória são denotados por letras minúsculas \\(x,y,z,\\ldots\\) Uma variável aleatória é dita discreta se assumir valores em conjunto finito ou infinito enumerável. Uma variável aleatória é dita contínua se assumir valores em um intervalo de \\(\\mathbb R\\). 3.2 Função de probabilidade Seja \\(X\\) uma v.a. discreta assumindo valores no conjunto \\(\\{x_{1}, x_{2}, \\ldots\\}\\) finito ou enumerável. A função \\[p(x) = P(X=x), \\; \\; x\\in \\mathbb R,\\] é dita função de probabilidade de \\(X\\), se satisfaz as seguintes propriedades Se \\(x\\notin \\{x_{1}, x_{2}, \\ldots\\}\\), então \\(p(x)=0\\). \\(p(x_{i}) \\geq 0\\) para qualquer \\(i=1,2,\\ldots\\) \\(\\sum_{i=1}^{\\infty} p(x_{i})=1\\). Se \\(A\\subset \\mathbb R\\), então \\(\\displaystyle P(X \\in A) = \\sum_{i: x_{i}\\in A}p (x_{i})\\). 3.2.1 Exemplos Exemplo 3.1 Três bolas são selecionadas aleatoriamente de uma urna que contém 20 bolas numeradas de 1 a 20. Se apostamos que pelo menos uma das bolas retiradas tem o número maior ou igual a 17, qual a probabilidade de ganharmos? Solução. Seja \\(X\\) o maior número sorteado. Por exemplo, Se \\(\\omega = \\{3,10,5,\\}\\), então \\(X(\\omega) = 10\\) (perdemos a aposta). Se \\(\\omega&#39; = \\{2,5,16\\}\\), então \\(X(\\omega&#39;) = 16\\) (ganhamos a aposta). Agora, suponha que todas as \\(\\binom{20}{3}\\) possíveis seleções são igualmente prováveis. Logo, para \\(x\\in \\{3,\\ldots, 20\\}\\) \\[\\begin{align*} p(x) = P(X=x) = \\frac{\\binom{x-1}{2}}{\\binom{20}{3}}. \\end{align*}\\] Finalmente, queremos obter \\(P(X \\geq 17)\\) \\[\\begin{align*} P(X\\geq 17) &amp;= p(17) + p(18) + p(19) + p(20) \\\\ &amp;= \\frac{\\binom{16}{2}}{\\binom{20}{3}} + \\frac{\\binom{17}{2}}{\\binom{20}{3}} + \\frac{\\binom{18}{2}}{\\binom{20}{3}} + \\frac{\\binom{19}{2}}{\\binom{20}{3}}\\\\ &amp;\\approx 0,105 + 0,119 + 0,134 + 0,150 = 0,508. \\end{align*}\\] Exemplo 3.2 O número de pessoas que entram em uma academia durante um minuto é uma v.a. discreta \\(X\\) com função de probabilidade dada por \\[ p(k) = \\frac{c \\, 4^k}{k!}, \\; k = 0,1,\\ldots \\] Determine: (a) o valor de \\(c\\) \\(P(X&gt;2)\\). Solução. Seja \\(X\\): Número de pessoas que entram naquela academia durante um minuto. Logo \\(\\displaystyle \\sum_{k=0}^\\infty p(k) = 1 \\Rightarrow c \\displaystyle \\sum_{k=0}^\\infty \\frac{4^k}{k!} = 1 \\Rightarrow c e^4 \\Rightarrow c =e^{-4}\\). Portanto, \\[p(k) = \\frac{e^{-4}\\, 4^k}{k!}, \\; k = 0,1,\\ldots \\] \\(P(X&gt;2) = 1- P(X\\leq 2) = 1-[p(0) + p(1) + p(2)] = 1-13\\,e^{-4} \\approx 0,7619\\). 3.3 Função de distribuição acumulada Para todo \\(x\\in \\mathbb R\\), defina \\(F(x) = P(X\\leq x)\\), então \\[\\begin{eqnarray*} F(0) &amp;=&amp; P(X \\leq 0) = p(0) = 1/8, \\\\[0.2cm] F(1) &amp;=&amp; P(X \\leq 1) = p(0) + p(1) = 4/8, \\\\[0.2cm] F(2) &amp;=&amp; P(X \\leq 2) = p(0) + p(1) + p(2) =7/8, \\\\[0.2cm] F(3) &amp;=&amp; P(X \\leq 3) = p(0) + p(1) + p(2) + p(3)= 1. \\end{eqnarray*}\\] Definição 3.1 A função de distribuição (acumulada) de uma variável aleatória \\(X\\) é a função \\(F: \\mathbb R \\rightarrow \\mathbb R\\) definida por \\[\\begin{equation*} F(x) = P(X\\leq x) = P(\\{s\\in \\Omega: X(s)\\leq x\\}), \\; x\\in \\mathbb R. \\end{equation*}\\] 3.3.1 Algumas propriedades da função de distribuição \\(F\\) é uma função não-decrescente, isto é \\[\\begin{align*} \\text{Se } x &lt; y, \\text{ então } F(x) \\leq F(y). \\end{align*}\\] Se \\(X\\) é uma v.a. discreta, então \\[\\begin{align*} F(x) = \\sum_{y \\leq x} p(y). \\end{align*}\\] \\(P(X=x) = P(X\\leq x) - P(X &lt; x) = F(x) - F(x^{-})\\) (salto de \\(F\\) no ponto \\(x\\)). Para \\(a,b\\in\\mathbb R\\) com \\(a &lt; b,\\) \\(P(a&lt; X \\leq b) = F(b) - F(a)\\). 3.3.2 Propriedades fundamentais da função de distribuição (F1) \\(F\\) é não decrescente: \\(x&lt;y \\Rightarrow F(x) \\leq F(y)\\). (F2) \\(F\\) é contínua à direita: \\(x_n\\downarrow x \\Rightarrow F(x_n) \\downarrow F(x)\\). (F3) \\(\\lim_{n\\to \\infty}F(n)=1\\) e \\(\\lim_{n\\to-\\infty} F(n) = 0\\). Qualquer função \\(F: \\mathbb R \\rightarrow \\mathbb R\\) satisfazendo as condições (F1), (F2) e (F3) é função de distribuição de alguma variável aleatória. "],["valoresperado.html", "Capítulo 4 Valor esperado 4.1 Motivação 4.2 Funções de variáveis aleatórias 4.3 Variância 4.4 Independência de variáveis aleatórias", " Capítulo 4 Valor esperado Seja \\(X\\) uma variável aleatória discreta com função de probabiliade \\(p(\\cdot)\\) e assumindo valores em \\(\\{x_1, x_2,\\ldots\\}\\). A esperança matemática, média ou valor esperado de \\(X\\) é definida por \\[\\begin{align*} E(X) = \\sum_{i=1}^\\infty x_i\\, p(x_i). \\end{align*}\\] Observação. Note que a esperança de \\(X\\), é uma média ponderada dos valores de \\(x\\), em que cada valor de \\(x\\) é ponderado por sua probabilidade correspondente. Voltando ao exemplo do lançamento da moeda 3 vezes e, definindo \\(X\\) como o número de caras observadas, temos que \\[ E(X) = 0 \\times \\frac{1}{8} + 1 \\times \\frac{3}{8} + 2 \\times \\frac{3}{8} + 3 \\times \\frac{1}{8} = 1,5. \\] Algumas observações sobre a o valor esperado: O valor esperado pode não ser um dos valores possíveis de \\(X\\), Não se deve arredondar \\(E(X)\\) para um número inteiro. Exemplo 4.1 Seja \\(X:\\) Resultado observado no lançamento de um dado honesto. Determine o valor esperado de \\(X\\). Solução. A função de probabilidade de \\(X\\) é \\[ p(x) = \\frac{1}{x}, \\; x=1,\\ldots,6. \\] Logo \\[ E(X) = \\sum_{x=1}^6 x \\frac{1}{6} = \\frac{1}{6}\\sum_{x=1}^6 x= \\frac{6\\times 7}{6 \\times 2} = \\frac{7}{2}. \\] Exemplo 4.2 Um lote contém 3 itens defeituoso e 5 não defeituosos. Retiram-se 2 itens do lote em sequência, sem reposição. Determine o número esperado de itens defeituosos retirados. Solução. Vamos determinar, primeiro, a função de probabilidade de \\(X:\\) número de itens defeituosos retirados. Para isso, seja \\(D_i\\): o i-ésimo item retirado é defeituoso e \\(B_i\\): o i-ésimo item retirado é bom. Logo: \\[\\begin{align*} p(0)=P(X=0) &amp;= P(B_1\\cap B_2) = P(B_1)P(B_2|B_1) = \\frac{5}{8} \\frac{4}{7} = \\frac{20}{56},\\\\ p(1)=P(X=1) &amp;= P(B_1 \\cap D_2) + P(D_1 \\cap B_2) = \\frac{5}{8} \\frac{3}{7} + \\frac{3}{8} \\frac{5}{7} = \\frac{15}{56} + \\frac{15}{56} = \\frac{30}{56},\\\\ p(2)=P(X=2) &amp;= P(D_1 \\cap D_2) =P(D_1)P(D_2|D_1) = \\frac{3}{8} \\frac{2}{7} = \\frac{6}{56}. \\end{align*}\\] Portanto, \\[ E(X) = 0\\times \\frac{20}{56} + 1 \\times \\frac{30}{56} + 2 \\times \\frac{6}{56} = \\frac{3}{4}. \\] 4.1 Motivação Suponha uma variável aleatória discreta \\(X\\) assumindo valores no conjunto \\(\\{x_1,x_2,\\ldots\\}\\). Essa variável aleatória é o resultado de um experimento aleatório. Suponha que repetimos o experimento \\(N\\) vezes. Seja \\(N_i\\) (\\(i=1,2,\\ldots\\)) o número de vezes que observamos o valor \\(x_i\\). Pela interpretação frequentista da probabilidade, para \\(N\\) suficientemente grande temos que \\[ p(x_i) \\approx \\frac{N_i}{N}, \\] e a média aritmética dos valores observados de \\(X\\) é \\[ \\bar{X} = \\sum_{i=1}^\\infty \\frac{N_i\\, x_i}{N} \\approx \\sum_{i=1}^\\infty p(x_i) x_i = E(X) \\] Essas aproximações são adequadamente justificadas pela Lei dos grandes números. 4.2 Funções de variáveis aleatórias Se \\(X\\) é uma variável aleatória e \\(g\\) uma função a valores reais, então \\(Y=g(X)\\), também é uma variável aleatória. Proposição 4.1 Seja \\(X\\) uma v.a. discreta com função de probabilidade \\(p(x)\\). Para qualquer função \\(g\\) a valores reais, \\[ E[g(X)] = \\sum_{x: p(x)&gt;0} g(x) p(x). \\] Observação. Note que esse resultado permite o cálculo da esperança de \\(Y=g(X)\\), mesmo que se desconheça a distribuição de probabilidade de \\(Y\\). Exemplo 4.3 Seja \\(X\\): Número de caras nos três lançamentos de uma moeda justa, então a função de probabilidade de \\(X\\) é \\(x\\) \\(0\\) \\(1\\) \\(2\\) \\(3\\) \\(p(x)\\) \\(1/8\\) \\(3/8\\) \\(3/8\\) \\(1/8\\) E seja \\(Y=X^2\\), logo, \\[\\begin{align*} E(X^2)=E(Y) = \\sum_{x=0}^3 x^2 p(x) = 0^2\\times \\frac{1}{8} + 1^2 \\times \\frac{3}{8} + 2^2 \\times \\frac{3}{8} + 3^2 \\times \\frac{1}{8} = 3. \\end{align*}\\] Observação. Em geral \\(E(X^2) \\neq [E(X)]^2\\) Exemplo 4.4 Suponha que uma moeda é lançada 3 vezes, e que ganhamos ou perdemos R$1 conforme o número de caras seja par ou ímpar. Qual o valor esperado do nosso lucro? Solução. Seja \\(X\\): Número de caras \\(\\Rightarrow\\) \\(Y=(-1)^X\\): Lucro obtido no jogo. Logo, \\[ E(Y)=E[(-1)^X]=(-1)^0\\times \\frac{1}{8} + (-1)^1 \\times \\frac{3}{8} + (-1)^2 \\times \\frac{3}{8} + (-1)^3 \\times \\frac{1}{8}=0. \\] Corolário 4.1 Se \\(a\\) e \\(b\\) são constantes, então Se \\(a\\) e \\(b\\) são constantes, então \\[ E(aX + b) = a E(X) + b \\] Exemplo 4.5 Uma moeda é lançada 3 vezes, e ganhamos R$5 a cada cara obtida e perdemos R$2 a cada coroa. Qual o valor esperado do nosso lucro? Solução. \\(X\\): Número de caras, \\(3-X\\): Número de coroas \\(\\Rightarrow\\) \\(Y=5X - 2(3-X) =7X - 6\\): Lucro. \\[ E(Y)=E(7X-6) = 7E(X) - 6= 7 \\times \\frac{3}{2} - 6 = \\frac{9}{2}. \\] 4.3 Variância Definição 4.1 A variância de uma v.a. \\(X\\) com esperança \\(\\mu\\) é definida por \\[ \\sigma^2=Var(X)=E[(X-\\mu)^2]. \\] Definição 4.2 O desvio padrão de \\(X\\) é definido por \\(\\sigma=DP(X)= \\sqrt{Var (X)}\\). Exemplo 4.6 Seja \\(X\\) o resultado obtido no lançamento de um dado justo, assim \\[ p(i) = 1/6, \\; \\; i =1,2,3,4,5,6. \\] Logo, \\(E(X) = \\displaystyle\\sum_{i=1}^6 i \\, p(i) = \\frac{1}{6}\\sum_{i=1}^6 i =\\frac{1}{6}\\frac{(6)(7)}{2} = \\frac{7}{2}\\). \\[\\begin{align*} \\sigma^2 &amp;= \\sum_{i=1}^6 (i-E(X))^2 p(i)\\\\ &amp;= \\frac{1}{6}\\left[\\left(1-\\frac{7}{2}\\right)^2 + \\left(2-\\frac{7}{2}\\right)^2 + \\cdots + \\left(6-\\frac{7}{2}\\right)^2\\right] \\\\ &amp;=\\frac{35}{12}. \\end{align*}\\] e, \\[ \\sigma = DP(X) = \\sqrt{\\frac{35}{12}} \\approx 1,70. \\] Proposição 4.2 \\(Var(X) = E(X^2) - [E(X)]^2\\) Prova. Seja \\(\\mu = E(X)\\), \\[\\begin{align*} (X-\\mu)^2 = X^2 - 2X\\mu + \\mu^2, \\end{align*}\\] Logo, \\[\\begin{align*} Var(X) = E[(X-\\mu)^2] &amp;= E(X^2) - 2\\mu^2 + \\mu^2 \\\\ &amp;=E(X^2) - \\mu^2 = E(X^2) - [E(X)]^2. \\end{align*}\\] Proposição 4.3 Se \\(a\\) e \\(b\\) são constantes, então \\[ Var(aX+b) = a^2 Var(X) \\] Corolário 4.2 Seja \\(X\\) uma v.a. tal que \\(E(X) = \\mu\\) e \\(Var(X) = \\sigma^2 &gt;0\\). Defina \\(Z=\\frac{X-\\mu}{\\sigma}\\). Então \\[ E(Z) = 0 \\text{ e } Var(Z) = 1. \\] 4.4 Independência de variáveis aleatórias Definição 4.3 As variáveis aleatórias \\(X_1, \\ldots, X_n\\) são independentes se, para qualquer escolha de conjuntos \\(A_1,\\ldots,A_n \\subset \\mathbb R\\), tem-se que \\[ P(X_1 \\in A_1, \\ldots, X_n\\in A_n) = \\prod_{i=1}^n P(X_i \\in A_i). \\] Definição 4.4 (caso discreto) No caso de variáveis aleatórios discretas, a definição anterior é equivalente à condição de que, para qualquer escolha de \\(x_1,\\ldots,x_n \\in \\mathbb R\\), tem-se que \\[ P(X_1 = x_1, \\ldots, X_n = x_n) = \\prod_{i=1}^n P(X_i=x_i). \\] Proposição 4.4 (Linearidade da esperança) Para quaisquer variáveis aleatórias \\(X_1,\\ldots,X_n\\), temos: \\[ E(X_1 + \\ldots + X_n) = E(X_1) + \\cdots + E(X_n) \\] Proposição 4.5 (Linearidade da variância) Sejam \\(X_1,\\ldots,X_n\\) variáveis aleatórias independentes, temos: \\[ Var(X_1 + \\ldots + X_n) = Var(X_1) + \\cdots + Var(X_n) \\] "],["fgm.html", "Capítulo 5 Função geradora de momentos 5.1 Momentos 5.2 Função geradora de momentos 5.3 Exemplos de \\(M_X(t)\\) para algumas distribuições comuns", " Capítulo 5 Função geradora de momentos 5.1 Momentos Definição 5.1 Seja \\(X\\) uma variável aleaória. Para \\(n \\geq 1\\) inteiro, definimos o n-ésimo momento de \\(X\\) como \\[ \\mu_{(n)} = E(X^n). \\] Observação. No caso em que \\(X\\) é uma v.a. discreta com função de probabilidade \\(p(x)\\), temos que \\[ \\mu_{(n)} = \\sum_{x: p(x)&gt;0} x^n p(x) \\] Observação. Note que para \\(n=1\\), temos que \\(\\mu_{(1)}\\) corresponde à média da v.a. \\(X\\) e, que a variância de \\(X\\) é uma função do primeiro e segundo momento, isto é, \\(Var(X) = \\mu_{(2)} - (\\mu_{(1)})^2\\). 5.2 Função geradora de momentos Definição 5.2 Seja \\(X\\) uma variável aleatória. Definimos a função geradora de momentos de \\(X\\) como: \\[ M_{X}(t) = E(e^{tX}), \\; t \\in \\mathbb{R}. \\] Proposição 5.1 Seja \\(X\\) uma variável aleatória, temos que \\[ M_{X}^{(n)}(t)|_{t=0} = E(X^n) \\] Prova. Procedemos por indução em \\(n\\) \\[\\begin{align*} M_X^{\\prime} (t)=\\frac{d}{dt}M_X(t) &amp;= \\frac{d}{dt}E(e^{tX})\\\\ &amp;=E(\\frac{d}{dt} e^{tX})\\\\ &amp;=E(Xe^{tX}) \\end{align*}\\] Assuma que \\(M^{(n-1)}(t)=\\frac{d^{n-1}}{dt^{n-1}} M_X(t) = E(X^{n-1} e^{tX})\\). Logo \\[\\begin{align*} M^{(n)}(t) &amp;= \\frac{d}{dt} M^{(n-1)}(t)\\\\ &amp;=\\frac{d}{dt}E(X^{n-1} e^{tX})\\\\ &amp;=E(\\frac{d}{dt} X^{n-1} e^{tX})\\\\ &amp;=E(X^n e^{tX}) \\end{align*}\\] Para finalizar a prova, basta avaliar \\(M^{(n)}_X(t)\\) em \\(t=0\\). 5.3 Exemplos de \\(M_X(t)\\) para algumas distribuições comuns Exemplo 5.1 (Bernoulli) Seja \\(X\\) uma v.a. e \\(0&lt;p&lt;1\\), tal que \\[p(0) = 1-p, \\; \\; p(1) = p.\\] Logo, para \\(t\\in\\mathbb R\\), a função geradora de momentos é dada por \\[\\begin{align*} M_{X}(t) &amp;= E(e^{tX}) \\\\ &amp;= e^{t\\cdot 0} \\times p(0) + e^{t\\cdot 1} \\times p(1) \\\\ &amp;= (1-p) + p e^{t}, \\; \\end{align*}\\] Exemplo 5.2 (Geométrica) Seja \\(X\\) uma v.a., cuja função de probabilidade é \\[ p(x) = (1-p)^{x-1}p, \\; x=1,2,\\ldots \\] Logo, para \\(t &lt; \\ln\\left(\\frac{1}{1-p}\\right)\\), a função geradora de momentos de \\(X\\) é \\[\\begin{align*} M_{X}(t) &amp;= E(e^{tX})\\\\ &amp;=\\sum_{x=1}^\\infty e^{tx} (1-p)^{x-1}p\\\\ &amp;=\\frac{p}{1-p} \\sum_{x=1}^\\infty e^{tx} (1-p)^{x}\\\\ &amp;=\\frac{p}{1-p} \\sum_{x=1}^\\infty [e^{t} (1-p)]^{x} \\\\ &amp;=\\frac{p}{1-p}\\cdot \\frac{e^{t} (1-p)}{1- e^{t} (1-p)}\\\\ &amp;=\\frac{p e^{t}}{1- e^{t} (1-p)} \\end{align*}\\] Exemplo 5.3 (Poisson) Seja \\(X\\) uma v.a. cuja função de probabilidade é \\[ p(x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}, \\; x=0,1,\\ldots \\] onde \\(\\lambda &gt;0\\) constante. Logo, para \\(t\\in\\mathbb R\\), a função geradora de momentos é dada por \\[\\begin{align*} M_X(t) &amp;= E(e^{tX})\\\\ &amp;=\\sum_{x=0}^\\infty e^{tx} \\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\ &amp;= e^{-\\lambda}\\sum_{x=0}^\\infty \\frac{(\\lambda e^t)^x}{x!}\\\\ &amp;=e^{-\\lambda} e^{\\lambda e^t}\\\\ &amp;=e^{-\\lambda(1-e^t)} \\end{align*}\\] Proposição 5.2 Sejam \\(a,b\\) constantes e \\(Y=aX+b\\), então \\[ M_Y(t) = e^{tb} M_X(ta) \\] Prova. \\[\\begin{align*} M_Y(t) &amp;= E(e^{t(aX+b)}) \\\\ &amp;=E(e^{(ta)X}e^{tb})\\\\ &amp;=e^{tb}E(e^{(ta)X})\\\\ &amp;=e^{tb}M_X(ta) \\end{align*}\\] "],["modelos-discretos.html", "Capítulo 6 Modelos de distribuições discretas 6.1 Distribuição Uniforme Discreta 6.2 Distribuição de Bernoulli 6.3 Distribuição Binomial 6.4 Distribuição Geométrica 6.5 Distribuição Binomial Negativa (Pascal) 6.6 Distribuição Hipergeométrica 6.7 Distribuição de Poisson 6.8 Aproximação de Poisson à Binomial", " Capítulo 6 Modelos de distribuições discretas Neste capítulo estudaremos vários modelos de distribuições de variáveis aleatórias discretas mais comuns. Ao longo do capítulo usaremos a notação \\(X\\sim\\mathcal D\\) para dizer que \\(X\\) “tem distribuição \\(\\mathcal D\\)”, onde \\(\\mathcal D\\) é uma certa distribuição de probabilidade. 6.1 Distribuição Uniforme Discreta Definição 6.1 Dizemos que a v.a. \\(X\\) tem distribuição uniforme discreta sobre o conjunto \\(\\{x_1,\\ldots,x_n\\}\\subset \\mathbb R\\) se tem função de probabilidade dada por \\[ p(x_i) = \\frac{1}{n}, \\; i =1,2,\\ldots,n. \\] \\(X\\) é um elemento escolhido ao acaso no conjunto \\(\\{x_1,\\ldots,x_n\\}\\). Notação: \\(X\\sim\\) Uniforme discreta\\(\\{x_1,\\ldots,x_n\\}\\). Exemplo 6.1 Seja \\(X\\): Número observado no lançamento de um dado honesto, temos que \\[ p(i)=\\frac{1}{6}, \\; i=1,2,3,4,5,6. \\] Proposição 6.1 Seja \\(X\\sim\\) Uniforme discreta\\(\\{1,\\ldots,n\\}\\), então: \\[\\begin{align*} E(X) = \\frac{n+1}{2} \\text{ e } Var(X) = \\frac{(n-1)(n+1)}{12} \\end{align*}\\] Prova. \\[\\begin{align*} E(X) &amp;= \\frac{1}{n} \\sum_{i=1}^n i = \\frac{1}{n} \\frac{n(n+1)}{2} = \\frac{n+1}{2} \\\\ E(X^2) &amp;= \\frac{1}{n} \\sum_{i=1}^n i^2 = \\frac{1}{n} \\frac{n(n+1)(2n+1)}{6} \\\\ Var(X) &amp;= E(X^2) - [E(X)]^2 = \\frac{(n-1)(n+1)}{12} \\end{align*}\\] 6.2 Distribuição de Bernoulli Definição 6.2 (Ensaio de Bernoulli) Um ensaio de Bernoulli é um experimento com somente dois resultados possíveis: sucesso ou fracasso, de modo que a probabilidade de sucesso é igual a \\(p\\in[0,1]\\). Exemplo 6.2 Exemplos de ensaios de Bernoulli são: Lançamento de uma moeda: cara (sucesso) ou coroa (fracasso). Avaliação de um item: item bom (sucesso) ou item defeituoso (fracasso). Resposta de um munícipe sobre o favorecimento a um projeto de lei: sim (sucesso) ou não (fracasso). Dado um evento \\(A \\subset \\Omega\\) com espaço amostral \\(\\Omega\\) associado a um certo experimento aleatório, podemos definir um ensaio de Bernoulli, da seguinte maneira: dizemos que ocorre sucesso, se \\(A\\) ocorre, e dizemos que ocorre fracasso se, \\(A^c\\) ocorre. Por exemplo, considere o lançamento de um dado honesto e, defina \\(A=\\{6\\}\\): observar a face 5, logo \\(A^c=\\{1,2,3,4,5\\}\\). No exemplo, a probabilidade de sucesso é \\(p=1/6\\). Considere um ensaio de Bernoulli, e defina a v.a. \\(X \\in \\{0,1\\}\\) com distribuição de probabilidade: \\[P(X=1)=p \\text{ e } P(X=0)=1-p,\\] de modo que \\(\\{X=1\\}\\) corresponde ao evento em que ocorreu sucesso e o evento \\(\\{X=0\\}\\) corresponde ao evento em que ocorreu fracasso. Dizemos que \\(X\\) é a da ocorrência de sucesso em um ensaio de Bernoulli. No exemplo do lançamento do dado, temos: \\[ X(\\omega)=\\begin{cases} 1, &amp; \\omega \\in A =\\{6\\}, \\\\ 0, &amp; \\omega \\in A^c=\\{1,2,3,4,5\\} \\end{cases} \\] Definição 6.3 A variável aleatória \\(X\\) definida como a indicadora da ocorrência de sucesso em um ensaio de Bernoulli tem uma distribuição de Bernoulli com parâmetro \\(p\\), cuja função de probabilidade de \\(X\\) é dada por: \\[ p(x) = p^x (1-p)^{1-x}, \\; x=0,1. \\] Notação: \\(X \\sim\\) Bernoulli(\\(p\\)), onde \\(p\\) é chamado de parâmetro de sucesso. Exemplo 6.3 A continuação apresentamos alguns exemplos de variáveis aleatórias com distribuição de Bernoulli: Uma pessoa é selecionada ao acaso entre os moradores de uma cidade, e pergunta-se a ela se concorda com um projeto municipal. As respostas possíveis são SIM (sucesso) ou NÃO (fracasso). Defina: \\[ X=\\begin{cases} 1, &amp; \\text{se a pessoa responde SIM}, \\\\ 0, &amp; \\text{se a pessoa responde NÃO} \\end{cases} \\] No lançamento de uma moeda. Defina: \\[ X=\\begin{cases} 1, &amp; \\text{se sair cara}, \\\\ 0, &amp; \\text{se sair coroa} \\end{cases} \\] Na inspecção de um item de um lote. Defina: \\[ X=\\begin{cases} 1, &amp; \\text{se o item for defeituoso}, \\\\ 0, &amp; \\text{se o item não for defeituoso} \\end{cases} \\] Proposição 6.2 Seja \\(X\\sim\\) Bernoulli(\\(p\\)), temos que \\[ E(X) = p \\text{ e } Var(X) = p(1-p) \\] Prova. \\[\\begin{align*} E(X) &amp;= \\sum_{x=0}^1 x\\, p^x (1-p)^{1-x} = p\\\\ E(X^2) &amp;= \\sum_{x=0}^1 x^2 \\, p^x (1-p)^{1-x} = p \\\\ Var(X) &amp;= E(X^2) - [E(X)]^2 = p-p^2= p(1-p) \\end{align*}\\] 6.3 Distribuição Binomial A distribuição binomial, surge da realização sucessiva de \\(n\\geq 1\\) ensaios independentes de Bernoulli. Por exemplo, considere o experimento de lançar uma moeda honestas 10 vezes esse experimento tem as seguintes características: O experimento lançar uma moeda é um ensaio de Bernoulli. O experimento é realizado 3 vezes. Todos os 3 ensaios são idênticos e independentes. A probabilidade \\(p=1/2\\) de obter uma cara, é constante em todos os ensaios. Nesse experimento, definimos a variável aleatória, \\(X\\), definida como o número de caras obtidas nos 3 lançamentos. Sob as condições do experimento podemos determinar a função de probabilidade de \\(X\\). Podemos determinar que a função de probabilidade de \\(X\\) é: \\[ p(x) = \\binom{3}{x}(1/2)^x(1/2)^{n-x}, \\; x=0,1,2,3. \\] Explicação: \\(\\binom{3}{x}\\): corresponde ao número de maneiras de escolher 2 caras. \\((1/2)^{x}\\): corresponde à probabilidade de observar \\(x\\) caras nos \\(n\\) lançamentos (multiplicamos as probabilidades pois os ensaios são independentes). \\((1/2)^{n-x}\\): corresponde à probabilidade de observar \\(n-x\\) coroas nos \\(n\\) lançamentos (multiplicamos as probabilidades pois os ensaios são independentes). Repare que se \\(X\\sim\\) Binomial(\\(n,p\\)), então \\(X= X_1 + \\ldots + X_n\\), onde \\(X_1,\\ldots,X_n \\overset{iid}{\\sim}\\) Bernoulli(\\(p\\)). De modo que \\(X_i = 1\\) se o \\(i\\)-ésimo ensaio for sucesso ou \\(X_i=0\\) se o \\(i\\)-ésimo ensaio for fracasso. Definição 6.4 Considere \\(n\\geq 1\\) ensaios independentes de Bernoulli e seja \\(p\\) a probabilidade de sucesso em cada ensaio. Logo, a variável aleatória \\(X\\) definida como o número de sucessos nos \\(n\\) ensaios tem uma distribuição binomial de parâmetros \\(n\\) e \\(p\\), cuja função de probabilidade é dada por \\[ p(x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\, x=0,1,\\ldots,n. \\] Notação: \\(X\\sim\\) Binomial(\\(n,p\\)). Observação. Note que pelo Teorema Binomial \\(p(x)\\) é de fato uma função de probabilidade. Com efeito: \\[ \\sum_{x=0}^n \\binom{n}{x} p^x (1-p)^{n-x} = (p+(1-p))^n = 1. \\] Proposição 6.3 Seja \\(X\\sim\\)Binomial(\\(n,p\\)), temos que \\[ E(X) = np \\text{ e } Var(X) = np(1-p) \\] Prova. Usamos o fato que \\(X=\\sum_{i=1}^n X_i\\), em que cada \\(X_1, \\ldots, X_n \\sim\\) Bernoulli(\\(p\\)) independentes. Logo \\[\\begin{align*} E(X) = \\sum_{i=1}^n E(X_i) = np, \\\\ Var(X) = \\sum_{i=1}^n Var(X_i) = np(1-p). \\end{align*}\\] Exemplo 6.4 Suponha que 60% da população de uma cidade é a favor de um projeto proposto pelo prefeito. Seleciona-se uma amostra aleatória de 15 pessoas. Qual a probabilidade de que a amostra contenha no máximo duas pessoas favoráveis ao projeto? Quais são o valor esperado e variância do número de pessoas a favor do projeto na amostra? Solução. Seja \\(X\\) o número de pessoas favoráveis ao projeto na amostra. Então, \\(X\\sim\\) Binomial(15,0.6). \\(P(X\\leq 2) = \\binom{15}{0} (0.6)^0 (0.4)^{15} + \\binom{15}{1} (0.6)^1 (0.4)^{14} + \\binom{15}{0} (0.6)^2 (0.4)^{13}\\) \\(E(X) = 15 \\times 0.6 = 9\\) e \\(Var(X)= 15 \\times 0.6 \\times 0.4 =3.6\\). Proposição 6.4 Seja \\(X\\sim\\) Binomial(\\(n,p\\)), então, à medida que \\(x\\) varia de 0 a \\(n\\), \\(p(x)\\) primeiro cresce e depois decresce, atingindo seu valor máximo quando \\(x=\\lfloor (n+1)p \\rfloor\\): maior inteiro menor ou igual que \\((n+1)p\\). 6.4 Distribuição Geométrica Definição 6.5 Consideremos um ensaio de Bernoulli com probabilidade de sucesso \\(p\\) e realizações sucessivas e independentes desse experimento até que ocorra o primeiro sucesso. A variável aleatória definida como o número de ensaios necessários até o primeiro sucesso tem uma distribuição geométrica de parâmetro \\(p\\), cuja função de probabilidade é dada por \\[ p(x) = (1-p)^{x-1}p, \\; x=1,2,3,\\ldots \\] Notação: \\(X\\sim\\) Geom(\\(p\\)) Observação. Pela série geométrica vemos que \\(p(x)\\) é de fato uma função de probabilidade. Com efeito: \\[ \\sum_{x=1}^\\infty (1-p)^{x-1}p = p\\sum_{x=0} (1-p)^x = p \\times \\frac{1}{1-(1-p)} =1. \\] Proposição 6.5 Seja \\(X\\sim\\) Geom(\\(p\\)), temos que \\[ E(X) = \\frac{1}{p} \\text{ e } Var(X) = \\frac{1-p}{p^2} \\] Prova. Seja \\(q=1-p\\), logo \\[\\begin{align*} E(X) &amp;= \\sum_{x=1}^\\infty x q^{x-1} p \\\\ &amp;= \\sum_{x=1}^\\infty (x-1 + 1) q^{x-1} p \\\\ &amp;= \\sum_{x=1}^\\infty (x-1) q^{x-1} p + \\sum_{x=1}^\\infty q^{x-1} p \\\\ &amp;= q\\sum_{y=0}^\\infty y q^{y-1} p + 1 \\\\ &amp;= q E(X) + 1. \\end{align*}\\] Daí, \\((1-q) E(X)= 1 \\Rightarrow E(X) = \\frac{1}{p}\\). \\[\\begin{align*} E(X^2) &amp;= \\sum_{x=1}^\\infty x^2 q^{x-1}p \\\\ &amp;= \\sum_{x=1}^\\infty (x-1 + 1)^2 q^{x-1}p \\\\ &amp;= \\sum_{x=1}^\\infty (x-1)^2 q^{x-1}p + 2 \\sum_{x=1}^\\infty (x-1) q^{x-1}p + \\sum_{x=1}^\\infty q^{x-1}p \\\\ &amp;= q\\sum_{y=0}^\\infty y^2 q^{y-1} p + 2q \\sum_{y=0}^\\infty yq^{y-1}p + 1 \\\\ &amp;=qE(X^2) + 2q E(X) + 1. \\end{align*}\\] Daí, \\(pE(X^2) = \\frac{2q}{p} +1 \\Rightarrow E(X^2) = \\frac{2q+p}{p^2} = \\frac{q+1}{p^2}\\). Portanto, \\[ Var(X) = E(X^2) - [E(X)]^2= \\frac{q+1}{p^2} - \\frac{1}{p^2} = \\frac{q}{p^2} = \\frac{1-p}{p^2}. \\] Exemplo 6.5 Um dado honesto é lançado repetidamente, de modo independente, até que se obtenha a face 6. Determine: a probabilidade de que sejam necessários exatamente 5 lançamentos. a probabilidade de que sejam necessários pelo menos 4 lançamentos. a esperança e variância do número de lançamentos feitos. Solução. Seja \\(X:\\) Número de lançamentos feitos até obter a face 6. Então, \\(X\\sim\\) Geométrica(\\(p = 1/6\\)). \\(P(X=5)= \\left(\\frac{1}{6}\\right)\\left(\\frac{5}{6}\\right)^4 = \\frac{5^4}{6^5} \\approx 0.0804\\). \\(P(X\\geq 4) = \\sum_{x=4}^\\infty \\left(\\frac{1}{6}\\right)\\left(\\frac{5}{6}\\right)^{x-1} = \\left(\\frac{5}{6}\\right)^3 \\approx 0.5787.\\) \\(E(X)=\\frac{1}{1/6} = 6\\) e \\(Var(X)=\\frac{5/6}{(1/6)^2} = 30\\). 6.5 Distribuição Binomial Negativa (Pascal) Definição 6.6 Consideremos um ensaio de Bernoulli com probabilidade de sucesso \\(p\\) e realizações sucessivas e independentes desse experimento até que ocorra o \\(r\\)-ésimo sucesso. A variável aleatória definida como o número de ensaios necessários até o \\(r\\)-ésimo sucesso tem uma distribuição binomial negativa de parâmetros \\(r\\) e \\(p\\), cuja função de probabilidade é dada por \\[ p(x) = \\binom{x-1}{r-1} p^r(1-p)^{x-r}, \\; x=r,r+1,\\ldots \\] Notação: \\(X \\sim\\) BN(\\(r,p\\)) Observação. Seja \\(y=x-r\\), \\(x=r,r+1\\ldots\\) , \\[\\begin{align*} \\binom{x-1}{r-1} &amp;= \\binom{y+r-1}{r-1} \\\\ &amp;=\\frac{(y+r-1)\\cdots r (r-1)!}{(r-1)! y!}\\\\ &amp;=\\frac{(y+r-1)\\cdots r}{y!} \\\\ &amp;=(-1)^y \\frac{(-r)\\cdots (-y-r+1)}{y!}\\\\ &amp;=(-1)^y\\binom{-r}{y} \\end{align*}\\] Daí, o nome de binomial negativa. Da observação anterior se \\(X\\sim\\) BN(\\(r,p\\)), então pode-se escrever a função de probabilidade de \\(X\\) como \\[ p(x) = (-1)^{x-r} \\binom{-r}{x-r}p^rq^{x-r}, \\; x=r,r+1,\\ldots \\] onde \\(q=1-p\\). Observação. Da série binomial \\[ (1+x)^\\beta = \\sum_{y=0}^\\infty \\binom{\\beta}{y} x^y, \\] temos que \\[ p^{-r} = (1-q)^{-r} = \\sum_{y=0}^\\infty \\binom{-r}{y} (-q)^y, \\] Agora, é facil mostrar que \\(p(x)\\) é de fato uma função de probabilidade \\[\\begin{align*} \\sum_{x=r}^\\infty (-1)^{x-r} \\binom{-r}{x-r}p^rq^{x-r} &amp;=\\sum_{y=0}^\\infty (-1)^y \\binom{-r}{y}p^rq^y\\\\ &amp;= \\sum_{y=0}^\\infty \\binom{-r}{y} (-q)^y p^r = p^{-r} p^r = 1. \\end{align*}\\] Observação. Repare que se \\(X\\sim\\) BN(\\(r,p\\)), então \\(X=\\sum_{i=1}^r X_i\\), tal que \\(X_1,\\ldots,X_r \\overset{iid}{\\sim}\\) Geom(\\(p\\)). A interpretação é a seguinte: \\(X_1\\) representa o número de ensaios até o primeiro sucesso, \\(X_2\\) representa o número de ensaios necessários depois do primeiro sucesso para obter o segundo sucesso e assim por diante. Proposição 6.6 Seja \\(X\\sim\\) BN(\\(r,p\\)), temos que \\[ E(X) = \\frac{r}{p} \\text{ e } Var(X) = \\frac{r(1-p)}{p^2} \\] Prova. \\(X=\\sum_{i=1}^r X_i\\), tal que \\(X_1,\\ldots,X_r\\overset{iid}{\\sim}\\) Geom(\\(p\\)), logo \\[\\begin{align*} E(X) &amp;= \\sum_{i=1}^r E(X_i) = \\frac{r}{p}, \\\\ Var(X) &amp;= \\sum_{i=1}^r Var(X_i) = \\frac{r(1-p)}{p^2}. \\end{align*}\\] Exemplo 6.6 Um dado honesto é lançado repetidamente, de modo independente, até que a face 6 seja obtida 4 vezes. Qual a probabilidade de que sejam necessários exatamente 10 lançamentos? Solução. \\(X:\\) Número de lançamentos necessários até que a face 6 seja obtida 4 vezes. Então \\(X\\sim\\) Binomial Negativa(\\(r=4,p=1/6\\)). Logo \\[ P(X=10) = p(10) = \\binom{10-1}{4-1} (1/6)^4(5/6)^{6} = \\binom{9}{3} (1/6)^4(5/6)^{6} \\approx 0,0217. \\] 6.6 Distribuição Hipergeométrica Definição 6.7 Considere uma urna com \\(N\\) bolas das quais \\(R\\leq N\\) são vermelhas e \\(N-R\\) são pretas. Suponha que selecionamos uma amostra de tamanho \\(n\\leq N\\) sem reposição. A variável aleatória definida como o número de bolas vermelhas selecionadas na amostra tem uma distribuição hipergeométrica de parâmetros \\(n\\), \\(R\\) e \\(N\\) cuja função de probabilidade é dada por \\[ p(x) = \\frac{\\binom{R}{x} \\binom{N-R}{n-x}}{\\binom{N}{n}}, \\; x=0,1,\\ldots n. \\] Notação: \\(X\\sim\\) Hipergeométrica(\\(n,R,N\\)). Observação. Embora tenhamos definido \\(p(x)\\) para qualquer \\(x\\) entre 0 e \\(n\\) simplesmente por mera conveniência, o verdadeiro suporte da distribuição são os valores de \\(x\\) inteiros tais que \\(\\textrm{máx}(0,n-(N-R))\\leq x \\leq \\textrm{mín}(n,R).\\) Exemplo 6.7 Um aluno estuda 12 exercícios, dos quais o professor vai escolher 6 aleatoriamente para uma prova. O estudante sabe resolver 9 dos 12 problemas. Seja \\(X\\) o número de exercícios resolvidos por ele na prova. Qual a distribuição de \\(X\\)? Calcule a probabilidade de que o aluno resolva ao menos 5 exercícios da prova. Solução. Seja X: Número de exercícios resolvidos pelo estudante na prova. \\(X\\sim\\) Hipergeométrica(6,9,12). \\(P(X\\geq 5) = p(5) + p(6) = 1/2.\\) Proposição 6.7 Seja \\(X\\sim\\) Hipergeométrica(\\(n,R,N\\)) e seja \\(p=\\frac{R}{N}\\), então \\[ E(X)=np \\text{ e } Var(X) = \\left(\\frac{N-n}{N-1}\\right) np(1-p) \\] Prova. Seja \\(p=\\frac{R}{N}\\), \\[\\begin{align*} E(X) &amp;= \\sum_{x=1}^n x \\frac{\\binom{R}{x} \\binom{N-R}{n-x}}{\\binom{N}{n}} \\end{align*}\\] Usando as identidades \\[\\begin{align*} x\\binom{R}{x} = R \\binom{R-1}{x-1} \\text{ e } n\\binom{N}{n} = N \\binom{N-1}{n-1} \\end{align*}\\] obtemos \\[\\begin{align*} E(X) &amp;=\\frac{nR}{N} \\sum_{x=1}^n \\end{align*}\\] 6.7 Distribuição de Poisson Definição 6.8 Uma variável aleatória tem distribuição de Poisson de parâmetro \\(\\lambda &gt;0\\) se sua função de probabilidade é \\[ p(x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\; x=0,1,2, \\ldots \\] Notação: \\(X\\sim\\) Poisson(\\(\\lambda\\)) Exemplo 6.8 Alguns exemplos de variáveis que podem ser modeladas por uma distribuição de Poisson são: O número de erros de impressão em uma página. O número de clientes que chegam em uma agência bancária. O número de gols na copa do mundo. O número de partículas \\(\\alpha\\) emitidas por um material radioativo em um período de tempo determinado. Observação. Geralmente a distribuição de Poisson é usada para modelar uma contagem de indivíduos que se distribuem aleatoriamente no tempo ou no espaço. Proposição 6.8 Seja \\(X\\sim\\) Poisson(\\(\\lambda\\)), temos que \\[ E(X) = \\lambda \\text{ e } Var(X)=\\lambda \\] Prova. \\[\\begin{align*} E(X) &amp;=\\sum_{x=0}^\\infty x \\frac{e^{-\\lambda} \\lambda^x}{x!} \\\\ &amp;=\\sum_{x=1}^\\infty \\frac{e^{-\\lambda} \\lambda^x}{(x-1)!}\\\\ &amp;= \\lambda \\sum_{x=1}^\\infty \\frac{e^{-\\lambda} \\lambda^{x-1}}{(x-1)!}\\\\ &amp;= \\lambda \\sum_{y=0}^\\infty \\frac{e^{-\\lambda} \\lambda^y}{y!}\\\\ &amp;=\\lambda. \\end{align*}\\] \\[\\begin{align*} E(X^2) &amp;=\\sum_{x=0}^\\infty x^2 \\frac{e^{-\\lambda} \\lambda^x}{x!} \\\\ &amp;=\\lambda \\sum_{x=1}^\\infty x \\frac{e^{-\\lambda} \\lambda^{x-1}}{(x-1)!} \\\\ &amp;= \\lambda \\sum_{y=0}^\\infty (y+1) \\frac{e^{-\\lambda} \\lambda^y}{y!}\\\\ &amp;= \\lambda \\left[\\sum_{y=0}^\\infty y \\frac{e^{-\\lambda} \\lambda^y}{y!} + \\sum_{y=0}^\\infty \\frac{e^{-\\lambda} \\lambda^y}{y!} \\right]\\\\ &amp;=\\lambda(\\lambda + 1). \\end{align*}\\] Portanto, \\(Var(X) = \\lambda(\\lambda + 1) - \\lambda^2 = \\lambda\\). Exemplo 6.9 Suponha que o número de erros tipográficos em uma única página deste livro tenha uma distribuição de Poisson com \\(\\lambda = 1/2\\). Calcule a probabilidade de que exista pelo menos um erro nesta página. Solução. Seja \\(X\\): Número de erros nesta página, logo \\[ P(X\\geq 1) = 1- P(X\\leq 0) = 1-e^{-1/2} \\approx 0,393. \\] Exemplo 6.10 O número de partículas que uma fonte radioativa emite por minuto é uma variável aleatória com distribuição de Poisson com média igual a 5. Qual a probabilidade de que pelo menos três partículas sejam emitidas em um minuto. Solução. \\[ P(X\\geq 3) = 1-e^{-5}-5e^{-5} -\\frac{5^2e^{-5}}{2!} = 1-\\frac{37}{2}e^{-5} \\approx 0,8753. \\] 6.8 Aproximação de Poisson à Binomial Seja \\(X\\sim\\) Binomial(\\(n,p\\)), com \\(n\\) grande e \\(p\\) pequeno, de modo que o valor \\(\\lambda = np\\) é moderado. E seja \\(Y\\sim\\) Poisson(\\(\\lambda=np\\)), então para qualquer inteiro \\(x\\) entre 0 e \\(n\\), \\[ P(X=x) \\approx P(Y=x) = \\frac{e^{-np} (np)^x}{x!} \\] Essa aproximação decorre do Teorema de Poisson (1832). Observação. Empiricamente, temos as seguintes regras práticas: \\(n\\geq 20\\) e \\(p\\leq 0,05\\) ou \\(n\\geq 100\\) e \\(np \\leq 10\\) Exemplo 6.11 Seja \\(X\\sim\\) Binomial(100,0.065) \\[ P(X=10) = \\binom{100}{10} (0.065)^{10}(0.935)^{90} \\approx 0.05502 \\] Pela aproximação de Poisson à Binomial, usamos \\(Y\\sim\\) Poisson(\\(100\\times 0.065 = 6.5\\)), logo \\[ P(X=10) \\approx P(Y=10) = \\frac{e^{-6.5} (6.5)^{10}}{10!} \\approx 0.05578 \\] "],["vas-continuas.html", "Capítulo 7 Variáveis aleatórias contínuas 7.1 Função de distribuição 7.2 Obtenção de \\(f\\) a partir de \\(F\\) 7.3 Percentis de uma variável aleatória contínua 7.4 Esperança de uma variável aleatória contínua 7.5 Esperança de uma função de uma v.a. contínua 7.6 Variância de uma variável aleatória contínua 7.7 Função geradora de momentos de uma variável aleatória contínua", " Capítulo 7 Variáveis aleatórias contínuas Lembre que uma variável aleatória é dita contínua se assume valores em um intervalo de \\(\\mathbb R\\). Por exemplo, o tempo de vida de um aparelho eletrônico, a temperatura em um determinado dia, a altura de uma pessoa ou o peso de um bebê recém-nascido. Para caracterizar uma variável aleatória usamos a chamada função de densidade, definida a continuação: Definição 7.1 (Função de densidade) Uma função \\(f:\\mathbb R \\rightarrow \\mathbb R\\), é uma função de densidade se satisfaz as seguintes condições: \\(f(x) \\geq 0\\), para qualquer \\(x\\in\\mathbb R\\) \\(\\int_{-\\infty}^\\infty f(x) dx = 1\\). Definição 7.2 Dizemos que \\(X\\) é uma variável (absolutamente) contínua se existir uma função de densidade \\(f\\) tal que para qualquer \\(A \\subset \\mathbb R\\) \\[ P(X\\in A) = \\int_{A} f(x) dx \\] Por exemplo, se quisermos calcular a probabilidade de \\(X\\) pertencer a um intervalo da reta \\([a,b]\\), basta calcular: \\[ P(a\\leq X \\leq b)=\\int_a^b f(x) dx. \\] Exemplo 7.1 Verifique se as seguintes funções são funções de densidade: \\[\\begin{align*} f(x) = \\begin{cases} \\frac{1}{2}, \\; 0 \\leq x \\leq 2\\\\ 0, \\text{caso contrário}. \\end{cases} \\end{align*}\\] \\[\\begin{align*} f(x) = \\begin{cases} e^{-x}, \\; x &gt; 0 \\\\ 0, \\text{caso contrário} \\end{cases} \\end{align*}\\] Apresentamos os gráficos das funções em a. e b., a seguir: Solução. Claramente as funções acima são não negativas para qualquer valor de \\(x\\). Agora, vamos verificar se integram 1. Com efeito: \\[\\begin{align*} \\int_{0}^2 \\frac{1}{2} dx &amp;= \\frac{1}{2} \\left. x\\right|_{0}^{2} \\\\ &amp;= \\frac{1}{2} \\times 2 =1 \\end{align*}\\] \\[\\begin{align*} \\int_0^\\infty e^{-x} dx &amp;= \\left.-e^{-x}\\right|_{0}^\\infty \\\\ &amp;= -(e^{-\\infty} - 1) = 1. \\end{align*}\\] Portanto, as duas funções são funções de densidade. Exemplo 7.2 Suponha que \\(X\\) seja uma variável aleatória contínua cuja função de densidade é dada por \\[ f(x) = \\begin{cases} c(4x - 2x^2) &amp; 0&lt;x&lt;2,\\\\ 0 &amp; \\text{caso contrário} \\end{cases} \\] Qual o valor de \\(c\\)? Determine \\(P(X&gt;1).\\) Solução. Para responder à letra a. usamos o fato que \\(\\int_{-\\infty}^\\infty f(x)=1\\). Com efeito, \\[\\begin{align*} c\\int_0^2 (4x - 2x^2) dx=1, \\end{align*}\\] logo, \\[\\begin{align*} c \\left[2x^2 - \\frac{2x^3}{3}\\right]_{0}^{2} &amp;= 1\\\\ c \\left[8 - \\frac{16}{3}\\right] = 1 \\iff c \\left(\\frac{8}{3}\\right) = 1. \\end{align*}\\] Portanto, \\(c=\\frac{3}{8}\\). \\[\\begin{align*} P(X &gt; 1) = \\int_{1}^{2} \\frac{3}{8} (4x - 2x^2) = 0.5. \\end{align*}\\] Exemplo 7.3 A quantidade de tempo em horas que a bateria de um smartphone funciona sem desligar é uma variável aleatória contínua com função de densidade dada por \\[ f(x) = \\begin{cases} \\frac{1}{10} e^{-1/10}, \\; x &gt; 0,\\\\ 0, \\text{caso contrário} \\end{cases} \\] Qual a probabilidade de que o smartphone funcione entre 5 e 15 horas antes de desligar? ele funciones menos de 10 horas? Solução. Seja \\(X\\): A quantidade de tempo em horas que a bateria de um smartphone funciona sem desligar. \\[\\begin{align*} P(10 &lt; X &lt; 15) &amp;= \\int_5^{15} \\frac{1}{10} e^{-x/10} dx \\\\ &amp;=\\left. -e^{-x/10} \\right|_5^15 = -e^{-3/2} + e^{-1/2} \\approx 0,384. \\end{align*}\\] \\[P(X&lt;10) = \\int_{0}^10 \\frac{1}{10} e^{-x/10} dx = \\left. -e^{-x/10}\\right|_0^10 = 1-e^{-1} \\approx 0,633.\\] Observação. Note que a probabilidade de que uma variável aleatória contínua assuma qualquer valor especifíco é zero, ou seja, se \\(a\\in\\mathbb R\\), então \\(P(X=a)=0\\), pois \\[ P(X=a)=\\int_a^a f(x) dx= 0. \\] Da anterior observação podemos concluir que para \\(a,b\\in\\mathbb R\\) com \\(a&lt;b\\), tem-se que \\[ P(a&lt;X&lt;b) = P(a&lt;X\\leq b) = P(a \\leq X&lt; b)=P(a&lt;X&lt;b). \\] 7.1 Função de distribuição Recorde que a função de distribuição de uma variável aleatória é definida por \\(F(x) = P(X\\leq x)\\), para qualquer \\(x\\in\\mathbb R\\). No caso em que \\(X\\) é uma variável contínua, tem-se que \\[ F(x) = \\int_{-\\infty}^x f(t)dt. \\] Observação. Note que \\(P(a \\leq X \\leq b) = F(b) - F(a)\\). 7.2 Obtenção de \\(f\\) a partir de \\(F\\) Anteriormente, definimos a função de distribuição de uma variável aleatória continua como: \\[ F(x) = \\int_{-\\infty}^x f(t) dt. \\] Ou seja, mostramos como pode-se obter a função de distribuição a partir do conhecimento da função de densidade. O seguinte teorema mostra como pode-se obter a função de densidade a partir da função de distribuição. Teorema 7.1 Se \\(F(x)\\) é a função de distribuição de uma variável aleatória contínua \\(X\\), então \\(f(x)\\) é dada por \\[ f(x) =F^\\prime(x), \\] sempre que exista a derivada. Exemplo 7.4 Suponha que \\[ F(x) = \\begin{cases} 0, \\; x&lt;0 \\\\ x, \\; 0\\leq x \\leq 1 \\\\ 1, \\; x&gt;1 \\end{cases} \\] Logo, \\[ f(x) =F&#39;(x) = \\begin{cases} 0, \\; x&lt;0 \\\\ 1, \\; 0\\leq x \\leq 1 \\\\ 0, \\; x&gt;1 \\end{cases} \\] Exemplo 7.5 Se \\(X\\) é uma variável aleatoria com função de densidade dada por \\[ f(x) = \\begin{cases} 3x^2, \\; 0\\leq x \\leq 1 \\\\ 0, \\; \\text{caso contrário} \\end{cases} \\] Encontre \\(F(x)\\). Solução. Como \\[ F(x) = \\int_{-\\infty}^x f(t) dt, \\] temos que \\[\\begin{align*} F(x)=\\begin{cases} 0, \\; x &lt;0, \\\\ x^3, \\; 0\\leq x\\leq 1, \\\\ 1 \\; x&gt;1 \\end{cases} \\end{align*}\\] 7.3 Percentis de uma variável aleatória contínua Quando dizemos que o salário de um indivíduo esteve no 85-ésimo percentil de uma empresa, queremos dizer que 85% dos salários de toda a empresa estiveram por abaixo desse salário e 15% por em cima. Definição 7.3 Seja \\(p\\in (0,100)\\) um número inteiro. O \\(p\\)-ésimo percentil da distribuição \\(F\\) de uma variável aleatória contínua \\(X\\), denotado por \\(\\eta(p)\\) é definido por \\[ \\frac{p}{100}= F(\\eta(p)) = \\int_{-\\infty}^{\\eta(p)} f(x) dx \\] O 50-ésimo percentil da distribuição \\(F\\) de \\(X\\) chama-se a de \\(F\\) (ou de \\(X\\)), e é denotado por \\(\\tilde{\\mu}\\). Observação. \\(\\eta(p)\\) é o valor no eixo horizontal, tal que \\(p\\)% da área sob o gráfico de \\(f\\) está à esquerda de \\(\\eta(p)\\) e \\((100-p)\\)% está à direita. Exemplo 7.6 A função de distribuição de uma variável aleatória contínua \\(X\\) é \\[\\begin{align*} F(x) = \\begin{cases} 0, &amp; x&lt;0,\\\\ \\frac{x}{2}, &amp; 0 \\leq x \\leq 2 \\\\ 1, &amp; x&gt;2 \\end{cases} \\end{align*}\\] Determine a mediana, \\(\\tilde{\\mu}\\), de \\(F\\). Solução. A mediana \\(\\tilde{\\mu}\\) deve satisfazer a relação \\(0,5 = F(\\tilde\\mu)\\), logo \\(0,5=\\frac{\\tilde\\mu}{2}\\), portanto \\(\\tilde\\mu =1\\). Exemplo 7.7 A função de distribuição de uma variável aleatória contínua \\(X\\) é \\[\\begin{align*} F(x) = \\begin{cases} 1-e^{-2x}, &amp; x\\geq 0,\\\\ 0, &amp; x&lt;0 \\end{cases} \\end{align*}\\] Determine a mediana, \\(\\tilde{\\mu}\\), de \\(F\\). Solução. A mediana \\(\\tilde\\mu\\) satisfaz \\(0.5 = F(\\tilde\\mu)\\), logo \\(0,5=1-e^{-2\\tilde\\mu}\\), portanto \\(\\tilde\\mu = \\frac{\\ln(2)}{2}\\) 7.4 Esperança de uma variável aleatória contínua No capítulo 5, definimos a esperança de uma variável aleatória discreta, \\(X\\), como a soma (sobre os valores de \\(x\\)) do produto \\(x p(x)\\), onde \\(p(x)\\) é a função de probabilidade de \\(X\\). No caso contínuo procederemos de maneira semelhante, porém trocaremos a soma por uma integral e a função de probabilidade pela função de densidade. Daí, temos a seguinte definição. Definição 7.4 Seja \\(X\\) uma variável aleatória contínua com função de densidade \\(f\\), definimos a esperança (valor esperado ou média) de \\(X\\) como \\[ \\mu=E(X)=\\int_{-\\infty}^\\infty x f(x) dx \\] Exemplo 7.8 Considere uma variável aleatória contínua \\(X\\), cuja função de densidade é dada por \\[\\begin{align*} f(x) = \\begin{cases} 1, &amp; 0\\leq x \\leq 1 \\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\end{align*}\\] Encontre \\(E(X)\\). Solução. \\[\\begin{align*} E(X) &amp;= \\int_{0}^1 x dx \\\\ &amp;=\\left.\\frac{x^2}{2}\\right|_0^1 \\\\ &amp;=\\frac{1}{2}. \\end{align*}\\] Exemplo 7.9 Seja \\(X\\) o tempo de vida útil, em meses, de uma lâmpada, cuja função de densidade é dada por \\[\\begin{align*} f(x) = \\begin{cases} e^{-x} &amp; x\\geq 0 \\\\ 0 &amp; \\text{caso contrário} \\end{cases} \\end{align*}\\] Determine \\(E(X)\\). Solução. Procederemos por integração por partes. Seja \\(u=x\\) e \\(dv=e^{-x}\\), logo \\(du=dx\\) e \\(v=-e^{-x}\\) \\[\\begin{align*} E(X) &amp;= \\int_0^\\infty x e^{-x}\\\\ &amp;=\\left.-xe^{-x}\\right|_0^\\infty + \\int_0^\\infty e^{-x} dx \\\\ &amp;=\\left. -e^{-x}\\right|_0^\\infty\\\\ &amp;=1. \\end{align*}\\] 7.5 Esperança de uma função de uma v.a. contínua Suponha que \\(X\\) seja uma variável aleatória contínua e consideremos a variável aleatória \\(h(X)\\) onde \\(h\\) é uma função a valores reais. Logo, podemos calcular a esperança de \\(h(X)\\) através da seguinte proposição. Proposição 7.1 Seja \\(X\\) uma variável aleatória contínua com função de densidade \\(f(x)\\) e \\(h\\) uma função a valores reais, então \\[ E(h(X)) = \\int_{-\\infty}^\\infty h(x)f(x) dx. \\] A anterior proposição é a lei do estatístico inconsciente no caso contínuo. Exemplo 7.10 Duas espécies competem em uma região para controlar uma limitada quantidade de certo recurso. Seja \\(X\\) a v.a. contínua que representa a proporção do recurso controlado pela primeira especie, e suponha que a função de densidade de \\(X\\) é \\[ f(x) = \\begin{cases} 1, &amp; 0 \\leq x\\leq 1 \\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\] Seja \\(h(X)\\) a maior proporção controlada por uma das especies. Calcule a \\(E(h(X))\\). Solução. \\[\\begin{align*} h(X) = \\max\\{X,1-X\\} = \\begin{cases} 1-X, &amp; 0\\leq X\\leq 1/2 \\\\ X, &amp; 1/2\\leq X \\leq 1 \\end{cases} \\end{align*}\\] \\[\\begin{align*} E(h(X)) &amp;= \\int_0^{1/2} (1-x) dx + \\int_{1/2}^{1} x dx\\\\ &amp;= \\left[ x - \\frac{x^2}{2}\\right]_0^{1/2} + \\left.\\frac{x^2}{2}\\right|_{1/2}^{1} = \\frac{3}{4}. \\end{align*}\\] 7.6 Variância de uma variável aleatória contínua Lembre que no caso discreto definimos a variância de uma variável aleatória discreta com função de probabilidade \\(p(x)\\) e média \\(\\mu\\) como a soma dos produtos \\((x-\\mu)^2 p(x)\\). Em caso que \\(X\\) seja uma v.a. contínua definimos a variância de \\(X\\) como segue. Definição 7.5 Seja \\(X\\) uma v.a. contínua com função de densidade \\(f(x)\\) e média \\(\\mu\\), a variância de \\(X\\) é dada por \\[\\begin{align*} Var(X) = E[(X-\\mu)^2] = \\int_{-\\infty}^\\infty (x-\\mu)^2 f(x) dx. \\end{align*}\\] Proposição 7.2 Se \\(X\\) é uma v.a. contínua com função de densidade \\(f(x)\\), então \\[\\begin{align*} Var(X) = E(X^2) - [E(X)]^2 = \\int_{-\\infty}^\\infty x^2 f(x) dx - \\left(\\int_{-\\infty}^\\infty x f(x)\\right)^2dx. \\end{align*}\\] Proposição 7.3 (propriedades da média e da variância) Seja \\(X\\) uma v.a. contínua e \\(a,b\\in \\mathbb R\\), então \\(E(aX + b) = aE(X)+b\\). \\(E(b) = b\\). \\(Var(aX+b)=a^2 Var(X)\\). \\(Var(b)=0\\). 7.7 Função geradora de momentos de uma variável aleatória contínua Seja \\(X\\) uma v.a. contínua com função de densidade \\(f(x)\\). Para \\(n\\geq 1\\) inteiro, o \\(n\\)-ésimo momento de \\(X\\) é definido por \\[ \\mu_{(n)} = E(X^n) = \\int_{-\\infty}^\\infty x^n f(x) dx. \\] Definição 7.6 Seja \\(X\\) uma v.a. contínua com função de densidade \\(f(x)\\), a função geradora de momentos de \\(X\\) é \\[ M_X(t) = E(e^{tX}) = \\int_{-\\infty}^\\infty e^{tx} f(x) dx. \\] Exemplo 7.11 Seja \\(X\\) uma variável aleatória contínua cuja função de densidade é dada por \\[ f(x) = \\begin{cases} 1, &amp; 0\\leq x \\leq 1,\\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\] Encontre \\(M_X(t)\\). Solução. Seja \\(t\\neq 0\\). Logo \\[\\begin{align*} M_X(t) &amp;= \\int_0^1 e^{tx} dx \\\\ &amp;=\\left. e^{tx}\\right|_0^t \\\\ &amp;=\\frac{e^t-1}{t}. \\end{align*}\\] Portanto, \\[ M_X(t) = \\begin{cases} \\frac{e^t-1}{t} &amp; t\\neq 0 \\\\ 1 &amp; t=0. \\end{cases} \\] Exemplo 7.12 Seja \\(X\\) a precipitação pluviométrica de um município em um certo dia, cuja função de densidade é dada por \\[\\begin{align*} f(x) = \\begin{cases} \\lambda e^{-\\lambda x} &amp; x\\geq 0 \\\\ 0 &amp; \\text{caso contrário} \\end{cases} \\end{align*}\\] onde \\(\\lambda &gt;0\\) é uma constante. Encontre \\(M_X(t)\\). Solução. Seja \\(t&lt;\\lambda\\). Logo \\[\\begin{align*} M_X(t)&amp;=\\lambda \\int_0^\\infty e^{tx} e^{-\\lambda x} dx\\\\ &amp;=\\lambda \\int_0^\\infty e^{-(\\lambda-t)x} dx\\\\ &amp;=\\lambda \\frac{1}{\\lambda-t} \\left. e^{-(\\lambda-t)x}\\right|_{x=0}^{x=\\infty} \\\\ &amp;=\\frac{\\lambda}{\\lambda-t} \\end{align*}\\] "],["modelos-continuos.html", "Capítulo 8 Modelos de distribuições contínuas 8.1 Distribuição uniforme contínua 8.2 Distribuição exponencial 8.3 Distribuição normal 8.4 Quantis da distribuição normal 8.5 Aproximação normal à binomial 8.6 A curtose e a distribuição normal 8.7 Distribuição Gama 8.8 Distribuição qui-quadrada 8.9 Distribuição t-Student 8.10 Distribuição de Cauchy-Lorentz 8.11 Distribuição Beta 8.12 Distribuição Log-Normal 8.13 Distribuição de Pareto 8.14 Distribuição de Weibull 8.15 Distribuição de Laplace (dupla exponencial)", " Capítulo 8 Modelos de distribuições contínuas 8.1 Distribuição uniforme contínua Definição 8.1 Dizemos que a variável aleatória \\(X\\) tem distribuição uniforme contínua no intervalo \\([a,b]\\), se sua função de densidade é \\[ f(x) = \\begin{cases} \\frac{1}{b-a} &amp; a \\leq x \\leq b, \\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\] Notação: \\(X\\sim\\) Uniforme Contínua(\\([a,b]\\)) A função de distribuição de uma variável uniforme contínua no intervalo \\([a,b]\\) é \\[ F(x) = \\begin{cases} 0, &amp; x&lt;a\\\\ \\frac{x-a}{b-a}, &amp; a\\leq x \\leq b\\\\ 1, &amp; x \\geq b \\end{cases} \\] Proposição 8.1 Se \\(X \\sim\\) Uniforme Contínua(\\([a,b]\\)), então \\[ E(X) = \\frac{a+b}{2} \\text{ e } Var(X) = \\frac{(b-a)^2}{12} \\] Exemplo 8.1 A eficiência \\(X\\) de um certo componente eletrico é modelada por uma variável aleatória contínua com distribuição uniforme no intervalo \\([0,100]\\). Qual a probabilidade de que \\(X\\) esteja entre 60 e 80 unidades seja menor que 90 unidades Solução. Seja \\(X\\): eficiencia do componente eletrico \\(P(60 \\leq X \\leq 80) = F(80) - F(60) = 0,20\\). \\(P(X\\leq 90) = F(90)=0,90.\\) 8.2 Distribuição exponencial Definição 8.2 Dizemos que a variável aleatória \\(X\\) tem distribuição exponencial de parâmetro \\(\\lambda &gt; 0\\) se, sua função de densidade é \\[ f(x) = \\begin{cases} \\lambda e^{-\\lambda x} &amp; x \\geq 0 \\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\] Notação: \\(X\\sim\\) Exponencial(\\(\\lambda\\)). A função de distribuição de uma variável exponencial de parâmetro \\(\\lambda\\) é \\[\\begin{align*} F(x) = \\begin{cases} 1-e^{-\\lambda x}, &amp; x \\geq 0 \\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\end{align*}\\] Proposição 8.2 Se \\(X \\sim\\) Exponencial(\\(\\lambda\\)), então \\[ E(X) = \\frac{1}{\\lambda} \\text{ e } Var(X) = \\frac{1}{\\lambda^2} \\] Exemplo 8.2 O tempo de atendimento, em minutos, a um cliente em um serviço de informação de uma biblioteca é uma variável aleatória contínua com distribuição exponencial, com um tempo médio de atendimendo de 5 minutos. Qual a probabilidade de que o atendimento a um cliente dure mais de 10 minutos ? Solução. Seja \\(X\\): Tempo de atendimento, em minutos, a um cliente em um serviço de informação de uma biblioteca \\(\\sim\\) Exponencial(\\(\\lambda = 1/5\\)). \\[ P(X &gt; 10) = 1- P(X\\leq 10) = 1-F(10) = e^{-10/5} = 0,1353.\\] 8.3 Distribuição normal A distribuição normal é a distribuição contínua utilizada com mais frequência nas aplicações da teoria da probabilidade. Ela constitui a base para o desenvolvimento de muitos dos métodos da Estatística. Definição 8.3 Dizemos que a variável aleatória \\(X\\) tem uma distribuição normal de parâmetros \\(\\mu \\in \\mathbb R\\) e \\(\\sigma^2&gt;0\\), se sua função de densidade é \\[ f(x) = \\frac{1}{\\sqrt{2\\pi} \\sigma} e^{-(x-\\mu)^2/2\\sigma^2}, \\; x \\in \\mathbb R. \\] Notação: \\(X\\sim\\) N(\\(\\mu\\),\\(\\sigma^2\\)). A distribuição normal também é conhecida como a distribuição de Laplace-Gauss. No seguinte gráfico apresentamos várias curvas da normal para diferentes valores dos parâmetros \\(\\mu\\) e \\(\\sigma^2\\). A função de distribuição da normal é \\[ F(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\int_{-\\infty}^x e^{-(t-\\mu)^2/2\\sigma^2} dt, \\; x\\in \\mathbb R. \\] 8.3.1 Propriedades da distribuição normal A densidade \\(f\\) é simétrica em torno de \\(\\mu\\), isto é: \\(f(\\mu+ x) = f(\\mu - x)\\) para qualquer \\(x\\in \\mathbb R\\). Para qualquer \\(x\\in\\mathbb R\\), \\(F(\\mu + x) + F(\\mu-x) = 1\\). \\(x=\\mu\\) é o único ponto de máximos de \\(f\\), e o valor máximo é \\(\\frac{1}{\\sigma \\sqrt{2\\pi}}\\). \\(f\\) tem dois pontos de inflexão: \\(x=\\mu - \\sigma\\) e \\(x=\\mu + \\sigma\\). \\(\\lim_{x\\to \\pm \\infty} f(x) = 0\\). O desvio padrão \\(\\sigma\\) determina a largura da curva da normal: quanto maior \\(\\sigma\\) tem-se uma curva mais larga e achatada, dito de ooutra maneira, quanto maior \\(\\sigma\\) menos concentrada perto de \\(\\mu\\) a densidade é (veja a figura a continuação). 8.3.2 A distribuição normal padrão A distribuição normal padrão resulta quando os parâmetros de uma distribuição normal correspondem a \\(\\mu = 0\\) e \\(\\sigma^2 = 1\\). Ou seja, dizemos que a variável \\(Z\\sim\\) N(0,1) se sua função de densidade é \\[ \\phi(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2}, \\; z\\in \\mathbb R. \\] A função de distribuição de uma normal padrão é denotada pela letra grega \\(\\Phi\\) maiúscula e é dada por \\[ \\Phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^z e^{-t^2/2} dt, \\; x\\in\\mathbb R. \\] Observação. Os valores de \\(\\Phi(z)\\) não são possíveis de obter analiticamente, no entanto, podem ser aproximados numericamente e encontram-se tabelados para os valores de \\(z\\geq 0\\). Note que se \\(z&lt;0\\), podemos calcular \\(\\Phi(z)\\) através de \\(\\Phi(z) = 1-\\Phi(-z)\\). A continuação apresentamos alguns resultados úteis para o cálculo de probabilidades envolvendo uma distribuição normal. Proposição 8.3 Seja \\(X\\) uma variável aleatória com média \\(\\mu\\) e variância \\(0&lt;\\sigma^2&lt;\\infty\\). Se \\[ Z = \\frac{X-\\mu}{\\sigma}, \\] então \\(E(Z) = 0\\) e \\(Var(Z)=1\\). Proposição 8.4 Seja \\(X\\sim\\) N(\\(\\mu,\\sigma^2\\)), e defina \\(Y=aX + b\\), então \\(Y\\sim\\) N(\\(a\\mu + b\\), \\(a^2 \\sigma^2\\)). Prova. \\[\\begin{align*} F_Y(y) &amp;= P(Y \\leq y) \\\\ &amp;= P(aX + b \\leq y) \\\\ &amp;=P\\left(X\\leq\\frac{y-b}{a}\\right)\\\\ &amp;=F_X\\left(\\frac{y-b}{a}\\right) \\end{align*}\\] Logo, \\[\\begin{align*} f_Y(y) &amp;= F_Y&#39;(y)\\\\ &amp;=\\frac{1}{a} F_X&#39;\\left(\\frac{y-b}{a}\\right) \\\\ &amp;=\\frac{1}{a}f_X\\left(\\frac{y-b}{a}\\right)\\\\ &amp;=\\frac{1}{\\sqrt{2\\pi} (a\\sigma)} e^{-(y-(a\\mu + b))^2/2(a^2\\sigma^2)} \\end{align*}\\] Corolário 8.1 Seja \\(X\\sim\\) N(\\(\\mu,\\sigma^2\\)), então \\(Z=\\frac{X-\\mu}{\\sigma}\\sim\\) N(0,1). Corolário 8.2 Seja \\(Z\\sim\\) N(0,1), então \\(X = \\sigma Z + \\mu \\sim\\) N(\\(\\mu,\\sigma^2\\)) Proposição 8.5 Se \\(X\\sim\\) N(\\(\\mu,\\sigma^2\\)), então \\[ E(X) = \\mu \\text{ e } Var(X) = \\sigma^2. \\] Prova. Podemos escrever \\(X = \\sigma Z + \\mu\\), onde \\(Z\\sim N(0,1)\\), logo \\(E(X) = \\sigma E(Z) + \\mu = \\mu\\) e \\(Var(X)=\\sigma^2 Var(Z) = \\sigma^2\\). 8.3.3 Calculando probabilidades de uma \\(N(\\mu,\\sigma^2)\\) a partir da \\(N(0,1)\\) Seja \\(F\\) a função de distribuição de uma variável aleatória normal com média \\(\\mu\\) e variância \\(\\sigma^2\\), e \\(\\Phi\\) a função de distribuição de uma normal padrão, para qualquer \\(a\\in \\mathbb R\\), tem-se que \\[ F(a)=P(X\\leq a) = P\\left(Z \\leq \\frac{a-\\mu}{\\sigma}\\right) = \\Phi\\left(\\frac{a-\\mu}{\\sigma}\\right). \\] Exemplo 8.3 Suponha que os diâmetros das bolas de golf produzidas por uma companhia seguem uma distribuição normal com \\(\\mu = 1,96\\) polegadas e \\(\\sigma = 0,04\\) polegadas. Uma bola de golf é considerada defeituosa se seu diâmetro é menor que 1,90 polegadas ou maior que 2,02 polegadas. Qual a porcentagem de bolas de golf defeituosas fabricadas pela companhia? Solução. Seja \\(X\\): Diâmetro de uma bola de golf fabricada pela companhia. Logo, \\[\\begin{align*} P(X &lt; 1,90 \\text{ ou } X&gt; 2,02) &amp;= 1- P(1,90 \\leq X \\leq 2,02) \\\\ &amp;=1-[F(2,02)-F(1,90)]\\\\ &amp;=1-\\left[\\Phi\\left(\\frac{2,02 -1,96}{0,04}\\right) -\\Phi\\left(\\frac{1,90 -1,96}{0,04}\\right)\\right]\\\\ &amp;=1-[\\Phi(1,5)-\\Phi(-1,5)]\\\\ &amp;=2-2\\Phi(1,5)\\\\ &amp;=2-2(0,9331)=0,1336 \\end{align*}\\] 8.4 Quantis da distribuição normal Seja \\(X\\) uma variável aleatória contínua com função de distribuição \\(F\\) e seja \\(p\\in(0,1)\\), definimos o \\(p\\)-ésimo quantil como o valor \\(Q(p)\\) tal que \\(F(Q(p)) = p\\). No caso de \\(X \\sim\\) \\(N(\\mu,\\sigma^2)\\), temos que \\[\\begin{align*} F(Q(p)) = \\Phi\\left(\\frac{Q(p) - \\mu}{\\sigma}\\right) = p. \\end{align*}\\] Note que devemos encontrar o \\(p\\)-ésimo quantil da normal padrão, denotado por \\(z(p)\\) e logo \\(Q(p)\\) será o valor tal que \\(z(p) = \\frac{Q(p) - \\mu}{\\sigma}\\), isto é, \\(Q(p) = \\mu + \\sigma z(p)\\). Por exemplo, se \\(p=0,05\\), queremos achar o valor \\(z(p)\\) tal que \\(\\Phi(z(p)) = p = 0,05\\), Neste caso, procurando na tabela da normal, temos que \\(z(0,05)=-1.64\\) e \\(Q(0.05) = \\mu + 0,05 \\sigma\\). Veja a figura a seguir: Em Inferência Estatística, os quantis de uma distribuição normal padrão recebem o nome de valores críticos e frequentemente é usada a notação: \\(z_\\alpha= z(1-\\alpha), \\; \\alpha \\in (0,1)\\) e eles tem um papel fundamental na definição de intervalos de confiança e a região crítica de testes de hipóteses. Exemplo 8.4 Numa população o nível sérico de colesterol em adultos (medido em mg/dl) é uma variável aleatória com distribuição normal com parâmetros \\(\\mu=225\\) e \\(\\sigma=75\\). Calcule o valor acima do qual se encontra o colesterol de 10% da população que tem os níveis mais elevados. Solução. Seja \\(X\\): Nível de colesterol de uma pessoa selecionada aleatoriamente dessa população \\(\\sim\\) N(225,\\(75^2\\)), logo \\[ Z = \\frac{X - 225}{75} \\sim \\text{N(0,1)}. \\] Queremos achar valor \\(a\\) tal que \\(P(X &gt; a) = 0.10 \\iff P(X \\leq a)=0.90\\), ou seja, \\(a=Q(0.90)\\). Logo, \\(a=\\mu + \\sigma z(0.90)= 225 + 75 \\times 1,28 = 321\\). Portanto, 10% da população tem um nível de colesterol acima de 321 mg/dl. 8.5 Aproximação normal à binomial Lembre que uma variável aleatória \\(X\\) tem distribuição binomial com parâmetros \\(n\\) e \\(p\\) se sua função de probabilidade é dada por \\[ p(x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\; x=0,1,\\ldots, n. \\] Quando \\(n\\) é muito grande por veces resulta inviável calcular a probabilidade de que \\(X\\) assuma um certo conjunto de valores. Consideremos o seguinte exemplo: Exemplo 8.5 Durante um longo período tem se determinado que 70% dos advogados que apresentam o exame da OAB são aprovados. Suponha que 500 advogados que apresentam o exame, qual a probabilidade de que pelo menos 370 deles sejam aprovados. Seja \\(X\\): Número de advogados que aprovam o exame dentre os 500 \\(\\sim\\) Binomial(500,0.70). \\[ P(X \\geq 370) = \\sum_{x=370}^{500} \\binom{500}{x} (0.70)^x (0.30)^{500-x} \\] Nesse caso teriamos que calcular 131 probabilidades binomiais, o que resulta uma tarefa bastante tediosa se tivessemos que usar uma calculadora ou pior se tivessemos que realizar o cálculo “à mão”. Diante dessa situação podemos usar a distribuição normal para aproximar probabilidades binomiais. O seguinte teorema mostra como isso pode ser feito. Teorema 8.1 Seja \\(X\\sim\\) Binomial(\\(n,p\\)). Se \\(n\\) é suficientemente grande, então para \\(x=0,1,\\ldots,n\\) \\[\\begin{align*} P(X \\leq x) = P(X \\leq x+0,5) &amp;\\approx \\Phi\\left( \\frac{x + 0,5 - np}{\\sqrt{np(1-p)}} \\right) \\\\ P(x \\leq X \\leq y) = P(x - 0,5\\leq X \\leq y+0,5) &amp;\\approx \\Phi\\left(\\frac{ y + 0,5 - np}{\\sqrt{np(1-p)}}\\right) - \\Phi\\left(\\frac{ x - 0,5 - np}{\\sqrt{np(1-p)}}\\right) \\end{align*}\\] Observação. O procedimento de substrair e somar 0,5 é conhecido como correção de continuidade de Fisher e fornece uma aproximação mais precisa, especialmente quando \\(n\\) não for muito grande. Dois critérios que oferecem uma boa aproximação comumente usados são: \\(np\\geq 5\\) e \\(n(1-p) \\geq 5\\) ou \\(np(1-p)\\geq 10\\). A continuação apresentamos a função de probabilidade de uma distribuição binomial e a densidade da distribuição normal para diferentes valores de \\(n\\) e \\(p\\). Agora, usaremos o Teorema 9.1. para responder ao Exemplo 9.4. Nesse caso \\(\\mu = 500\\times 0.70 = 350\\) e \\(\\sigma^2 = 500 \\times 0.70 \\times 0.30 = 105\\) \\[\\begin{align*} P(X\\geq 370) &amp;= 1 - P(X \\leq 369) \\\\ &amp;=1-\\Phi\\left( \\frac{369 +0,5 - 350}{\\sqrt{105}} \\right)\\\\ &amp;=1-\\Phi(1.90)\\\\ &amp;=1-0,9713\\\\ &amp;=0.0287. \\end{align*}\\] Portanto, a probabilidade de pelo menos 370 advogados aprovem o exame da OAB é aproximadamente de 2%. Exemplo 8.6 Um fabricante sabe por experiência que o 4% de um lote contendo um certo produto é rejeitado por defeitos. Se um novo lote de 800 unidades vai ser inspecionado. Qual a probabilidade aproximada de que menos de 35 unidades sejam rejeitadas? Solução. Seja \\(X\\): Número de produtos rejeitados por defeito \\(\\sim\\) Binomial(800,0,04), podemos usar a distribuição normal com \\(\\mu = 800 \\times 0,04 = 32\\) e \\(\\sigma^2 = 800 \\times 0,04 \\times 0,96 = 30,72\\). Logo, \\[ P(X&lt;35) = P(X\\leq 34) = \\Phi\\left( \\frac{34+0,5 - 32}{\\sqrt{30,72}}\\right) = \\Phi(0,45)=0,6736. \\] Exemplo 8.7 O tamanho ideal de uma turma de primeiro ano em uma faculdade particular é de 150 alunos. A faculdade, sabendo de experiências anteriores que, em média, apenas 30% dos alunos aceitos vão de fato seguir o curso, usa a prática de aprovar os pedidos de matrícula de 450 estudantes. Calcule a probabilidade de que mais de 150 estudantes de primeiro ano frequente as aulas nesta faculdade. Solução. Seja \\(X\\): Número de estudantes que seguem o curso, então \\(X\\) é uma variável binomial com distribuição binomial com parâmetros \\(n=450\\) e \\(p=0,3\\). Usando a aproximação normal à binomial, temos que \\[\\begin{align*} P(X\\geq 150) &amp;\\approx 1-\\Phi\\left( \\frac{150 + 0,5 - (450)(0,3)}{\\sqrt{(450)(0,3)(0,7)}} \\right) \\\\ &amp;=1-\\Phi(1,59) \\\\ \\approx 0,0559. \\end{align*}\\] Portanto, menos do 6% das vezes mais que 150 dos 450 estudantes aceitos vão de fato seguir o curso. 8.6 A curtose e a distribuição normal A curtose é uma medida de forma que mostra o achatamento da curva da função de densidade de probabilidade de uma variável aleatória. Definição 8.4 Tomando a distribuição normal como referência, diremos que uma distribuição pode ser menos “achatada” que a normal (LEPTOCÚRTICA) ou mais “achatada” que a normal (PLATICÚRTICA). A distribuição normal desde o ponto de vista da curtose, é chamada de MESOCÚRTICA. Definição 8.5 Seja \\(X\\) uma variável aleatória (discreta ou contínua) com média \\(\\mu\\) e variância \\(\\sigma^2\\). Então, o coeficiente de curtose de \\(X\\) é definida como \\[ \\kappa = \\frac{E[(X-\\mu)^4]}{\\sigma^4} - 3 \\] Critério Se \\(\\kappa &lt; 0\\), então a distribuição de \\(X\\) é leptocúrtica. Se \\(\\kappa = 0\\), então a distribuição de \\(X\\) é mesocúrtica. Se \\(\\kappa &gt; 0\\), então a distribuição de \\(X\\) é platicúrtica. 8.7 Distribuição Gama Definição 8.6 A função Gama de Euler \\(\\Gamma: (0,\\infty) \\rightarrow \\mathbb R\\) é definida por \\[ \\Gamma(\\alpha) = \\int_{0}^\\infty x^{\\alpha-1} e^{-x} dx, \\] e possui as seguintes propriedades: \\(\\Gamma(\\alpha + 1)= \\alpha \\Gamma(\\alpha)\\), \\(\\alpha &gt;0\\). \\(\\Gamma(n+1) = n!\\) para \\(n\\geq 0\\) inteiro. Definição 8.7 Dizemos que uma variável aleatória \\(X\\) tem distribuição gama com parâmetros \\(\\alpha &gt;0\\) e \\(\\lambda&gt;0\\) se, sua função de densidade é \\[ f(x) = \\begin{cases} \\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha -1} e^{-\\lambda x}, &amp; x &gt;0 \\\\ 0, &amp; \\text{caso contrário} \\end{cases} \\] Notação: \\(X \\sim\\) Gama(\\(\\alpha,\\lambda\\)) O parâmetro \\(\\alpha\\) é um parâmetro de forma, ao passo que o parâmetro \\(\\lambda\\) é um parâmetro de escala, podemos reparametrizar essa distribuição introduzindo a mudança \\(\\theta = 1/\\lambda\\), neste caso \\(\\theta\\) é chamado de taxa da distribuição. A continução apresentamos várias curvas da densidade da gama para diferentes valores de \\(\\alpha\\) e \\(\\lambda\\). Como \\(f\\) é uma função de densidade, temos que: \\[ \\int_{0}^\\infty x^{\\alpha - 1}e^{-\\lambda x} dx = \\frac{\\Gamma(\\alpha)}{\\lambda^\\alpha}, \\; \\alpha, \\lambda &gt; 0. \\] Além disso, Se \\(\\lambda = 1\\), a distribuição é chamada de gama padrão e, sua função de densidade é dada por \\[ f_1(x;\\alpha) = \\frac{1}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-x}, \\; x&gt;0 \\] Se \\(\\alpha=1\\), então Gama(\\(1,\\lambda\\)) \\(\\equiv\\) Exponencial(\\(\\lambda\\)). A função de distribuição de uma gama padrão é definida por \\[ F_1(x;\\alpha) = \\int_0^x \\frac{1}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-x}, \\; x&gt;0, \\] e recebe o nome de função gama incompleta. Proposição 8.6 Seja \\(X\\sim\\) Gama(\\(\\alpha,\\lambda\\)), então \\[ F_X(x) = F_1(\\lambda x;\\alpha) \\] Prova. Seja \\(x&gt;0\\), logo \\[\\begin{align*} \\frac{d}{dx} F_1(\\lambda x;\\alpha) &amp;= \\lambda f_1(\\lambda x;\\alpha) \\\\ &amp;=\\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-\\lambda x}\\\\ &amp;=f_X(x) \\end{align*}\\] Portanto, \\(F_1(\\lambda x;\\alpha) = F_X(x)\\). Proposição 8.7 Seja \\(X\\sim\\) Gama(\\(\\alpha,\\lambda\\)), então: \\[E(X) =\\frac{\\alpha}{\\lambda} \\text{ e } Var(X) = \\frac{\\alpha}{\\lambda^2}\\] Exemplo 8.8 Suponha que o tempo de sobrevivência de um rato macho em semanas exposto a 240 rads de radiação gamma tem uma uma distribuição gama com \\(\\alpha = 8\\) e \\(\\lambda = 1/15\\). Determine a probabilidade de que um rato sobreviva entre 60 e 120 semanas. a probabilidade de que um rato sobreviva pelo menos 30 semanas. o tempo médio de sobrevivência de um rato. Solução. Seja \\(X\\): Tempo de sobrevivência de um rato, em semanas, exposto a 240 rads de radiação gamma \\(\\sim\\) Gama(\\(\\alpha=8\\),\\(\\lambda=1/15\\)). Logo Queremos calcular \\(P(60 \\leq X \\leq 120)\\). Com efeito, \\[\\begin{align*} P(60 \\leq X \\leq 120) &amp;= F_X(120)- F_X(60) \\\\ &amp;=F_1\\left(\\frac{120}{15};8\\right) - F_1\\left(\\frac{30}{15};8\\right) \\\\ &amp;=F_1(8;8)-F_1(4;8) = 0,547 - 0,051 = 0,496. \\end{align*}\\] \\(P(X \\geq 30) = 1-F_X(30)=1 - F_1\\left(\\frac{30}{15};8\\right) = 1 - F(2) = 1- 0,001 = 0,999\\) \\(E(X) = \\frac{\\alpha}{\\lambda} = (8)(15) = 120\\) semanas. 8.8 Distribuição qui-quadrada Definição 8.8 Dizemos que uma variável aleatória \\(X\\) tem distribuição qui-quadrada com \\(\\nu\\) graus de liberdade se, sua função de densidade é \\[ f(x) = \\begin{cases} \\frac{1}{2^{\\nu/2}\\Gamma(\\nu/2)} x^{(\\nu/2)-1}e^{-x/2}, x&gt;0 \\\\ 0, \\text{caso contrário} \\end{cases} \\] Observação. Note que, se \\(\\alpha = \\nu/2\\) e \\(\\lambda = 1/2\\), então Gama(\\(\\nu/2,1/2\\)) \\(\\equiv\\) \\(\\chi^2_{\\nu}\\). A figura abaixo mostra diferentes curvas da função de densidade de uma qui-quadrado para diferentes valores de \\(\\nu\\). 8.9 Distribuição t-Student Definição 8.9 Dizemos que uma variável aleatória \\(X\\) tem distribuição \\(t\\)-Student com \\(\\nu\\) graus de liberdade se, sua função de densidade é \\[ f(x) = \\frac{\\Gamma(\\frac{\\nu + 1}{2})}{\\sqrt{\\nu \\pi}\\Gamma(\\nu/2)} \\frac{1}{(1+x^2/\\nu)^{(\\nu + 1)/2}}, \\; x \\in \\mathbb R. \\] A figura abaixo mostra diferentes curvas da função de densidade de uma t-Student para diferentes valores de \\(\\nu\\). Além disso, adicionamos uma normal padrão, note que a distribução t-Student é uma distribuição com “caudas mais pesadas” que a normal. As distribuições qui-quadrado e t-Student estão relacionadas com a distribuição normal como segue: Se \\(Z_1,\\ldots,Z_n\\) são variáveis aleatórias independentes e identicamente distrbibuídas com distribuição normal padrão, então a variável \\(Y = \\sum_{i=1}^n Z_i^2\\) tem distribuição qui-quadrado com n graus de liberdade. Se \\(Z\\) e \\(Y\\) são variáveis aleatórias independentes, \\(Z\\sim N(0,1)\\) e \\(Y\\sim \\chi^2_{\\nu}\\), então a variável \\[ T = \\frac{Z}{\\sqrt{Y/\\nu}},\\] tem distribuição t de Student com n graus de liberdade 8.9.1 Amostragem de uma população normal Definição 8.10 Seja \\(F\\) uma distribuição de probabilidade. Uma amostra aleatória de tamanho \\(n\\) de uma população \\(F\\) é uma sequência finita \\(X_1,X_2,\\ldots, X_n\\) de variáveis aleatórias independentes e identicamente distribuídas com distribuição \\(F\\). Nesta seção lidamos com amostras obtidas a partir de uma população normal. A amostragem oriundas de populações normais conduz a diversas propriedades úteis da amostragem estatística e também a muitas distribuições amostrais amplamente conhecidas. Proposição 8.8 Seja \\(X_1, X_2, \\ldots, X_n\\) uma amostra aleatória de uma população normal com média \\(\\mu\\) e variância \\(\\sigma^2\\), defina, \\(\\bar X = \\frac{X_1 + \\ldots + X_n}{n}\\) e \\(S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar X)^2\\) como média amostral e variância amostral de \\(X_1,\\ldots, X_n\\), respectivamente. Então \\(\\bar X\\) e \\(S^2\\) são independentes, com \\(\\bar X \\sim N(\\mu,\\sigma^2/n)\\) \\(\\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2_{n-1}\\) \\(\\frac{\\sqrt{n}(\\bar X -\\mu)}{S} \\sim t_{n-1}\\) 8.10 Distribuição de Cauchy-Lorentz Definição 8.11 Dizemos que uma variável aleatória \\(X\\) tem distribuição de Cauchy (ou Cauchy-Lorentz) com parâmetros \\(\\alpha \\in \\mathbb R\\) e \\(\\beta &gt; 0\\) se, sua função de densidade é \\[ f(x)=\\frac{1}{\\pi \\beta \\{1+[(x-\\alpha)/\\beta]^2\\}}, \\; x\\in\\mathbb R \\] A seguir apresentamos várias curvas da densidade da Cauchy para diferentes valores de \\(\\alpha\\) e \\(\\beta\\). Observação. Quando \\(\\alpha=0\\) e \\(\\beta = 1\\), temos a distribuição Cauchy padrão, cuja função de densidade é \\[ f(x) = \\frac{1}{\\pi (1+x^2)}, \\; x\\in\\mathbb R \\] É possível mostrar que a média da distribuição de Cauchy não existe. De fato, se tentamos calcular a média de \\(X\\sim\\) Cauchy(0,1), temos que para qualquer \\(t\\in\\mathbb R\\): \\[\\begin{align*} E(X) &amp;= \\int_{-\\infty}^\\infty \\frac{x}{\\pi (1+x^2)} dx\\\\ &amp;= \\int_{-\\infty}^t \\frac{x}{\\pi (1+x^2)} dx + \\int_{t}^\\infty \\frac{x}{\\pi (1+x^2)} dx \\\\ &amp;= \\frac{1}{\\pi}\\left[\\int_{-\\infty}^{1+t^2} \\frac{du}{u} + \\int_{1+t^2}^{\\infty} \\frac{du}{u} \\right] \\\\ &amp;= \\frac{1}{\\pi}\\left[ \\ln(1+t^2) - \\ln(-\\infty) + \\ln(\\infty) - \\ln(1+t^2) \\right] \\\\ &amp;=\\infty - \\infty \\; (\\text{não definido}) \\end{align*}\\] Portanto, \\(E(X)\\) não existe. Observação. De fato \\(E(|X|) = \\infty\\), portanto não existem os momentos \\(E(X^n)\\) para qualquer \\(n\\geq 1\\). Em particular, a função geradora de momentos não existe. A pesar de não existir a média da distribuição de Cauchy é possível mostrar, por exemplo, que a médiana é \\(\\tilde \\mu = \\alpha\\). Para simplificar os cálculos assuma que \\(X\\sim\\) Cauchy(0,1), mostraremos que \\(\\tilde \\mu = 0\\): \\[\\begin{align*} F(0)=P(X\\leq 0) &amp;= \\frac{1}{\\pi}\\int_{-\\infty}^0 \\frac{dx}{1+x^2}\\\\ &amp;=\\frac{1}{\\pi} \\left[\\mathrm{arctg}(x)\\right]_{-\\infty}^0\\\\ &amp;=\\frac{1}{\\pi} (0-(-\\pi/2)) = 1/2. \\end{align*}\\] Portanto, \\(\\tilde \\mu = 0\\). Exemplo 8.9 Mostraremos nesse exemplo como a distribuição de Cauchy descreve a distância horizontal à qual um segmento de linha inclinado a um ângulo aleatório com distribuição uniforme contínua em [\\(-\\pi/2, \\pi/2\\)] corta o eixo \\(x\\). A situação é apresentada na figura abaixo. Solução. Seja \\(\\Theta\\) o ângulo daquele segmento, com um ponto fixo de rotação, que faz com o eixo \\(x\\) (como mostrado na figura acima). Então \\(\\Theta \\sim\\) Uniforme Contínua[\\(-\\pi/2,\\pi/2\\)]. Além disso, \\[\\begin{align*} F_X(x)=P(X \\leq x) &amp;= P(\\mathrm{tg}(\\Theta)\\leq \\frac{x}{\\beta})\\\\ &amp;=P(\\Theta \\leq \\mathrm{arctg}(x/\\beta))\\\\ &amp;=F_{\\Theta}(\\mathrm{arctg}(x/\\beta))\\\\ &amp;= \\frac{1}{\\pi}\\left[\\mathrm{arctg}(x/\\beta) + \\pi/2\\right] \\end{align*}\\] Logo, \\[\\begin{align*} f_X(x) = \\frac{d F(x)}{dx} &amp;= \\frac{1}{\\pi \\beta} \\left(\\frac{1}{1+(x/\\beta)^2}\\right) \\end{align*}\\] Portanto, \\(X\\sim\\) Cauchy(0,\\(\\beta\\)). 8.11 Distribuição Beta Definição 8.12 A função \\(B:(0,\\infty) \\times (0,\\infty) \\rightarrow \\mathbb R\\) é definida por \\[ B(\\alpha,\\beta) = \\int_0^1 x^{\\alpha -1} (1-x)^{\\beta - 1} dx, \\] Observação. A função beta está relacionada à função gama por meio da seguinte identidade: \\(B(\\alpha,\\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\). Definição 8.13 Dizemos que uma variável aleatória \\(X\\) tem distribuição beta com parâmetros \\(\\alpha&gt;0\\) e \\(\\beta&gt;0\\) se, sua função de densidade é \\[ f(x) = \\begin{cases} \\frac{1}{B(\\alpha,\\beta)}x^{\\alpha-1} (1-x)^{\\beta -1}, &amp; x \\in (0,1) \\\\ 0 &amp; \\text{caso contrário} \\end{cases} \\] A função de distribuição de uma variável aleatória beta, em geral, recebe o nome de função beta incompleta e é dada por \\[ F(x) = \\int_0^x \\frac{1}{B(\\alpha,\\beta)} t^{\\alpha - 1} (1-t)^{\\beta - 1} dt. \\] Se \\(\\alpha\\) e \\(\\beta\\) são inteiros, então \\[\\begin{align*} F(x) &amp;= \\int_0^x \\frac{1}{B(\\alpha,\\beta)} x^{\\alpha - 1} (1-x)^{\\beta - 1}\\\\ &amp;= \\sum_{i=\\alpha}^n \\binom{n}{i} x^i(1-x)^{n-i}, \\end{align*}\\] onde \\(n=\\alpha+\\beta-1\\). Proposição 8.9 Seja \\(X\\sim\\) Beta(\\(\\alpha,\\beta\\)), então \\[ E(X) = \\frac{\\alpha}{\\alpha + \\beta} \\text{ e } Var(X) = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta +1)} \\] Prova. Pela definição de esperança, temos \\[\\begin{align*} E(X) &amp;=\\frac{1}{B(\\alpha,\\beta)}\\int_{0}^1 x^\\alpha (1-x)^{\\beta -1} dx\\\\ &amp;=\\frac{B(\\alpha+1,\\beta)}{B(\\alpha,\\beta)}\\\\ &amp;=\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)}\\times \\frac{\\Gamma(\\alpha+1) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta + 1)}\\\\ &amp;=\\frac{\\alpha}{\\beta}. \\end{align*}\\] O cálculo da variância é deixado como exercício. Exemplo 8.10 Um distribuidor de combustível tem tanques de armazenamento de grande capacidade com um abastecimento fixo, que são cheios cada segunda. Ele deseja saber se a porcentagem de combustível vendido durante a semana. Depois de várias semanas de observação descobre que essa porcentagem pode ser bem modelada por uma variável aleatória com distribuição beta com \\(\\alpha=4\\) e \\(\\beta = 2\\). Qual a probabilidade de que venda pelo menos 90% de suas existências em uma semana? Solução. Seja \\(X\\): porcentagem de combustível vendido durante a semana \\(\\sim\\) Beta(4,2). \\[\\begin{align*} P(X&gt;0.90) &amp;= 1-\\int_0^{0.90} \\frac{1}{B(4,2)} t^{3} (1-t) dt\\\\ &amp;=1- F(0.90)\\\\ &amp;=0.08. \\end{align*}\\] 8.12 Distribuição Log-Normal Definição 8.14 Dizemos que uma variável aleatória \\(X\\) tem distribuição Log-Normal com parâmetros \\(\\mu\\in\\mathbb R\\) e \\(\\sigma^2 &gt; 0\\) se sua função de densidade é dada por: \\[ f(x) = \\frac{1}{x\\sigma\\sqrt{2\\pi}}e^{-(\\ln x - \\mu)^2/2\\sigma^2}, \\; x \\geq 0. \\] Notação: \\(X\\sim\\) Log-Normal(\\(\\mu,\\sigma^2\\)). Observação. \\(X\\sim\\) Log-Normal(\\(\\mu,\\sigma^2\\)) se \\(Y=\\ln X\\sim\\) N(\\(\\mu,\\sigma^2\\)) ou equivalentemente, se \\(Y \\sim\\)N(\\(\\mu,\\sigma^2\\)), então \\(X=e^Y\\sim\\) log-normal(\\(\\mu,\\sigma^2\\)). A função de distribuição de \\(X\\) é dada por \\[\\begin{align*} F(x) = P(X \\leq x) &amp;= P(\\ln X \\leq \\ln x)\\\\ &amp;=P(Y \\leq \\ln x)\\\\ &amp;=P\\left(Z\\leq \\frac{\\ln x - \\mu}{\\sigma}\\right)\\\\ &amp;=\\Phi\\left(\\frac{\\ln x - \\mu}{\\sigma}\\right) \\end{align*}\\] Agora, se \\(X\\sim\\) Log-Normal(\\(\\mu,\\sigma^2\\)), \\(Y\\sim\\)N(\\(\\mu,\\sigma^2\\)) e \\(Z\\sim\\) N(0,1), temos que \\[ E(X) = E(e^Y) = E(e^{\\mu + \\sigma Z}) = e^\\mu E(e^{\\sigma Z}) = e^\\mu M_Z(\\sigma) = e^{\\mu + (\\sigma^2t^2)/2}. \\] \\[ E(X^2) = E(e^{2Y}) = E(e^{2\\mu + 2\\sigma Z}) = e^{2\\mu} E(e^{2\\sigma Z}) = e^{2\\mu}M_{Z}(2\\sigma) = e^{2\\mu+2\\sigma^2}. \\] Portanto, \\[ Var(X) = e^{2\\mu+2\\sigma^2} - e^{2\\mu+\\sigma^2}. \\] Em geral, o \\(n\\)-ésimo momento de \\(X\\sim\\) log-normal(\\(\\mu,\\sigma^2\\)). \\[ E(X^n) = e^{n\\mu - n^2\\sigma^2/2}. \\] Observação. A função geradora de momentos da distribuição Log-Normal não existe. Exemplo 8.11 Suponha que o preço de uma ação (em dólares) negociada na bolsa de valores segue uma distribuição Log-Normal com parâmetros \\(\\mu = 5\\) e \\(\\sigma^2 = 1\\). Determine: a probabilidade de que o preço daquela ação não supere os $250. o p-ésimo quantil do preço daquela ação. Solução. Seja \\(X\\); preço da ação \\(\\sim\\) log-normal(\\(5,1\\)), P(X &lt; 250) &amp;= ()\\ &amp;=(0.52) . Seja \\(Q(p)\\) o p-ésimo quantil de \\(X\\), então \\[ F_X(Q(p)) = p \\iff \\Phi\\left(\\frac{\\ln(x) - 5}{1}\\right) = p, \\] logo: \\(z(p) = \\ln(Q(p)) - 5 \\iff Q(p) = e^{z(p) + 5}\\). Observação. Em geral, se \\(X\\sim\\) log-normal(\\(\\mu,\\sigma^2\\)), o \\(p\\)-ésimo quantil de \\(X\\) vem dado por: \\[ Q(p) = e^{\\sigma z(p) + \\mu}. \\] 8.13 Distribuição de Pareto Definição 8.15 Dizemos que a variável aleatória \\(X\\) tem distribuição de Pareto com parâmetros \\(\\alpha,\\beta &gt;0\\), se sua função de densidade é \\[ f(x) =\\begin{cases} \\frac{\\alpha \\beta^\\alpha}{x^{\\alpha + 1}}, &amp; x\\geq \\beta \\\\ 0, &amp; x &lt; \\beta \\end{cases} \\] A função de distribuição de \\(X\\) é dada por \\[\\begin{align*} F(x) &amp;= \\int_\\beta^x \\frac{\\alpha\\beta^\\alpha}{t^{\\alpha+1}} dt \\\\ &amp;=\\alpha\\beta^\\alpha \\int_\\beta^x t^{-\\alpha-1} dt \\\\ &amp;=\\alpha \\beta^\\alpha \\left[-\\frac{t^{-\\alpha}}{\\alpha}\\right]_\\beta^x \\\\ &amp;= 1 - \\left(\\frac{\\beta}{x}\\right)^\\alpha, \\; x \\geq \\beta \\end{align*}\\] Em suma \\[\\begin{align*} F(x) = \\begin{cases} 1- \\left(\\frac{\\beta}{x}\\right)^\\alpha, &amp; x\\geq \\beta \\\\ 0 &amp; x &lt; \\beta \\end{cases} \\end{align*}\\] Proposição 8.10 Seja \\(X\\sim\\) Pareto(\\(\\alpha,\\beta\\)), então \\[ E(X) = \\begin{cases} \\frac{\\alpha\\beta}{\\alpha - 1}, &amp; \\alpha &gt; 1,\\\\ \\infty, &amp; \\alpha \\leq 1 \\end{cases} \\] e \\[ Var(X) = \\begin{cases} \\frac{\\beta^2\\alpha}{(\\alpha - 1)^2(\\alpha - 2)}, &amp; \\alpha &gt;2,\\\\ \\infty &amp; \\alpha \\geq 2 \\end{cases} \\] Prova. \\[\\begin{align*} E(X) &amp;= \\int_\\beta^\\infty x \\frac{\\alpha\\beta^\\alpha}{x^{\\alpha+1}} dx\\\\ &amp;= \\int_\\beta^\\infty \\frac{\\alpha\\beta^\\alpha}{x^\\alpha} dx \\\\ &amp;= \\alpha\\beta^\\alpha \\left[ - \\frac{\\beta^{-\\alpha + 1}}{-\\alpha +1}\\right]_\\beta^\\infty = \\begin{cases} \\frac{\\alpha\\beta}{\\alpha - 1}, &amp; \\alpha &gt; 1,\\\\ \\infty, &amp; \\alpha \\leq 1 \\end{cases} \\end{align*}\\] \\[\\begin{align*} E(X^2) &amp;= \\int_\\beta^\\infty x \\frac{\\alpha\\beta^\\alpha}{x^{\\alpha+1}} dx\\\\ &amp;= \\alpha\\beta^\\alpha\\left[ \\frac{x^{-\\alpha + 2}}{-\\alpha + 2}\\right]_\\beta^\\infty = \\begin{cases} \\frac{\\alpha\\beta^2}{\\alpha - 2}, &amp; \\alpha &gt; 2,\\\\ \\infty, &amp; \\alpha \\leq 2 \\end{cases} \\end{align*}\\] O resultado segue, calculando \\(Var(X) = E(X^2) - [E(X)]^2\\) Exercício 8.1 Mostre que para \\(n\\geq 1\\) \\[ E(X^n) = \\begin{cases} \\frac{\\alpha\\beta^n}{\\alpha - n}, &amp; \\alpha &gt; n,\\\\ \\infty, &amp; \\alpha \\leq n \\end{cases} \\] Exemplo 8.12 Suponha que a renda em reais de uma certa população tem distribuição de Pareto com parâmetro de forma \\(\\alpha = 3\\) e parâmetro de escala \\(\\beta = 1000\\). Encontre: a proporção da população com renda entre 2000 e 4000 reais. A renda media da população. A renda mediana da população. Solução. Seja \\(X:\\) Renda da população \\(\\sim\\) Pareto(3,1000) \\(P(2000 &lt; X &lt; 4000) = F(4000) - F(2000) = \\left(\\frac{2}{4}\\right)^3 - \\left(\\frac{1}{4}\\right)^3 \\approx 10.93 \\%\\) \\(E(X) = \\frac{\\alpha\\beta}{\\alpha - 1} = 1500\\) reais. É deixado como exercício ao leitor. 8.14 Distribuição de Weibull Definição 8.16 Dizemos que uma variável aleatória \\(X\\) tem distribuição de Weibull com parâmetros \\(\\alpha &gt; 0\\) e \\(\\lambda &gt; 0\\) se sua função de densidade é dada por \\[ f(x) = \\alpha \\lambda x^{\\alpha - 1} e^{-\\lambda x^\\alpha}, \\; x&gt;0 \\] Notação: \\(X\\sim\\) Weibull(\\(\\alpha,\\lambda\\)). Observação. Quando \\(\\alpha = 2\\) e \\(\\lambda = 1/\\theta^2\\) a distribuição é conhecida como distribuição de Rayleigh. A função de distribuição de \\(X\\) é dada por \\[ F(x) = \\begin{cases} 1-e^{-\\lambda x^\\alpha}, &amp; x&gt;0 \\\\ 0, &amp; x\\leq 0 \\end{cases} \\] Proposição 8.11 Seja \\(X\\sim\\) Weibull(\\(\\alpha,\\lambda\\)), então \\[ E(X) = \\lambda^{-1/\\alpha} \\Gamma(1+1/\\alpha) \\text{ e } Var(X) = \\lambda^{-2/\\alpha} \\left[\\Gamma(1+2/\\alpha) - [\\Gamma(1+1/\\alpha)]^2)\\right] \\] 8.15 Distribuição de Laplace (dupla exponencial) Definição 8.17 Dizemos que uma variável aleatória \\(X\\) tem distribuição de Laplace (ou dupla exponencial) com parâmetros \\(\\mu\\in\\mathbb R\\) e \\(\\lambda&gt;0\\) se sua função de densidade é dada por \\[ f(x) = \\frac{1}{2} e^{-\\lambda|x - \\mu|}, \\; x \\in \\mathbb R \\] Notação: \\(X\\sim\\) Laplace(\\(\\mu,\\lambda\\)) A função de distribuição de \\(X\\) é dada por \\[\\begin{align*} F(x) = \\begin{cases} \\frac{1}{2} e^{\\lambda(x - \\mu)}, &amp; x&lt; \\mu,\\\\ 1-\\frac{1}{2}e^{-\\lambda(x-\\mu)}, &amp; x\\geq \\mu \\end{cases} \\end{align*}\\] Proposição 8.12 Seja \\(X\\sim\\)Laplace(\\(\\mu,\\lambda\\)), então \\[E(X) = \\mu \\text{ e } Var(X) = \\frac{2}{\\lambda^2} \\] "],["desigualdades.html", "Capítulo 9 Algumas desigualdades Desigualdade de Markov Desigualdade de Chebyshev Desigualdade de Jensen Teorema de chebyshev", " Capítulo 9 Algumas desigualdades Desigualdade de Markov Se \\(X\\geq 0\\), então para qualquer \\(\\lambda &gt; 0\\), \\[ P(X\\geq \\lambda) \\leq \\frac{E(X)}{\\lambda}.\\] Desigualdade de Chebyshev Seja \\(X\\) uma v.a. com \\(E(X) &lt; \\infty\\). Então, para qualquer \\(\\lambda &gt; 0\\), \\[ P(|X-E(X)| \\geq \\lambda) \\leq \\frac{Var(X)}{\\lambda^2}.\\] Desigualdade de Jensen Suponha que \\(\\psi: \\mathbb R \\rightarrow \\mathbb R\\) é uma função convexa. Se \\(E(|X|) &lt; \\infty\\), enttão \\[ E(\\psi(X)) \\geq \\psi(E(X)). \\] Um caso de aplicação da Desigualdade de Chebyshev é apresentado no seguinte teorema. Teorema de chebyshev Teorema 9.1 Seja \\(X\\) uma variável aleatória com \\(\\mu = E(X)\\) e \\(0&lt;\\sigma^2 = Var(X) &lt; \\infty\\), então para qualquer \\(k&gt;0\\) \\[P(|X-\\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}.\\] Prova. Faremos a prova no caso em que \\(X\\) é uma variável aleatória contínua com função de densidade \\(f(x)\\). De fato, \\[\\begin{align*} \\sigma^2 &amp;= \\int_{-\\infty}^\\infty (x-\\mu)^2 f(x) dx \\\\ &amp;= \\int_{-\\infty}^{\\mu - \\sigma} (x-\\mu)^2 f(x) dx + \\int_{\\mu -\\sigma}^{\\mu +\\sigma} (x-\\mu)^2 f(x) dx + \\int_{\\mu +\\sigma}^\\infty (x-\\mu)^2 f(x) dx \\end{align*}\\] Note que a segunda integral é maior ou igual a 0, enquanto que primeira e a última integral é maior ou igual a \\(k^2\\sigma^2\\). Daí, \\[\\begin{align*} \\sigma^2 \\geq k^2\\sigma^2 \\left[P(X\\leq \\mu -k\\sigma) + P(X\\geq \\mu + k\\sigma)\\right], \\end{align*}\\] Portanto, \\[P(|X-\\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}.\\] "],["transformaccoes.html", "Capítulo 10 Transformações de variáveis aleatória 10.1 Método da função de distribuição 10.2 Método das transformações 10.3 Método da transformação inversa", " Capítulo 10 Transformações de variáveis aleatória Motivação: Suponha que você possui uma amostra aleatória \\(X_1, \\ldots, X_n\\). Definimos uma estatística como uma função \\(T= T(X_1,\\ldots,X_n) \\in \\mathbb R\\) da amostra aleatória. Como \\(X_1,\\ldots, X_n\\) são variáveis aleatórias então a estatística \\(T\\) também é uma variável aleatória. Se por exemplo, \\(X_1, \\ldots, X_n\\) é uma amostra dos preços do aluguel (em reais) em uma certa região, \\(T = X_{(n)} = \\textrm{máx}\\{X_1,\\ldots,X_n\\}\\) representa o valor máximo do aluguel. Portanto, se quisermos calcular a probabilidade de que o valor máximo não exceda os 2000 reais, \\(P(X_{(n)} &lt; 2000)\\), precisamos da distribuição de \\(X_{(n)}\\) que por definição é uma transformação de \\(X_1,\\ldots, X_n\\). Neste capítulo lidaremos com métodos para determinar a distribuição de probabilidade de transformações de variáveis aleatórias. Entre os método mais comuns encontramos: O método da função de distribuição. O método das transformações. 10.1 Método da função de distribuição Ilustraremos o método da função de distribuição através de vários exemplos. Exemplo 10.1 Seja \\(X\\) uma variável aleatória, e seja \\(Y=X^n\\). Determine a distribuição de \\(Y\\). Solução. Seja \\(Y = X^n\\), então \\[\\begin{align*} F_Y(y) &amp;= P(Y \\leq y) \\\\ &amp;=P(X \\leq y^{1/n}) \\\\ &amp;=F_X(y^{1/n}). \\end{align*}\\] Logo, derivando em relação a \\(y\\), temos que a densidade de \\(Y\\) é dada por \\[ f_Y(y) = \\frac{1}{n} y^{1/n - 1} f_X(y^{1/n}) \\] Se por exemplo, \\(X \\sim\\) Uniforme Contínua(0,1), temos que \\[ f_Y(y) = \\frac{1}{n} y^{1/n - 1}, \\; y \\in (0,1). \\] Exemplo 10.2 Seja \\(X\\) uma variável aleatória, e seja \\(Y = X^2\\). Determine a distribuição de \\(Y\\). Solução. Seja \\(Y = X^2\\), então \\[\\begin{align*} F_Y(y) &amp;= P(Y \\leq y) \\\\ &amp;=P(X^2 \\leq y) \\\\ &amp;=P(|X| \\leq \\sqrt{y})\\\\ &amp;=F_X(\\sqrt{y}) - F_X(-\\sqrt{y}). \\end{align*}\\] Logo, derivando em relação a \\(y\\), temos que a densidade de \\(Y\\) é dada por \\[ f_Y(y) = \\frac{1}{\\sqrt{y}} f_X(\\sqrt{y}) + \\frac{1}{\\sqrt{y}} f_X(-\\sqrt{y}), \\; y &gt;0. \\] Se por exemplo, \\(X\\sim N(0,1)\\), então \\(Y = X^2 \\sim \\chi^2_1\\). Com efeito, a densidade da distribuição qui-quadrado com 1 grau de liberdade é dada por \\[ f_Y(y) = \\frac{(1/2)^{1/2}}{\\sqrt{\\pi}} y^{-1/2}e^{-y/2}, \\; y&gt;0. \\] Para concluirmos a afirmação, basta usar o fato que \\(f_X(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}, x \\in \\mathbb R\\). Exemplo 10.3 Seja \\(X\\) uma variável aleatória, e seja \\(Y = |X|\\). Determine a distribuição de \\(Y\\). Solução. Seja \\(Y = X^2\\), então \\[\\begin{align*} F_Y(y) &amp;= P(Y \\leq y) \\\\ &amp;=P(|X| \\leq y)\\\\ &amp;=F_X(y) - F_X(-y). \\end{align*}\\] Logo, derivando em relação a \\(y\\), temos que a densidade de \\(Y\\) é dada por \\[ f_Y(y) = f_X(y) + f_X(-y), \\; y &gt;0. \\] Se por exemplo \\(X \\sim N(0,1)\\), a distribuição de \\(Y= |X|\\) é conhecida como a distribuição normal dobrada e sua função de densidade é dada por \\[\\begin{align*} f_Y(y) &amp;= \\frac{1}{\\sqrt{2\\pi}} e^{-y^2/2} + \\frac{1}{\\sqrt{2\\pi}} e^{-y^2/2}\\\\ &amp;=\\frac{\\sqrt 2}{\\sqrt{\\pi}} e^{-y^2/2}, \\; y&gt;0. \\end{align*}\\] 10.2 Método das transformações Continuamos interessados em determinar a distribuição de \\(Y= g(X)\\). O método das transformações é uma aplicação do método da função de distribuição, no caso em que \\(g(x)\\) é uma função estritamente monótona. Primeiro, vamos supor que \\(y=g(x)\\) é estritamente crescente, nesse caso note que \\(x=g^{-1}(y)\\) também é estritamente crescente. Logo \\[\\begin{align*} F_Y(y) &amp;= P(g(X) \\leq y) \\\\ &amp;=P(X \\leq g^{-1}(x)) \\\\ &amp;=F_X(g^{-1}(x)) \\end{align*}\\] Derivando em relação a \\(y\\) e usando o fato que \\(g^{-1}(y)\\) é estritamente crescente, temos que a densidade de \\(Y\\) é dada por \\[ f_Y(y) = f_X(g^{-1}(y))\\left|\\frac{dg^{-1}(y)}{dy}\\right|, \\; y=g(x) \\] Agora, suponha que \\(g(x)\\) é estritamente decrescente, então \\[\\begin{align*} F_Y(y) &amp;= P(g(X) \\leq y) \\\\ &amp;=1 - P(X \\leq g^{-1}(x)) \\\\ &amp;=1 - F_X(g^{-1}(x)). \\end{align*}\\] Derivando em relação a \\(y\\) e usando o fato que \\(g^{-1}(y)\\) é estritamente decrescente, temos que a densidade de \\(Y\\) é dada por \\[ f_Y(y) = f_X(g^{-1}(y))\\left|\\frac{dg^{-1}(y)}{dy}\\right|, \\; y=g(x) \\] Por fim, temos o seguinte teorema. Teorema 10.1 (método das transformações) Seja \\(X\\) uma variável aleatória contínua com função de densidade \\(f_X\\), e seja \\(g(x)\\) uma função estritamente monótona e derivável, então a densidade de \\(Y = g(X)\\) é dada por \\[ f_Y(y) = f_X(g^{-1}(y))\\left|\\frac{dg^{-1}(y)}{dy}\\right|, \\; y=g(x) \\text{ para algum } x. \\] Exemplo 10.4 Seja \\(X\\) uma variável aleatória contínua com função de densidade dada por \\[f(x) = 2x, \\; x \\in [0,1].\\] Encontre a função de densidade de \\(Y = -4X + 3\\). Solução. Podemos proceder como segue: Determine o conjunto de valores de \\(y\\): \\[y = -4x + 3 \\iff x=g^{-1}(y) = \\frac{3 - y}{4}, \\; y \\in [-1,3]\\] Determine a derivada de \\(g^{-1}(y)\\): \\[\\frac{dg^{-1}(y)}{dy} = -\\frac{1}{4}\\] Finalmente, a densidade de \\(Y\\) é dada por: \\[\\begin{align*} f_Y(y) &amp;= f_X(g^{-1}(y))\\left|\\frac{dg^{-1}(y)}{dy}\\right|\\\\ &amp;=\\frac{3-y}{8}, \\; y \\in [-1,3]. \\end{align*}\\] 10.3 Método da transformação inversa Apresenteramos um método geral para gerar uma variável aleatória contínua, o método é baseado no seguinte resultado e é conhecido como o método da função inversa. Teorema 10.2 Seja \\(U\\) uma variável aleatória uniforme em (0,1). Seja \\(F_X\\) a função de distribuição de uma variável aleatória contínua \\(X\\), se definimos a transformação \\(Y = F_X^{-1}(U)\\), então \\(Y\\) tem a mesma distribuição de \\(X\\). Prova. Seja \\(U\\sim\\) Uniforme em (0,1) e defina \\(Y = F_X^{-1}(U)\\). Logo \\[\\begin{align*} F_Y(y)&amp;=P(Y \\leq y)\\\\ &amp;=P(F_X^{-1}(U) \\leq y)\\\\ &amp;=P(U \\leq F_X(y))\\\\ &amp;=F_X(y). \\end{align*}\\] Exemplo 10.5 Suponha que queiramos gerar uma variável aleatória com distribuição exponencial de parâmetro \\(\\lambda &gt;0\\). Então podemos proceder como segue: Considere \\(U\\) uma variável aleatória uniforme em (0,1) e lembrando que \\(F_X(x) = 1- e^{-\\lambda x}, \\; x &gt;0\\), temos que \\(F_X^{-1}(u) = -\\frac{\\ln(1-u)}{\\lambda}\\). Logo, a transformação \\(X = -\\frac{\\ln(1-U)}{\\lambda}\\) tem distribuição exponencial de parâmetro \\(\\lambda\\). "],["bibliografia.html", "Bibliografia", " Bibliografia James, Barry. 2015. Probabilidade: Um curso em nível intermediário. IMPA. Lebensztayn, Élcio. 2012. Exercícios de Probabilidade. Online. Ross, Sheldon. 2010. Probabilidade: Um curso moderno com aplicações. Bookman. "],["tabelas.html", "Capítulo 11 Tabelas 11.1 Tabela da normal padrão 11.2 Tabela da função gama incompleta (Função de distribuição da gama padrão)", " Capítulo 11 Tabelas 11.1 Tabela da normal padrão 0.5000 0.5040 0.5080 0.5120 0.5160 0.5199 0.5239 0.5279 0.5319 0.5359 0.5398 0.5438 0.5478 0.5517 0.5557 0.5596 0.5636 0.5675 0.5714 0.5753 0.5793 0.5832 0.5871 0.5910 0.5948 0.5987 0.6026 0.6064 0.6103 0.6141 0.6179 0.6217 0.6255 0.6293 0.6331 0.6368 0.6406 0.6443 0.6480 0.6517 0.6554 0.6591 0.6628 0.6664 0.6700 0.6736 0.6772 0.6808 0.6844 0.6879 0.6915 0.6950 0.6985 0.7019 0.7054 0.7088 0.7123 0.7157 0.7190 0.7224 0.7257 0.7291 0.7324 0.7357 0.7389 0.7422 0.7454 0.7486 0.7517 0.7549 0.7580 0.7611 0.7642 0.7673 0.7704 0.7734 0.7764 0.7794 0.7823 0.7852 0.7881 0.7910 0.7939 0.7967 0.7995 0.8023 0.8051 0.8078 0.8106 0.8133 0.8159 0.8186 0.8212 0.8238 0.8264 0.8289 0.8315 0.8340 0.8365 0.8389 0.8413 0.8438 0.8461 0.8485 0.8508 0.8531 0.8554 0.8577 0.8599 0.8621 0.8643 0.8665 0.8686 0.8708 0.8729 0.8749 0.8770 0.8790 0.8810 0.8830 0.8849 0.8869 0.8888 0.8907 0.8925 0.8944 0.8962 0.8980 0.8997 0.9015 0.9032 0.9049 0.9066 0.9082 0.9099 0.9115 0.9131 0.9147 0.9162 0.9177 0.9192 0.9207 0.9222 0.9236 0.9251 0.9265 0.9279 0.9292 0.9306 0.9319 0.9332 0.9345 0.9357 0.9370 0.9382 0.9394 0.9406 0.9418 0.9429 0.9441 0.9452 0.9463 0.9474 0.9484 0.9495 0.9505 0.9515 0.9525 0.9535 0.9545 0.9554 0.9564 0.9573 0.9582 0.9591 0.9599 0.9608 0.9616 0.9625 0.9633 0.9641 0.9649 0.9656 0.9664 0.9671 0.9678 0.9686 0.9693 0.9699 0.9706 0.9713 0.9719 0.9726 0.9732 0.9738 0.9744 0.9750 0.9756 0.9761 0.9767 0.9772 0.9778 0.9783 0.9788 0.9793 0.9798 0.9803 0.9808 0.9812 0.9817 0.9821 0.9826 0.9830 0.9834 0.9838 0.9842 0.9846 0.9850 0.9854 0.9857 0.9861 0.9864 0.9868 0.9871 0.9875 0.9878 0.9881 0.9884 0.9887 0.9890 0.9893 0.9896 0.9898 0.9901 0.9904 0.9906 0.9909 0.9911 0.9913 0.9916 0.9918 0.9920 0.9922 0.9925 0.9927 0.9929 0.9931 0.9932 0.9934 0.9936 0.9938 0.9940 0.9941 0.9943 0.9945 0.9946 0.9948 0.9949 0.9951 0.9952 0.9953 0.9955 0.9956 0.9957 0.9959 0.9960 0.9961 0.9962 0.9963 0.9964 0.9965 0.9966 0.9967 0.9968 0.9969 0.9970 0.9971 0.9972 0.9973 0.9974 0.9974 0.9975 0.9976 0.9977 0.9977 0.9978 0.9979 0.9979 0.9980 0.9981 0.9981 0.9982 0.9982 0.9983 0.9984 0.9984 0.9985 0.9985 0.9986 0.9986 0.9987 0.9987 0.9987 0.9988 0.9988 0.9989 0.9989 0.9989 0.9990 0.9990 11.2 Tabela da função gama incompleta (Função de distribuição da gama padrão) \\(x\\) \\(\\alpha\\) 1 2 3 4 5 6 7 8 9 10 1 0.632 0.264 0.080 0.019 0.004 0.001 0.000 0.000 0.000 0.000 2 0.865 0.594 0.323 0.143 0.053 0.017 0.005 0.001 0.000 0.000 3 0.950 0.801 0.577 0.353 0.185 0.084 0.034 0.012 0.004 0.001 4 0.982 0.908 0.762 0.567 0.371 0.215 0.111 0.051 0.021 0.008 5 0.993 0.960 0.875 0.735 0.560 0.384 0.238 0.133 0.068 0.032 6 0.998 0.983 0.938 0.849 0.715 0.554 0.394 0.256 0.153 0.084 7 0.999 0.993 0.970 0.918 0.827 0.699 0.550 0.401 0.271 0.170 8 1.000 0.997 0.986 0.958 0.900 0.809 0.687 0.547 0.407 0.283 9 1.000 0.999 0.994 0.979 0.945 0.884 0.793 0.676 0.544 0.413 10 1.000 1.000 0.997 0.990 0.971 0.933 0.870 0.780 0.667 0.542 11 1.000 1.000 0.999 0.995 0.985 0.962 0.921 0.857 0.768 0.659 12 1.000 1.000 0.999 0.998 0.992 0.980 0.954 0.910 0.845 0.758 13 1.000 1.000 1.000 0.999 0.996 0.989 0.974 0.946 0.900 0.834 14 1.000 1.000 1.000 1.000 0.998 0.994 0.986 0.968 0.938 0.891 15 1.000 1.000 1.000 1.000 0.999 0.997 0.992 0.982 0.963 0.930 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
